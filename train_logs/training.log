2025-08-15 21:23:29,736 - __main__ - INFO - Training configuration: {'pipelines': ['mfcc', 'mel_cnn', 'raw_cnn'], 'num_epochs': 50, 'batch_size': 32, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'scheduler_type': 'plateau', 'early_stopping_patience': 10, 'gradient_clipping': 1.0, 'save_frequency': 10, 'sample_rate': 8000, 'max_length': 8000}
2025-08-15 21:23:29,736 - __main__ - INFO - Loading dataset...
2025-08-15 21:23:29,736 - ml_training.data.dataset_loader - INFO - Loading and preparing digit dataset...
2025-08-15 21:23:29,736 - ml_training.data.dataset_loader - INFO - Initialized DataLoader - SR: 8000Hz, Max Length: 8000 samples
2025-08-15 21:23:29,738 - ml_training.data.dataset_loader - INFO - Loading Free Spoken Digit Dataset...
2025-08-15 21:23:29,922 - ml_training.data.dataset_loader - ERROR - Error loading dataset: The directory at E:/Streaming-Digit-Detector/https:/github.com/Jakobovski/free-spoken-digit-dataset/archive/refs/heads/master.zip doesn't contain any data files
2025-08-15 21:23:29,922 - ml_training.data.dataset_loader - INFO - Attempting fallback dataset loading...
2025-08-15 21:23:29,922 - ml_training.data.dataset_loader - WARNING - Using fallback dataset loading - limited functionality
2025-08-15 21:23:29,923 - ml_training.data.dataset_loader - ERROR - Failed to load dataset
2025-08-15 21:23:29,923 - __main__ - ERROR - Training failed: Failed to load dataset
2025-08-15 21:28:52,096 - __main__ - INFO - Training configuration: {'pipelines': ['mfcc'], 'num_epochs': 5, 'batch_size': 16, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'scheduler_type': 'plateau', 'early_stopping_patience': 10, 'gradient_clipping': 1.0, 'save_frequency': 10, 'sample_rate': 8000, 'max_length': 8000}
2025-08-15 21:28:52,097 - ml_training.data.dataset_loader - INFO - Loading and preparing digit dataset...
2025-08-15 21:28:52,601 - ml_training.data.dataset_loader - INFO - ffmpeg detected - will use for high-quality audio resampling
2025-08-15 21:28:52,601 - ml_training.data.dataset_loader - INFO - Initialized DataLoader - SR: 8000Hz, Max Length: 8000 samples
2025-08-15 21:28:52,601 - ml_training.data.dataset_loader - INFO - Loading Free Spoken Digit Dataset from HuggingFace...
2025-08-15 21:29:00,560 - ml_training.data.dataset_loader - INFO - Dataset loaded successfully
2025-08-15 21:29:00,560 - ml_training.data.dataset_loader - INFO - Available splits: ['train', 'test']
2025-08-15 21:29:00,560 - ml_training.data.dataset_loader - INFO - Train split size: 2700
2025-08-15 21:29:02,456 - ml_training.data.dataset_loader - INFO - Dataset sample structure: dict_keys(['audio', 'label'])
2025-08-15 21:29:02,456 - ml_training.data.dataset_loader - INFO - Audio info: sampling_rate=8000, array_shape=(5958,)
2025-08-15 21:29:02,457 - ml_training.data.dataset_loader - INFO - Label type: <class 'int'>, value: 0
2025-08-15 21:29:02,457 - ml_training.data.dataset_loader - INFO - Creating train/test/validation splits...
2025-08-15 21:29:02,457 - ml_training.data.dataset_loader - INFO - Processing 2700 samples from 'train' split
2025-08-15 21:29:02,493 - ml_training.data.dataset_loader - INFO - Processed 100/2700 samples
2025-08-15 21:29:02,530 - ml_training.data.dataset_loader - INFO - Processed 200/2700 samples
2025-08-15 21:29:02,567 - ml_training.data.dataset_loader - INFO - Processed 300/2700 samples
2025-08-15 21:29:02,608 - ml_training.data.dataset_loader - INFO - Processed 400/2700 samples
2025-08-15 21:29:02,639 - ml_training.data.dataset_loader - INFO - Processed 500/2700 samples
2025-08-15 21:29:02,667 - ml_training.data.dataset_loader - INFO - Processed 600/2700 samples
2025-08-15 21:29:02,694 - ml_training.data.dataset_loader - INFO - Processed 700/2700 samples
2025-08-15 21:29:02,723 - ml_training.data.dataset_loader - INFO - Processed 800/2700 samples
2025-08-15 21:29:02,750 - ml_training.data.dataset_loader - INFO - Processed 900/2700 samples
2025-08-15 21:29:02,776 - ml_training.data.dataset_loader - INFO - Processed 1000/2700 samples
2025-08-15 21:29:02,806 - ml_training.data.dataset_loader - INFO - Processed 1100/2700 samples
2025-08-15 21:29:02,837 - ml_training.data.dataset_loader - INFO - Processed 1200/2700 samples
2025-08-15 21:29:02,867 - ml_training.data.dataset_loader - INFO - Processed 1300/2700 samples
2025-08-15 21:29:02,898 - ml_training.data.dataset_loader - INFO - Processed 1400/2700 samples
2025-08-15 21:29:02,926 - ml_training.data.dataset_loader - INFO - Processed 1500/2700 samples
2025-08-15 21:29:02,954 - ml_training.data.dataset_loader - INFO - Processed 1600/2700 samples
2025-08-15 21:29:02,986 - ml_training.data.dataset_loader - INFO - Processed 1700/2700 samples
2025-08-15 21:29:03,022 - ml_training.data.dataset_loader - INFO - Processed 1800/2700 samples
2025-08-15 21:29:03,057 - ml_training.data.dataset_loader - INFO - Processed 1900/2700 samples
2025-08-15 21:29:03,092 - ml_training.data.dataset_loader - INFO - Processed 2000/2700 samples
2025-08-15 21:29:03,125 - ml_training.data.dataset_loader - INFO - Processed 2100/2700 samples
2025-08-15 21:29:03,158 - ml_training.data.dataset_loader - INFO - Processed 2200/2700 samples
2025-08-15 21:29:03,191 - ml_training.data.dataset_loader - INFO - Processed 2300/2700 samples
2025-08-15 21:29:03,226 - ml_training.data.dataset_loader - INFO - Processed 2400/2700 samples
2025-08-15 21:29:03,259 - ml_training.data.dataset_loader - INFO - Processed 2500/2700 samples
2025-08-15 21:29:03,294 - ml_training.data.dataset_loader - INFO - Processed 2600/2700 samples
2025-08-15 21:29:03,328 - ml_training.data.dataset_loader - INFO - Processed 2700/2700 samples
2025-08-15 21:29:03,373 - ml_training.data.dataset_loader - INFO - Audio data shape: (2700, 8000)
2025-08-15 21:29:03,373 - ml_training.data.dataset_loader - INFO - Labels shape: (2700,)
2025-08-15 21:29:03,374 - ml_training.data.dataset_loader - INFO - Unique labels: [0 1 2 3 4 5 6 7 8 9]
2025-08-15 21:29:03,374 - ml_training.data.dataset_loader - INFO - Label encoding: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}
2025-08-15 21:29:03,374 - ml_training.data.dataset_loader - INFO - Creating splits - Test: 20.0%, Val: 10.0%
2025-08-15 21:29:03,436 - ml_training.data.dataset_loader - INFO - Dataset splits created successfully:
2025-08-15 21:29:03,436 - ml_training.data.dataset_loader - INFO -   Train: 1890 samples
2025-08-15 21:29:03,437 - ml_training.data.dataset_loader - INFO -   Val: 270 samples
2025-08-15 21:29:03,437 - ml_training.data.dataset_loader - INFO -   Test: 540 samples
2025-08-15 21:29:03,437 - ml_training.data.dataset_loader - INFO -   Classes: 10 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
2025-08-15 21:29:03,455 - ml_training.data.dataset_loader - INFO - Validating dataset splits...
2025-08-15 21:29:03,458 - ml_training.data.dataset_loader - INFO - Dataset preparation completed successfully
2025-08-15 21:29:03,460 - __main__ - INFO - Training mfcc pipeline...
2025-08-15 21:29:03,460 - ml_training.pipelines.mfcc_pipeline - INFO - Setting up MFCC pipeline...
2025-08-15 21:29:03,460 - ml_training.pipelines.mfcc_pipeline - INFO - Fitting feature scaler on training data...
2025-08-15 21:29:09,099 - ml_training.pipelines.mfcc_pipeline - INFO - Feature scaling statistics:
2025-08-15 21:29:09,099 - ml_training.pipelines.mfcc_pipeline - INFO -   Mean: [-509.94391019   24.72415496    5.40042514    1.75478205  -10.29276815]... (first 5)
2025-08-15 21:29:09,099 - ml_training.pipelines.mfcc_pipeline - INFO -   Std: [47.04976658 16.63563144  9.60469901  8.82461158  7.35149315]... (first 5)
2025-08-15 21:29:09,100 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 1890 samples...
2025-08-15 21:29:14,421 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (1890, 156)
2025-08-15 21:29:14,421 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 540 samples...
2025-08-15 21:29:16,082 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (540, 156)
2025-08-15 21:29:16,082 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 270 samples...
2025-08-15 21:29:16,884 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (270, 156)
2025-08-15 21:29:16,887 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Classifier initialized:
2025-08-15 21:29:16,887 - ml_training.pipelines.mfcc_pipeline - INFO -   Architecture: 156 -> 256 -> 128 -> 64 -> 10
2025-08-15 21:29:16,887 - ml_training.pipelines.mfcc_pipeline - INFO -   Total parameters: 82,890
2025-08-15 21:29:16,887 - ml_training.pipelines.mfcc_pipeline - INFO -   Dropout: 0.3
2025-08-15 21:29:17,018 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC pipeline setup completed:
2025-08-15 21:29:17,019 - ml_training.pipelines.mfcc_pipeline - INFO -   Device: cuda
2025-08-15 21:29:17,019 - ml_training.pipelines.mfcc_pipeline - INFO -   Train samples: 1890
2025-08-15 21:29:17,019 - ml_training.pipelines.mfcc_pipeline - INFO -   Val samples: 270
2025-08-15 21:29:17,019 - ml_training.pipelines.mfcc_pipeline - INFO -   Test samples: 540
2025-08-15 21:29:17,019 - ml_training.pipelines.mfcc_pipeline - INFO -   Batch size: 16
2025-08-15 21:29:17,019 - ml_training.pipelines.mfcc_pipeline - INFO -   Feature dimension: 156
2025-08-15 21:29:17,020 - ml_training_1958286911264 - INFO - ML Training Logger initialized - Log file: train_logs\mfcc_classifier_20250815_212917.log
2025-08-15 21:29:17,020 - ml_training_1958286911264 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:29:17,021 - ml_training_1958286911264 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:29:17,021 - ml_training_1958286911264 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:29:17,021 - ml_training_1958286911264 - INFO - NumPy Version: 1.26.4
2025-08-15 21:29:17,021 - ml_training_1958286911264 - INFO - Librosa Version: 0.10.2
2025-08-15 21:29:17,021 - ml_training_1958286911264 - INFO - CUDA Available: Yes
2025-08-15 21:29:17,022 - ml_training_1958286911264 - INFO - CUDA Version: 12.1
2025-08-15 21:29:17,022 - ml_training_1958286911264 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:29:17,022 - ml_training_1958286911264 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:29:17,022 - ml_training_1958286911264 - INFO - === END SYSTEM INFO ===
2025-08-15 21:29:17,131 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\mfcc_classifier
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO - Trainer initialized for mfcc_classifier
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO - === MFCC_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO - Total Parameters: 82,890
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO - Trainable Parameters: 82,890
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO - Non-trainable Parameters: 0
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO - Model Architecture:
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.0: Linear(in_features=156, out_features=256, bias=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.1: BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.2: ReLU(inplace=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.3: Dropout(p=0.3, inplace=False)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.4: Linear(in_features=256, out_features=128, bias=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.5: BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.6: ReLU(inplace=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.7: Dropout(p=0.3, inplace=False)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.8: Linear(in_features=128, out_features=64, bias=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.9: BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.10: ReLU(inplace=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.11: Dropout(p=0.3, inplace=False)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO -   network.12: Linear(in_features=64, out_features=10, bias=True)
2025-08-15 21:29:17,131 - ml_training_1958286911264 - INFO - === END MFCC_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:29:18,286 - ml_training_1958286911264 - INFO - === EXPERIMENT CONFIGURATION ===
2025-08-15 21:29:18,286 - ml_training_1958286911264 - INFO - learning_rate: 0.001
2025-08-15 21:29:18,286 - ml_training_1958286911264 - INFO - weight_decay: 0.0001
2025-08-15 21:29:18,286 - ml_training_1958286911264 - INFO - scheduler_type: plateau
2025-08-15 21:29:18,286 - ml_training_1958286911264 - INFO - early_stopping_patience: 10
2025-08-15 21:29:18,286 - ml_training_1958286911264 - INFO - gradient_clipping: 1.0
2025-08-15 21:29:18,286 - ml_training_1958286911264 - INFO - mixed_precision: True
2025-08-15 21:29:18,287 - ml_training_1958286911264 - INFO - optimizer: Adam
2025-08-15 21:29:18,287 - ml_training_1958286911264 - INFO - loss_function: CrossEntropyLoss with label smoothing
2025-08-15 21:29:18,287 - ml_training_1958286911264 - INFO - device: cuda
2025-08-15 21:29:18,287 - ml_training_1958286911264 - INFO - Configuration saved to: train_logs\config_mfcc_classifier_20250815_212917.json
2025-08-15 21:29:18,287 - ml_training_1958286911264 - INFO - === END CONFIGURATION ===
2025-08-15 21:29:18,287 - ml_training_1958286911264 - INFO - Starting training for 5 epochs
2025-08-15 21:29:18,287 - ml_training_1958286911264 - DEBUG - Timer started: train_epoch_1
2025-08-15 21:29:18,645 - ml_training_1958286911264 - DEBUG - Batch 0/119: Loss=3.0202, Acc=0.00%
2025-08-15 21:29:18,938 - ml_training_1958286911264 - DEBUG - Batch 50/119: Loss=1.7927, Acc=20.10%
2025-08-15 21:29:19,226 - ml_training_1958286911264 - DEBUG - Batch 100/119: Loss=1.6341, Acc=33.42%
2025-08-15 21:29:19,326 - ml_training_1958286911264 - INFO - Timer 'train_epoch_1': 1.0386 seconds
2025-08-15 21:29:19,327 - ml_training_1958286911264 - DEBUG - Timer started: val_epoch_1
2025-08-15 21:29:19,363 - ml_training_1958286911264 - INFO - Timer 'val_epoch_1': 0.0352 seconds
2025-08-15 21:29:19,364 - ml_training_1958286911264 - INFO - Epoch   1 | Train Loss: 1.9649 | Train Acc: 36.56% | Val Loss: 1.0913 | Val Acc: 88.15% | LR: 1.00e-03
2025-08-15 21:29:19,391 - ml_training_1958286911264 - INFO - Checkpoint saved at epoch 1
2025-08-15 21:29:19,392 - ml_training_1958286911264 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:29:19,392 - ml_training_1958286911264 - INFO - Checkpoint metrics: {'val_acc': 88.14814814814815, 'val_loss': 1.09126874629189}
2025-08-15 21:29:19,392 - ml_training_1958286911264 - DEBUG - Timer started: train_epoch_2
2025-08-15 21:29:19,401 - ml_training_1958286911264 - DEBUG - Batch 0/119: Loss=1.2738, Acc=81.25%
2025-08-15 21:29:19,799 - ml_training_1958286911264 - DEBUG - Batch 50/119: Loss=1.0894, Acc=66.30%
2025-08-15 21:29:20,149 - ml_training_1958286911264 - DEBUG - Batch 100/119: Loss=1.0716, Acc=71.23%
2025-08-15 21:29:20,266 - ml_training_1958286911264 - INFO - Timer 'train_epoch_2': 0.8739 seconds
2025-08-15 21:29:20,266 - ml_training_1958286911264 - DEBUG - Timer started: val_epoch_2
2025-08-15 21:29:20,305 - ml_training_1958286911264 - INFO - Timer 'val_epoch_2': 0.0396 seconds
2025-08-15 21:29:20,306 - ml_training_1958286911264 - INFO - Epoch   2 | Train Loss: 1.1979 | Train Acc: 72.65% | Val Loss: 0.7607 | Val Acc: 94.07% | LR: 1.00e-03
2025-08-15 21:29:20,327 - ml_training_1958286911264 - INFO - Checkpoint saved at epoch 2
2025-08-15 21:29:20,327 - ml_training_1958286911264 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:29:20,327 - ml_training_1958286911264 - INFO - Checkpoint metrics: {'val_acc': 94.07407407407408, 'val_loss': 0.7606645787463469}
2025-08-15 21:29:20,327 - ml_training_1958286911264 - DEBUG - Timer started: train_epoch_3
2025-08-15 21:29:20,337 - ml_training_1958286911264 - DEBUG - Batch 0/119: Loss=1.1729, Acc=81.25%
2025-08-15 21:29:20,741 - ml_training_1958286911264 - DEBUG - Batch 50/119: Loss=1.0443, Acc=83.33%
2025-08-15 21:29:21,034 - ml_training_1958286911264 - DEBUG - Batch 100/119: Loss=1.1272, Acc=81.93%
2025-08-15 21:29:21,147 - ml_training_1958286911264 - INFO - Timer 'train_epoch_3': 0.8200 seconds
2025-08-15 21:29:21,147 - ml_training_1958286911264 - DEBUG - Timer started: val_epoch_3
2025-08-15 21:29:21,197 - ml_training_1958286911264 - INFO - Timer 'val_epoch_3': 0.0507 seconds
2025-08-15 21:29:21,197 - ml_training_1958286911264 - INFO - Epoch   3 | Train Loss: 0.9920 | Train Acc: 82.70% | Val Loss: 0.6831 | Val Acc: 95.19% | LR: 1.00e-03
2025-08-15 21:29:21,209 - ml_training_1958286911264 - INFO - Checkpoint saved at epoch 3
2025-08-15 21:29:21,209 - ml_training_1958286911264 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:29:21,209 - ml_training_1958286911264 - INFO - Checkpoint metrics: {'val_acc': 95.18518518518519, 'val_loss': 0.6831361335866591}
2025-08-15 21:29:21,209 - ml_training_1958286911264 - DEBUG - Timer started: train_epoch_4
2025-08-15 21:29:21,214 - ml_training_1958286911264 - DEBUG - Batch 0/119: Loss=1.1469, Acc=81.25%
2025-08-15 21:29:21,520 - ml_training_1958286911264 - DEBUG - Batch 50/119: Loss=0.9174, Acc=88.97%
2025-08-15 21:29:21,859 - ml_training_1958286911264 - DEBUG - Batch 100/119: Loss=0.8743, Acc=88.74%
2025-08-15 21:29:21,980 - ml_training_1958286911264 - INFO - Timer 'train_epoch_4': 0.7703 seconds
2025-08-15 21:29:21,981 - ml_training_1958286911264 - DEBUG - Timer started: val_epoch_4
2025-08-15 21:29:22,010 - ml_training_1958286911264 - INFO - Timer 'val_epoch_4': 0.0296 seconds
2025-08-15 21:29:22,010 - ml_training_1958286911264 - INFO - Epoch   4 | Train Loss: 0.8917 | Train Acc: 88.36% | Val Loss: 0.6423 | Val Acc: 97.41% | LR: 1.00e-03
2025-08-15 21:29:22,023 - ml_training_1958286911264 - INFO - Checkpoint saved at epoch 4
2025-08-15 21:29:22,023 - ml_training_1958286911264 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:29:22,023 - ml_training_1958286911264 - INFO - Checkpoint metrics: {'val_acc': 97.4074074074074, 'val_loss': 0.642321898656733}
2025-08-15 21:29:22,023 - ml_training_1958286911264 - DEBUG - Timer started: train_epoch_5
2025-08-15 21:29:22,029 - ml_training_1958286911264 - DEBUG - Batch 0/119: Loss=0.8598, Acc=93.75%
2025-08-15 21:29:22,314 - ml_training_1958286911264 - DEBUG - Batch 50/119: Loss=0.7207, Acc=87.75%
2025-08-15 21:29:22,613 - ml_training_1958286911264 - DEBUG - Batch 100/119: Loss=1.1927, Acc=89.79%
2025-08-15 21:29:22,716 - ml_training_1958286911264 - INFO - Timer 'train_epoch_5': 0.6926 seconds
2025-08-15 21:29:22,716 - ml_training_1958286911264 - DEBUG - Timer started: val_epoch_5
2025-08-15 21:29:22,743 - ml_training_1958286911264 - INFO - Timer 'val_epoch_5': 0.0276 seconds
2025-08-15 21:29:22,743 - ml_training_1958286911264 - INFO - Epoch   5 | Train Loss: 0.8495 | Train Acc: 89.42% | Val Loss: 0.6113 | Val Acc: 97.41% | LR: 1.00e-03
2025-08-15 21:29:22,743 - ml_training_1958286911264 - INFO - Training completed. Evaluating on test set...
2025-08-15 21:29:22,767 - ml_training_1958286911264 - INFO - Loaded checkpoint from epoch 4
2025-08-15 21:29:22,767 - ml_training_1958286911264 - DEBUG - Timer started: test_evaluation
2025-08-15 21:29:22,832 - ml_training_1958286911264 - INFO - Timer 'test_evaluation': 0.0652 seconds
2025-08-15 21:29:22,843 - ml_training_1958286911264 - INFO - === TEST RESULTS ===
2025-08-15 21:29:22,843 - ml_training_1958286911264 - INFO - Test Accuracy: 0.9722
2025-08-15 21:29:22,843 - ml_training_1958286911264 - INFO - Test Loss: 0.6426
2025-08-15 21:29:22,843 - ml_training_1958286911264 - INFO - Classification Report:
2025-08-15 21:29:22,843 - ml_training_1958286911264 - INFO -                 precision    recall  f1-score   support
2025-08-15 21:29:22,843 - ml_training_1958286911264 - INFO -              0     0.9630    0.9630    0.9630        54
2025-08-15 21:29:22,843 - ml_training_1958286911264 - INFO -              1     0.9804    0.9259    0.9524        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              2     0.9310    1.0000    0.9643        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              3     1.0000    0.9074    0.9515        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              4     0.9474    1.0000    0.9730        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              5     0.9818    1.0000    0.9908        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              6     1.0000    0.9630    0.9811        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              7     0.9630    0.9630    0.9630        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              8     0.9643    1.0000    0.9818        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -              9     1.0000    1.0000    1.0000        54
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -       accuracy                         0.9722       540
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -      macro avg     0.9731    0.9722    0.9721       540
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO -   weighted avg     0.9731    0.9722    0.9721       540
2025-08-15 21:29:22,844 - ml_training_1958286911264 - INFO - === END TEST RESULTS ===
2025-08-15 21:29:24,163 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mfcc_classifier\training_history_mfcc_classifier_training_history.png
2025-08-15 21:29:24,776 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:29:24,776 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:29:25,946 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mfcc_classifier\confusion_matrix_mfcc_classifier_confusion_matrix.png
2025-08-15 21:29:25,947 - ml_training_1958286911264 - INFO - Visualizations generated successfully
2025-08-15 21:29:25,947 - ml_training_1958286911264 - INFO - Closing ML Training Logger
2025-08-15 21:29:25,949 - ml_training_1958286911264 - INFO - Metrics summary saved to: train_logs\metrics_summary_mfcc_classifier_20250815_212917.json
2025-08-15 21:29:25,950 - __main__ - INFO - Single pipeline training completed successfully
2025-08-15 21:29:25,950 - __main__ - INFO - Training script completed successfully
2025-08-15 21:29:49,598 - __main__ - INFO - Training configuration: {'pipelines': ['mfcc', 'mel_cnn', 'raw_cnn'], 'num_epochs': 10, 'batch_size': 32, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'scheduler_type': 'plateau', 'early_stopping_patience': 10, 'gradient_clipping': 1.0, 'save_frequency': 10, 'sample_rate': 8000, 'max_length': 8000}
2025-08-15 21:29:49,598 - __main__ - INFO - Loading dataset...
2025-08-15 21:29:49,598 - ml_training.data.dataset_loader - INFO - Loading and preparing digit dataset...
2025-08-15 21:29:49,634 - ml_training.data.dataset_loader - INFO - ffmpeg detected - will use for high-quality audio resampling
2025-08-15 21:29:49,634 - ml_training.data.dataset_loader - INFO - Initialized DataLoader - SR: 8000Hz, Max Length: 8000 samples
2025-08-15 21:29:49,634 - ml_training.data.dataset_loader - INFO - Loading Free Spoken Digit Dataset from HuggingFace...
2025-08-15 21:29:51,191 - ml_training.data.dataset_loader - INFO - Dataset loaded successfully
2025-08-15 21:29:51,191 - ml_training.data.dataset_loader - INFO - Available splits: ['train', 'test']
2025-08-15 21:29:51,191 - ml_training.data.dataset_loader - INFO - Train split size: 2700
2025-08-15 21:29:52,893 - ml_training.data.dataset_loader - INFO - Dataset sample structure: dict_keys(['audio', 'label'])
2025-08-15 21:29:52,893 - ml_training.data.dataset_loader - INFO - Audio info: sampling_rate=8000, array_shape=(5958,)
2025-08-15 21:29:52,893 - ml_training.data.dataset_loader - INFO - Label type: <class 'int'>, value: 0
2025-08-15 21:29:52,893 - ml_training.data.dataset_loader - INFO - Creating train/test/validation splits...
2025-08-15 21:29:52,893 - ml_training.data.dataset_loader - INFO - Processing 2700 samples from 'train' split
2025-08-15 21:29:52,928 - ml_training.data.dataset_loader - INFO - Processed 100/2700 samples
2025-08-15 21:29:52,961 - ml_training.data.dataset_loader - INFO - Processed 200/2700 samples
2025-08-15 21:29:52,993 - ml_training.data.dataset_loader - INFO - Processed 300/2700 samples
2025-08-15 21:29:53,028 - ml_training.data.dataset_loader - INFO - Processed 400/2700 samples
2025-08-15 21:29:53,059 - ml_training.data.dataset_loader - INFO - Processed 500/2700 samples
2025-08-15 21:29:53,091 - ml_training.data.dataset_loader - INFO - Processed 600/2700 samples
2025-08-15 21:29:53,122 - ml_training.data.dataset_loader - INFO - Processed 700/2700 samples
2025-08-15 21:29:53,152 - ml_training.data.dataset_loader - INFO - Processed 800/2700 samples
2025-08-15 21:29:53,184 - ml_training.data.dataset_loader - INFO - Processed 900/2700 samples
2025-08-15 21:29:53,217 - ml_training.data.dataset_loader - INFO - Processed 1000/2700 samples
2025-08-15 21:29:53,249 - ml_training.data.dataset_loader - INFO - Processed 1100/2700 samples
2025-08-15 21:29:53,282 - ml_training.data.dataset_loader - INFO - Processed 1200/2700 samples
2025-08-15 21:29:53,313 - ml_training.data.dataset_loader - INFO - Processed 1300/2700 samples
2025-08-15 21:29:53,346 - ml_training.data.dataset_loader - INFO - Processed 1400/2700 samples
2025-08-15 21:29:53,378 - ml_training.data.dataset_loader - INFO - Processed 1500/2700 samples
2025-08-15 21:29:53,409 - ml_training.data.dataset_loader - INFO - Processed 1600/2700 samples
2025-08-15 21:29:53,442 - ml_training.data.dataset_loader - INFO - Processed 1700/2700 samples
2025-08-15 21:29:53,474 - ml_training.data.dataset_loader - INFO - Processed 1800/2700 samples
2025-08-15 21:29:53,506 - ml_training.data.dataset_loader - INFO - Processed 1900/2700 samples
2025-08-15 21:29:53,538 - ml_training.data.dataset_loader - INFO - Processed 2000/2700 samples
2025-08-15 21:29:53,570 - ml_training.data.dataset_loader - INFO - Processed 2100/2700 samples
2025-08-15 21:29:53,601 - ml_training.data.dataset_loader - INFO - Processed 2200/2700 samples
2025-08-15 21:29:53,633 - ml_training.data.dataset_loader - INFO - Processed 2300/2700 samples
2025-08-15 21:29:53,666 - ml_training.data.dataset_loader - INFO - Processed 2400/2700 samples
2025-08-15 21:29:53,699 - ml_training.data.dataset_loader - INFO - Processed 2500/2700 samples
2025-08-15 21:29:53,731 - ml_training.data.dataset_loader - INFO - Processed 2600/2700 samples
2025-08-15 21:29:53,763 - ml_training.data.dataset_loader - INFO - Processed 2700/2700 samples
2025-08-15 21:29:53,798 - ml_training.data.dataset_loader - INFO - Audio data shape: (2700, 8000)
2025-08-15 21:29:53,798 - ml_training.data.dataset_loader - INFO - Labels shape: (2700,)
2025-08-15 21:29:53,798 - ml_training.data.dataset_loader - INFO - Unique labels: [0 1 2 3 4 5 6 7 8 9]
2025-08-15 21:29:53,799 - ml_training.data.dataset_loader - INFO - Label encoding: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}
2025-08-15 21:29:53,799 - ml_training.data.dataset_loader - INFO - Creating splits - Test: 20.0%, Val: 10.0%
2025-08-15 21:29:53,846 - ml_training.data.dataset_loader - INFO - Dataset splits created successfully:
2025-08-15 21:29:53,846 - ml_training.data.dataset_loader - INFO -   Train: 1890 samples
2025-08-15 21:29:53,846 - ml_training.data.dataset_loader - INFO -   Val: 270 samples
2025-08-15 21:29:53,847 - ml_training.data.dataset_loader - INFO -   Test: 540 samples
2025-08-15 21:29:53,847 - ml_training.data.dataset_loader - INFO -   Classes: 10 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
2025-08-15 21:29:53,854 - ml_training.data.dataset_loader - INFO - Validating dataset splits...
2025-08-15 21:29:53,854 - ml_training.data.dataset_loader - INFO - Dataset validation passed
2025-08-15 21:29:53,854 - ml_training.data.dataset_loader - INFO - Dataset preparation completed successfully
2025-08-15 21:29:53,859 - ml_training_1989262998224 - INFO - ML Training Logger initialized - Log file: train_logs\comparison_study_20250815_212953.log
2025-08-15 21:29:53,859 - ml_training_1989262998224 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:29:53,859 - ml_training_1989262998224 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:29:53,859 - ml_training_1989262998224 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:29:53,859 - ml_training_1989262998224 - INFO - NumPy Version: 1.26.4
2025-08-15 21:29:53,859 - ml_training_1989262998224 - INFO - Librosa Version: 0.10.2
2025-08-15 21:29:53,884 - ml_training_1989262998224 - INFO - CUDA Available: Yes
2025-08-15 21:29:53,886 - ml_training_1989262998224 - INFO - CUDA Version: 12.1
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - === END SYSTEM INFO ===
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - === DATASET INFORMATION ===
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - total_samples: 2700
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - train_samples: 1890
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - val_samples: 270
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - test_samples: 540
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - sample_rate: 8000
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - max_length: 8000
2025-08-15 21:29:53,888 - ml_training_1989262998224 - INFO - num_classes: 10
2025-08-15 21:29:53,889 - ml_training_1989262998224 - INFO - class_names: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
2025-08-15 21:29:53,889 - ml_training_1989262998224 - INFO - audio_shape: (2700, 8000)
2025-08-15 21:29:53,889 - ml_training_1989262998224 - INFO - mean_sample_rate: 8000.0
2025-08-15 21:29:53,889 - ml_training_1989262998224 - INFO - std_sample_rate: 0.0
2025-08-15 21:29:53,889 - ml_training_1989262998224 - INFO - === END DATASET INFO ===
2025-08-15 21:29:53,889 - ml_training_1989262998224 - INFO - Closing ML Training Logger
2025-08-15 21:29:53,889 - ml_training_1989262998224 - INFO - Metrics summary saved to: train_logs\metrics_summary_comparison_study_20250815_212953.json
2025-08-15 21:29:53,890 - __main__ - INFO - Training mfcc pipeline...
2025-08-15 21:29:53,890 - ml_training.pipelines.mfcc_pipeline - INFO - Setting up MFCC pipeline...
2025-08-15 21:29:53,890 - ml_training.pipelines.mfcc_pipeline - INFO - Fitting feature scaler on training data...
2025-08-15 21:29:59,298 - ml_training.pipelines.mfcc_pipeline - INFO - Feature scaling statistics:
2025-08-15 21:29:59,299 - ml_training.pipelines.mfcc_pipeline - INFO -   Mean: [-509.94391019   24.72415496    5.40042514    1.75478205  -10.29276815]... (first 5)
2025-08-15 21:29:59,299 - ml_training.pipelines.mfcc_pipeline - INFO -   Std: [47.04976658 16.63563144  9.60469901  8.82461158  7.35149315]... (first 5)
2025-08-15 21:29:59,299 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 1890 samples...
2025-08-15 21:30:04,709 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (1890, 156)
2025-08-15 21:30:04,709 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 540 samples...
2025-08-15 21:30:06,187 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (540, 156)
2025-08-15 21:30:06,187 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 270 samples...
2025-08-15 21:30:06,921 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (270, 156)
2025-08-15 21:30:06,924 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Classifier initialized:
2025-08-15 21:30:06,924 - ml_training.pipelines.mfcc_pipeline - INFO -   Architecture: 156 -> 256 -> 128 -> 64 -> 10
2025-08-15 21:30:06,924 - ml_training.pipelines.mfcc_pipeline - INFO -   Total parameters: 82,890
2025-08-15 21:30:06,924 - ml_training.pipelines.mfcc_pipeline - INFO -   Dropout: 0.3
2025-08-15 21:30:07,002 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC pipeline setup completed:
2025-08-15 21:30:07,002 - ml_training.pipelines.mfcc_pipeline - INFO -   Device: cuda
2025-08-15 21:30:07,002 - ml_training.pipelines.mfcc_pipeline - INFO -   Train samples: 1890
2025-08-15 21:30:07,002 - ml_training.pipelines.mfcc_pipeline - INFO -   Val samples: 270
2025-08-15 21:30:07,002 - ml_training.pipelines.mfcc_pipeline - INFO -   Test samples: 540
2025-08-15 21:30:07,002 - ml_training.pipelines.mfcc_pipeline - INFO -   Batch size: 32
2025-08-15 21:30:07,002 - ml_training.pipelines.mfcc_pipeline - INFO -   Feature dimension: 156
2025-08-15 21:30:07,008 - ml_training_1989354270656 - INFO - ML Training Logger initialized - Log file: train_logs\mfcc_classifier_20250815_213007.log
2025-08-15 21:30:07,008 - ml_training_1989354270656 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:30:07,008 - ml_training_1989354270656 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:30:07,008 - ml_training_1989354270656 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:30:07,008 - ml_training_1989354270656 - INFO - NumPy Version: 1.26.4
2025-08-15 21:30:07,008 - ml_training_1989354270656 - INFO - Librosa Version: 0.10.2
2025-08-15 21:30:07,009 - ml_training_1989354270656 - INFO - CUDA Available: Yes
2025-08-15 21:30:07,009 - ml_training_1989354270656 - INFO - CUDA Version: 12.1
2025-08-15 21:30:07,009 - ml_training_1989354270656 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:30:07,009 - ml_training_1989354270656 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:30:07,009 - ml_training_1989354270656 - INFO - === END SYSTEM INFO ===
2025-08-15 21:30:07,111 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\mfcc_classifier
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO - Trainer initialized for mfcc_classifier
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO - === MFCC_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO - Total Parameters: 82,890
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO - Trainable Parameters: 82,890
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO - Non-trainable Parameters: 0
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO - Model Architecture:
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO -   network.0: Linear(in_features=156, out_features=256, bias=True)
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO -   network.1: BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO -   network.2: ReLU(inplace=True)
2025-08-15 21:30:07,111 - ml_training_1989354270656 - INFO -   network.3: Dropout(p=0.3, inplace=False)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.4: Linear(in_features=256, out_features=128, bias=True)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.5: BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.6: ReLU(inplace=True)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.7: Dropout(p=0.3, inplace=False)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.8: Linear(in_features=128, out_features=64, bias=True)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.9: BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.10: ReLU(inplace=True)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.11: Dropout(p=0.3, inplace=False)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO -   network.12: Linear(in_features=64, out_features=10, bias=True)
2025-08-15 21:30:07,112 - ml_training_1989354270656 - INFO - === END MFCC_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:30:08,205 - ml_training_1989354270656 - INFO - === EXPERIMENT CONFIGURATION ===
2025-08-15 21:30:08,205 - ml_training_1989354270656 - INFO - learning_rate: 0.001
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - weight_decay: 0.0001
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - scheduler_type: plateau
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - early_stopping_patience: 10
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - gradient_clipping: 1.0
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - mixed_precision: True
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - optimizer: Adam
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - loss_function: CrossEntropyLoss with label smoothing
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - device: cuda
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - Configuration saved to: train_logs\config_mfcc_classifier_20250815_213007.json
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - === END CONFIGURATION ===
2025-08-15 21:30:08,206 - ml_training_1989354270656 - INFO - Starting training for 10 epochs
2025-08-15 21:30:08,206 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_1
2025-08-15 21:30:08,545 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=3.0815, Acc=3.12%
2025-08-15 21:30:08,849 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=1.4776, Acc=29.17%
2025-08-15 21:30:08,901 - ml_training_1989354270656 - INFO - Timer 'train_epoch_1': 0.6950 seconds
2025-08-15 21:30:08,902 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_1
2025-08-15 21:30:08,919 - ml_training_1989354270656 - INFO - Timer 'val_epoch_1': 0.0171 seconds
2025-08-15 21:30:08,919 - ml_training_1989354270656 - INFO - Epoch   1 | Train Loss: 2.0559 | Train Acc: 32.12% | Val Loss: 1.1830 | Val Acc: 86.30% | LR: 1.00e-03
2025-08-15 21:30:08,933 - ml_training_1989354270656 - INFO - Checkpoint saved at epoch 1
2025-08-15 21:30:08,933 - ml_training_1989354270656 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:30:08,933 - ml_training_1989354270656 - INFO - Checkpoint metrics: {'val_acc': 86.29629629629629, 'val_loss': 1.1830034918255277}
2025-08-15 21:30:08,934 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_2
2025-08-15 21:30:08,941 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=1.4457, Acc=68.75%
2025-08-15 21:30:09,256 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=1.1610, Acc=67.46%
2025-08-15 21:30:09,313 - ml_training_1989354270656 - INFO - Timer 'train_epoch_2': 0.3792 seconds
2025-08-15 21:30:09,313 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_2
2025-08-15 21:30:09,330 - ml_training_1989354270656 - INFO - Timer 'val_epoch_2': 0.0163 seconds
2025-08-15 21:30:09,330 - ml_training_1989354270656 - INFO - Epoch   2 | Train Loss: 1.2866 | Train Acc: 68.94% | Val Loss: 0.8345 | Val Acc: 93.70% | LR: 1.00e-03
2025-08-15 21:30:09,342 - ml_training_1989354270656 - INFO - Checkpoint saved at epoch 2
2025-08-15 21:30:09,342 - ml_training_1989354270656 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:30:09,342 - ml_training_1989354270656 - INFO - Checkpoint metrics: {'val_acc': 93.70370370370371, 'val_loss': 0.8344886501630148}
2025-08-15 21:30:09,342 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_3
2025-08-15 21:30:09,350 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=1.0823, Acc=81.25%
2025-08-15 21:30:09,666 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.8737, Acc=83.64%
2025-08-15 21:30:09,719 - ml_training_1989354270656 - INFO - Timer 'train_epoch_3': 0.3768 seconds
2025-08-15 21:30:09,719 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_3
2025-08-15 21:30:09,738 - ml_training_1989354270656 - INFO - Timer 'val_epoch_3': 0.0193 seconds
2025-08-15 21:30:09,738 - ml_training_1989354270656 - INFO - Epoch   3 | Train Loss: 0.9895 | Train Acc: 83.60% | Val Loss: 0.6979 | Val Acc: 95.93% | LR: 1.00e-03
2025-08-15 21:30:09,752 - ml_training_1989354270656 - INFO - Checkpoint saved at epoch 3
2025-08-15 21:30:09,753 - ml_training_1989354270656 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:30:09,753 - ml_training_1989354270656 - INFO - Checkpoint metrics: {'val_acc': 95.92592592592592, 'val_loss': 0.6979163951343961}
2025-08-15 21:30:09,753 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_4
2025-08-15 21:30:09,761 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=0.8943, Acc=87.50%
2025-08-15 21:30:10,059 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.7421, Acc=88.42%
2025-08-15 21:30:10,128 - ml_training_1989354270656 - INFO - Timer 'train_epoch_4': 0.3750 seconds
2025-08-15 21:30:10,129 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_4
2025-08-15 21:30:10,160 - ml_training_1989354270656 - INFO - Timer 'val_epoch_4': 0.0311 seconds
2025-08-15 21:30:10,160 - ml_training_1989354270656 - INFO - Epoch   4 | Train Loss: 0.8792 | Train Acc: 88.73% | Val Loss: 0.6597 | Val Acc: 96.30% | LR: 1.00e-03
2025-08-15 21:30:10,178 - ml_training_1989354270656 - INFO - Checkpoint saved at epoch 4
2025-08-15 21:30:10,178 - ml_training_1989354270656 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:30:10,178 - ml_training_1989354270656 - INFO - Checkpoint metrics: {'val_acc': 96.29629629629629, 'val_loss': 0.6597342623604668}
2025-08-15 21:30:10,178 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_5
2025-08-15 21:30:10,184 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=0.7792, Acc=93.75%
2025-08-15 21:30:10,511 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.7924, Acc=92.22%
2025-08-15 21:30:10,566 - ml_training_1989354270656 - INFO - Timer 'train_epoch_5': 0.3878 seconds
2025-08-15 21:30:10,566 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_5
2025-08-15 21:30:10,584 - ml_training_1989354270656 - INFO - Timer 'val_epoch_5': 0.0186 seconds
2025-08-15 21:30:10,585 - ml_training_1989354270656 - INFO - Epoch   5 | Train Loss: 0.8289 | Train Acc: 92.17% | Val Loss: 0.6306 | Val Acc: 96.67% | LR: 1.00e-03
2025-08-15 21:30:10,600 - ml_training_1989354270656 - INFO - Checkpoint saved at epoch 5
2025-08-15 21:30:10,600 - ml_training_1989354270656 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:30:10,600 - ml_training_1989354270656 - INFO - Checkpoint metrics: {'val_acc': 96.66666666666667, 'val_loss': 0.6305984391106499}
2025-08-15 21:30:10,600 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_6
2025-08-15 21:30:10,608 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=0.7909, Acc=93.75%
2025-08-15 21:30:10,907 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.7923, Acc=92.59%
2025-08-15 21:30:10,953 - ml_training_1989354270656 - INFO - Timer 'train_epoch_6': 0.3536 seconds
2025-08-15 21:30:10,954 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_6
2025-08-15 21:30:10,972 - ml_training_1989354270656 - INFO - Timer 'val_epoch_6': 0.0176 seconds
2025-08-15 21:30:10,972 - ml_training_1989354270656 - INFO - Epoch   6 | Train Loss: 0.8177 | Train Acc: 92.54% | Val Loss: 0.6150 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:30:10,986 - ml_training_1989354270656 - INFO - Checkpoint saved at epoch 6
2025-08-15 21:30:10,986 - ml_training_1989354270656 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:30:10,987 - ml_training_1989354270656 - INFO - Checkpoint metrics: {'val_acc': 97.77777777777777, 'val_loss': 0.6150483224127028}
2025-08-15 21:30:10,987 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_7
2025-08-15 21:30:10,994 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=0.7559, Acc=93.75%
2025-08-15 21:30:11,332 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.7883, Acc=94.73%
2025-08-15 21:30:11,384 - ml_training_1989354270656 - INFO - Timer 'train_epoch_7': 0.3971 seconds
2025-08-15 21:30:11,384 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_7
2025-08-15 21:30:11,402 - ml_training_1989354270656 - INFO - Timer 'val_epoch_7': 0.0172 seconds
2025-08-15 21:30:11,403 - ml_training_1989354270656 - INFO - Epoch   7 | Train Loss: 0.7503 | Train Acc: 94.55% | Val Loss: 0.6149 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:30:11,403 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_8
2025-08-15 21:30:11,408 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=0.7666, Acc=93.75%
2025-08-15 21:30:11,714 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.7183, Acc=94.98%
2025-08-15 21:30:11,771 - ml_training_1989354270656 - INFO - Timer 'train_epoch_8': 0.3686 seconds
2025-08-15 21:30:11,771 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_8
2025-08-15 21:30:11,804 - ml_training_1989354270656 - INFO - Timer 'val_epoch_8': 0.0330 seconds
2025-08-15 21:30:11,805 - ml_training_1989354270656 - INFO - Epoch   8 | Train Loss: 0.7528 | Train Acc: 94.97% | Val Loss: 0.6199 | Val Acc: 96.67% | LR: 1.00e-03
2025-08-15 21:30:11,805 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_9
2025-08-15 21:30:11,813 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=0.7133, Acc=100.00%
2025-08-15 21:30:12,113 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.6884, Acc=96.20%
2025-08-15 21:30:12,174 - ml_training_1989354270656 - INFO - Timer 'train_epoch_9': 0.3691 seconds
2025-08-15 21:30:12,174 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_9
2025-08-15 21:30:12,200 - ml_training_1989354270656 - INFO - Timer 'val_epoch_9': 0.0260 seconds
2025-08-15 21:30:12,201 - ml_training_1989354270656 - INFO - Epoch   9 | Train Loss: 0.7289 | Train Acc: 95.93% | Val Loss: 0.5999 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:30:12,201 - ml_training_1989354270656 - DEBUG - Timer started: train_epoch_10
2025-08-15 21:30:12,209 - ml_training_1989354270656 - DEBUG - Batch 0/60: Loss=0.6397, Acc=100.00%
2025-08-15 21:30:12,616 - ml_training_1989354270656 - DEBUG - Batch 50/60: Loss=0.7505, Acc=97.12%
2025-08-15 21:30:12,681 - ml_training_1989354270656 - INFO - Timer 'train_epoch_10': 0.4799 seconds
2025-08-15 21:30:12,682 - ml_training_1989354270656 - DEBUG - Timer started: val_epoch_10
2025-08-15 21:30:12,703 - ml_training_1989354270656 - INFO - Timer 'val_epoch_10': 0.0211 seconds
2025-08-15 21:30:12,704 - ml_training_1989354270656 - INFO - Epoch  10 | Train Loss: 0.6989 | Train Acc: 97.09% | Val Loss: 0.5997 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:30:12,714 - ml_training_1989354270656 - INFO - Training completed. Evaluating on test set...
2025-08-15 21:30:12,751 - ml_training_1989354270656 - INFO - Loaded checkpoint from epoch 6
2025-08-15 21:30:12,751 - ml_training_1989354270656 - DEBUG - Timer started: test_evaluation
2025-08-15 21:30:12,814 - ml_training_1989354270656 - INFO - Timer 'test_evaluation': 0.0636 seconds
2025-08-15 21:30:12,823 - ml_training_1989354270656 - INFO - === TEST RESULTS ===
2025-08-15 21:30:12,823 - ml_training_1989354270656 - INFO - Test Accuracy: 0.9759
2025-08-15 21:30:12,823 - ml_training_1989354270656 - INFO - Test Loss: 0.6259
2025-08-15 21:30:12,823 - ml_training_1989354270656 - INFO - Classification Report:
2025-08-15 21:30:12,823 - ml_training_1989354270656 - INFO -                 precision    recall  f1-score   support
2025-08-15 21:30:12,823 - ml_training_1989354270656 - INFO -              0     1.0000    0.9444    0.9714        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              1     0.9444    0.9444    0.9444        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              2     0.8710    1.0000    0.9310        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              3     1.0000    0.9259    0.9615        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              4     1.0000    1.0000    1.0000        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              5     0.9643    1.0000    0.9818        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              6     1.0000    1.0000    1.0000        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              7     1.0000    0.9630    0.9811        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              8     1.0000    1.0000    1.0000        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -              9     1.0000    0.9815    0.9907        54
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -       accuracy                         0.9759       540
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -      macro avg     0.9780    0.9759    0.9762       540
2025-08-15 21:30:12,825 - ml_training_1989354270656 - INFO -   weighted avg     0.9780    0.9759    0.9762       540
2025-08-15 21:30:12,826 - ml_training_1989354270656 - INFO - === END TEST RESULTS ===
2025-08-15 21:30:14,123 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mfcc_classifier\training_history_mfcc_classifier_training_history.png
2025-08-15 21:30:14,816 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:30:14,816 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:30:16,036 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mfcc_classifier\confusion_matrix_mfcc_classifier_confusion_matrix.png
2025-08-15 21:30:16,036 - ml_training_1989354270656 - INFO - Visualizations generated successfully
2025-08-15 21:30:16,036 - ml_training_1989354270656 - INFO - Closing ML Training Logger
2025-08-15 21:30:16,038 - ml_training_1989354270656 - INFO - Metrics summary saved to: train_logs\metrics_summary_mfcc_classifier_20250815_213007.json
2025-08-15 21:30:16,038 - __main__ - INFO - mfcc training completed:
2025-08-15 21:30:16,038 - __main__ - INFO -   Best val accuracy: 97.7778
2025-08-15 21:30:16,038 - __main__ - INFO -   Test accuracy: 0.9759
2025-08-15 21:30:16,039 - __main__ - INFO - Training mel_cnn pipeline...
2025-08-15 21:30:16,039 - ml_training.pipelines.mel_cnn_pipeline - INFO - Setting up Mel Spectrogram CNN pipeline...
2025-08-15 21:30:16,059 - ml_training.pipelines.mel_cnn_pipeline - INFO - Mel Spectrogram Extractor initialized:
2025-08-15 21:30:16,059 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Expected output shape: (64, 51)
2025-08-15 21:30:16,059 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Device: cuda
2025-08-15 21:30:16,059 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Frequency range: 0-4000 Hz
2025-08-15 21:30:16,059 - ml_training.pipelines.mel_cnn_pipeline - INFO - Precomputing mel spectrograms for 1890 samples...
2025-08-15 21:30:16,740 - ml_training.pipelines.mel_cnn_pipeline - INFO - Spectrogram precomputation completed
2025-08-15 21:30:16,740 - ml_training.pipelines.mel_cnn_pipeline - INFO - Precomputing mel spectrograms for 540 samples...
2025-08-15 21:30:16,816 - ml_training.pipelines.mel_cnn_pipeline - INFO - Spectrogram precomputation completed
2025-08-15 21:30:16,817 - ml_training.pipelines.mel_cnn_pipeline - INFO - Precomputing mel spectrograms for 270 samples...
2025-08-15 21:30:16,858 - ml_training.pipelines.mel_cnn_pipeline - INFO - Spectrogram precomputation completed
2025-08-15 21:30:16,868 - ml_training.pipelines.mel_cnn_pipeline - INFO - Mel Spectrogram CNN initialized:
2025-08-15 21:30:16,868 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Input shape: (1, 64, 51)
2025-08-15 21:30:16,868 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Architecture: Conv(32->64->128->256) -> Global Pool -> FC(512->256->10)
2025-08-15 21:30:16,868 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Total parameters: 653,802
2025-08-15 21:30:16,871 - ml_training.pipelines.mel_cnn_pipeline - INFO - Mel CNN pipeline setup completed:
2025-08-15 21:30:16,871 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Device: cuda
2025-08-15 21:30:16,871 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Train samples: 1890
2025-08-15 21:30:16,871 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Val samples: 270
2025-08-15 21:30:16,871 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Test samples: 540
2025-08-15 21:30:16,871 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Batch size: 16
2025-08-15 21:30:16,871 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Spectrogram shape: (64, 51)
2025-08-15 21:30:16,872 - ml_training_1991366041456 - INFO - ML Training Logger initialized - Log file: train_logs\mel_cnn_classifier_20250815_213016.log
2025-08-15 21:30:16,873 - ml_training_1991366041456 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:30:16,873 - ml_training_1991366041456 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:30:16,873 - ml_training_1991366041456 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:30:16,873 - ml_training_1991366041456 - INFO - NumPy Version: 1.26.4
2025-08-15 21:30:16,873 - ml_training_1991366041456 - INFO - Librosa Version: 0.10.2
2025-08-15 21:30:16,873 - ml_training_1991366041456 - INFO - CUDA Available: Yes
2025-08-15 21:30:16,873 - ml_training_1991366041456 - INFO - CUDA Version: 12.1
2025-08-15 21:30:16,874 - ml_training_1991366041456 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:30:16,874 - ml_training_1991366041456 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:30:16,874 - ml_training_1991366041456 - INFO - === END SYSTEM INFO ===
2025-08-15 21:30:16,876 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\mel_cnn_classifier
2025-08-15 21:30:16,876 - ml_training_1991366041456 - INFO - Trainer initialized for mel_cnn_classifier
2025-08-15 21:30:16,876 - ml_training_1991366041456 - INFO - === MEL_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:30:16,876 - ml_training_1991366041456 - INFO - Total Parameters: 653,802
2025-08-15 21:30:16,876 - ml_training_1991366041456 - INFO - Trainable Parameters: 653,802
2025-08-15 21:30:16,876 - ml_training_1991366041456 - INFO - Non-trainable Parameters: 0
2025-08-15 21:30:16,876 - ml_training_1991366041456 - INFO - Model Architecture:
2025-08-15 21:30:16,876 - ml_training_1991366041456 - INFO -   conv1: Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   conv2: Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   conv3: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   conv4: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   bn1: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   bn3: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   bn4: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   pool: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   dropout2d: Dropout2d(p=0.2, inplace=False)
2025-08-15 21:30:16,877 - ml_training_1991366041456 - INFO -   dropout: Dropout(p=0.3, inplace=False)
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO -   global_pool: AdaptiveAvgPool2d(output_size=(1, 1))
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO -   fc1: Linear(in_features=256, out_features=512, bias=True)
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO -   fc2: Linear(in_features=512, out_features=256, bias=True)
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO -   fc3: Linear(in_features=256, out_features=10, bias=True)
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO - === END MEL_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO - === EXPERIMENT CONFIGURATION ===
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO - learning_rate: 0.001
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO - weight_decay: 0.0001
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO - scheduler_type: plateau
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO - early_stopping_patience: 10
2025-08-15 21:30:16,878 - ml_training_1991366041456 - INFO - gradient_clipping: 1.0
2025-08-15 21:30:16,879 - ml_training_1991366041456 - INFO - mixed_precision: True
2025-08-15 21:30:16,879 - ml_training_1991366041456 - INFO - optimizer: Adam
2025-08-15 21:30:16,879 - ml_training_1991366041456 - INFO - loss_function: CrossEntropyLoss with label smoothing
2025-08-15 21:30:16,879 - ml_training_1991366041456 - INFO - device: cuda
2025-08-15 21:30:16,879 - ml_training_1991366041456 - INFO - Configuration saved to: train_logs\config_mel_cnn_classifier_20250815_213016.json
2025-08-15 21:30:16,879 - ml_training_1991366041456 - INFO - === END CONFIGURATION ===
2025-08-15 21:30:16,880 - ml_training_1991366041456 - INFO - Starting training for 10 epochs
2025-08-15 21:30:16,880 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_1
2025-08-15 21:30:17,612 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=2.7192, Acc=6.25%
2025-08-15 21:30:18,246 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=2.4031, Acc=10.42%
2025-08-15 21:30:18,975 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=2.3254, Acc=10.02%
2025-08-15 21:30:19,292 - ml_training_1991366041456 - INFO - Timer 'train_epoch_1': 2.4117 seconds
2025-08-15 21:30:19,292 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_1
2025-08-15 21:30:19,380 - ml_training_1991366041456 - INFO - Timer 'val_epoch_1': 0.0885 seconds
2025-08-15 21:30:19,380 - ml_training_1991366041456 - INFO - Epoch   1 | Train Loss: 2.3781 | Train Acc: 10.48% | Val Loss: 2.2180 | Val Acc: 27.41% | LR: 1.00e-03
2025-08-15 21:30:19,423 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 1
2025-08-15 21:30:19,423 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:19,423 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 27.40740740740741, 'val_loss': 2.2180135250091553}
2025-08-15 21:30:19,424 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_2
2025-08-15 21:30:19,437 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=2.2403, Acc=18.75%
2025-08-15 21:30:20,111 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=2.1382, Acc=15.32%
2025-08-15 21:30:20,757 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=2.0152, Acc=16.58%
2025-08-15 21:30:20,984 - ml_training_1991366041456 - INFO - Timer 'train_epoch_2': 1.5607 seconds
2025-08-15 21:30:20,986 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_2
2025-08-15 21:30:21,045 - ml_training_1991366041456 - INFO - Timer 'val_epoch_2': 0.0590 seconds
2025-08-15 21:30:21,045 - ml_training_1991366041456 - INFO - Epoch   2 | Train Loss: 2.2207 | Train Acc: 17.25% | Val Loss: 2.0297 | Val Acc: 26.67% | LR: 1.00e-03
2025-08-15 21:30:21,045 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_3
2025-08-15 21:30:21,057 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=2.0969, Acc=31.25%
2025-08-15 21:30:21,702 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=2.2767, Acc=24.14%
2025-08-15 21:30:22,328 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=2.2477, Acc=24.81%
2025-08-15 21:30:22,608 - ml_training_1991366041456 - INFO - Timer 'train_epoch_3': 1.5628 seconds
2025-08-15 21:30:22,609 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_3
2025-08-15 21:30:22,696 - ml_training_1991366041456 - INFO - Timer 'val_epoch_3': 0.0867 seconds
2025-08-15 21:30:22,696 - ml_training_1991366041456 - INFO - Epoch   3 | Train Loss: 2.0994 | Train Acc: 25.45% | Val Loss: 1.8818 | Val Acc: 33.70% | LR: 1.00e-03
2025-08-15 21:30:22,739 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 3
2025-08-15 21:30:22,740 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:22,740 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 33.7037037037037, 'val_loss': 1.881793597165276}
2025-08-15 21:30:22,740 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_4
2025-08-15 21:30:22,753 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=2.1103, Acc=31.25%
2025-08-15 21:30:23,386 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=2.1511, Acc=26.72%
2025-08-15 21:30:24,073 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=1.8639, Acc=28.03%
2025-08-15 21:30:24,312 - ml_training_1991366041456 - INFO - Timer 'train_epoch_4': 1.5724 seconds
2025-08-15 21:30:24,313 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_4
2025-08-15 21:30:24,373 - ml_training_1991366041456 - INFO - Timer 'val_epoch_4': 0.0599 seconds
2025-08-15 21:30:24,374 - ml_training_1991366041456 - INFO - Epoch   4 | Train Loss: 2.0079 | Train Acc: 28.68% | Val Loss: 1.7668 | Val Acc: 45.56% | LR: 1.00e-03
2025-08-15 21:30:24,412 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 4
2025-08-15 21:30:24,412 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:24,413 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 45.55555555555556, 'val_loss': 1.766837807262645}
2025-08-15 21:30:24,413 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_5
2025-08-15 21:30:24,430 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=1.7661, Acc=50.00%
2025-08-15 21:30:25,091 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=2.0874, Acc=33.09%
2025-08-15 21:30:25,737 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=1.8401, Acc=34.22%
2025-08-15 21:30:25,973 - ml_training_1991366041456 - INFO - Timer 'train_epoch_5': 1.5601 seconds
2025-08-15 21:30:25,974 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_5
2025-08-15 21:30:26,049 - ml_training_1991366041456 - INFO - Timer 'val_epoch_5': 0.0749 seconds
2025-08-15 21:30:26,050 - ml_training_1991366041456 - INFO - Epoch   5 | Train Loss: 1.8964 | Train Acc: 34.60% | Val Loss: 1.6879 | Val Acc: 46.67% | LR: 1.00e-03
2025-08-15 21:30:26,091 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 5
2025-08-15 21:30:26,091 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:26,091 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 46.666666666666664, 'val_loss': 1.6879243289723116}
2025-08-15 21:30:26,091 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_6
2025-08-15 21:30:26,104 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=1.9285, Acc=25.00%
2025-08-15 21:30:26,711 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=1.6367, Acc=40.32%
2025-08-15 21:30:27,386 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=1.6731, Acc=42.14%
2025-08-15 21:30:27,641 - ml_training_1991366041456 - INFO - Timer 'train_epoch_6': 1.5492 seconds
2025-08-15 21:30:27,641 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_6
2025-08-15 21:30:27,721 - ml_training_1991366041456 - INFO - Timer 'val_epoch_6': 0.0805 seconds
2025-08-15 21:30:27,722 - ml_training_1991366041456 - INFO - Epoch   6 | Train Loss: 1.7658 | Train Acc: 41.80% | Val Loss: 1.4239 | Val Acc: 65.19% | LR: 1.00e-03
2025-08-15 21:30:27,776 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 6
2025-08-15 21:30:27,776 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:27,776 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 65.18518518518519, 'val_loss': 1.4238561111337997}
2025-08-15 21:30:27,776 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_7
2025-08-15 21:30:27,792 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=1.6621, Acc=56.25%
2025-08-15 21:30:28,502 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=1.5518, Acc=47.67%
2025-08-15 21:30:29,132 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=1.6063, Acc=49.50%
2025-08-15 21:30:29,368 - ml_training_1991366041456 - INFO - Timer 'train_epoch_7': 1.5918 seconds
2025-08-15 21:30:29,368 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_7
2025-08-15 21:30:29,434 - ml_training_1991366041456 - INFO - Timer 'val_epoch_7': 0.0663 seconds
2025-08-15 21:30:29,434 - ml_training_1991366041456 - INFO - Epoch   7 | Train Loss: 1.6028 | Train Acc: 49.84% | Val Loss: 1.2726 | Val Acc: 66.30% | LR: 1.00e-03
2025-08-15 21:30:29,479 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 7
2025-08-15 21:30:29,480 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:29,480 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 66.29629629629629, 'val_loss': 1.272583105984856}
2025-08-15 21:30:29,481 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_8
2025-08-15 21:30:29,496 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=1.3126, Acc=68.75%
2025-08-15 21:30:30,143 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=1.3867, Acc=55.51%
2025-08-15 21:30:30,761 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=1.3976, Acc=56.13%
2025-08-15 21:30:30,978 - ml_training_1991366041456 - INFO - Timer 'train_epoch_8': 1.4978 seconds
2025-08-15 21:30:30,978 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_8
2025-08-15 21:30:31,061 - ml_training_1991366041456 - INFO - Timer 'val_epoch_8': 0.0829 seconds
2025-08-15 21:30:31,061 - ml_training_1991366041456 - INFO - Epoch   8 | Train Loss: 1.4876 | Train Acc: 56.46% | Val Loss: 1.1505 | Val Acc: 74.07% | LR: 1.00e-03
2025-08-15 21:30:31,114 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 8
2025-08-15 21:30:31,114 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:31,114 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 74.07407407407408, 'val_loss': 1.1504674939548267}
2025-08-15 21:30:31,116 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_9
2025-08-15 21:30:31,133 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=1.4410, Acc=50.00%
2025-08-15 21:30:31,771 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=1.2575, Acc=59.80%
2025-08-15 21:30:32,436 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=1.4848, Acc=58.73%
2025-08-15 21:30:32,688 - ml_training_1991366041456 - INFO - Timer 'train_epoch_9': 1.5718 seconds
2025-08-15 21:30:32,689 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_9
2025-08-15 21:30:32,771 - ml_training_1991366041456 - INFO - Timer 'val_epoch_9': 0.0824 seconds
2025-08-15 21:30:32,771 - ml_training_1991366041456 - INFO - Epoch   9 | Train Loss: 1.4017 | Train Acc: 59.42% | Val Loss: 1.0055 | Val Acc: 80.74% | LR: 1.00e-03
2025-08-15 21:30:32,817 - ml_training_1991366041456 - INFO - Checkpoint saved at epoch 9
2025-08-15 21:30:32,818 - ml_training_1991366041456 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:30:32,818 - ml_training_1991366041456 - INFO - Checkpoint metrics: {'val_acc': 80.74074074074075, 'val_loss': 1.00550737100489}
2025-08-15 21:30:32,818 - ml_training_1991366041456 - DEBUG - Timer started: train_epoch_10
2025-08-15 21:30:32,835 - ml_training_1991366041456 - DEBUG - Batch 0/119: Loss=1.5662, Acc=43.75%
2025-08-15 21:30:33,545 - ml_training_1991366041456 - DEBUG - Batch 50/119: Loss=1.1386, Acc=65.69%
2025-08-15 21:30:34,230 - ml_training_1991366041456 - DEBUG - Batch 100/119: Loss=1.1292, Acc=67.20%
2025-08-15 21:30:34,463 - ml_training_1991366041456 - INFO - Timer 'train_epoch_10': 1.6449 seconds
2025-08-15 21:30:34,464 - ml_training_1991366041456 - DEBUG - Timer started: val_epoch_10
2025-08-15 21:30:34,544 - ml_training_1991366041456 - INFO - Timer 'val_epoch_10': 0.0800 seconds
2025-08-15 21:30:34,544 - ml_training_1991366041456 - INFO - Epoch  10 | Train Loss: 1.2743 | Train Acc: 67.41% | Val Loss: 1.0176 | Val Acc: 77.41% | LR: 1.00e-03
2025-08-15 21:30:34,568 - ml_training_1991366041456 - INFO - Training completed. Evaluating on test set...
2025-08-15 21:30:34,616 - ml_training_1991366041456 - INFO - Loaded checkpoint from epoch 9
2025-08-15 21:30:34,621 - ml_training_1991366041456 - DEBUG - Timer started: test_evaluation
2025-08-15 21:30:34,790 - ml_training_1991366041456 - INFO - Timer 'test_evaluation': 0.1697 seconds
2025-08-15 21:30:34,800 - ml_training_1991366041456 - INFO - === TEST RESULTS ===
2025-08-15 21:30:34,800 - ml_training_1991366041456 - INFO - Test Accuracy: 0.8093
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO - Test Loss: 0.9967
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO - Classification Report:
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -                 precision    recall  f1-score   support
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -              0     0.8846    0.8519    0.8679        54
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -              1     0.8269    0.7963    0.8113        54
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -              2     0.5213    0.9074    0.6622        54
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -              3     0.5641    0.4074    0.4731        54
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -              4     0.9750    0.7222    0.8298        54
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -              5     0.7879    0.9630    0.8667        54
2025-08-15 21:30:34,801 - ml_training_1991366041456 - INFO -              6     1.0000    0.8333    0.9091        54
2025-08-15 21:30:34,802 - ml_training_1991366041456 - INFO -              7     1.0000    0.8889    0.9412        54
2025-08-15 21:30:34,802 - ml_training_1991366041456 - INFO -              8     0.9423    0.9074    0.9245        54
2025-08-15 21:30:34,802 - ml_training_1991366041456 - INFO -              9     0.8462    0.8148    0.8302        54
2025-08-15 21:30:34,802 - ml_training_1991366041456 - INFO -       accuracy                         0.8093       540
2025-08-15 21:30:34,802 - ml_training_1991366041456 - INFO -      macro avg     0.8348    0.8093    0.8116       540
2025-08-15 21:30:34,802 - ml_training_1991366041456 - INFO -   weighted avg     0.8348    0.8093    0.8116       540
2025-08-15 21:30:34,802 - ml_training_1991366041456 - INFO - === END TEST RESULTS ===
2025-08-15 21:30:36,001 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mel_cnn_classifier\training_history_mel_cnn_classifier_training_history.png
2025-08-15 21:30:36,480 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:30:36,481 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:30:37,597 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mel_cnn_classifier\confusion_matrix_mel_cnn_classifier_confusion_matrix.png
2025-08-15 21:30:37,597 - ml_training_1991366041456 - INFO - Visualizations generated successfully
2025-08-15 21:30:37,597 - ml_training_1991366041456 - INFO - Closing ML Training Logger
2025-08-15 21:30:37,598 - ml_training_1991366041456 - INFO - Metrics summary saved to: train_logs\metrics_summary_mel_cnn_classifier_20250815_213016.json
2025-08-15 21:30:37,600 - __main__ - INFO - mel_cnn training completed:
2025-08-15 21:30:37,600 - __main__ - INFO -   Best val accuracy: 80.7407
2025-08-15 21:30:37,600 - __main__ - INFO -   Test accuracy: 0.8093
2025-08-15 21:30:37,600 - __main__ - INFO - Training raw_cnn pipeline...
2025-08-15 21:30:37,600 - ml_training.pipelines.raw_cnn_pipeline - INFO - Setting up Raw Waveform CNN pipeline...
2025-08-15 21:30:37,612 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform Dataset initialized:
2025-08-15 21:30:37,612 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Samples: 1890
2025-08-15 21:30:37,612 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:30:37,612 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Augmentation: True
2025-08-15 21:30:37,612 - ml_training.pipelines.raw_cnn_pipeline - INFO -     Noise factor: 0.005
2025-08-15 21:30:37,612 - ml_training.pipelines.raw_cnn_pipeline - INFO -     Max shift: 400 samples
2025-08-15 21:30:37,612 - ml_training.pipelines.raw_cnn_pipeline - INFO -     Amplitude range: (0.8, 1.2)
2025-08-15 21:30:37,616 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform Dataset initialized:
2025-08-15 21:30:37,616 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Samples: 540
2025-08-15 21:30:37,616 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:30:37,616 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Augmentation: False
2025-08-15 21:30:37,618 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform Dataset initialized:
2025-08-15 21:30:37,618 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Samples: 270
2025-08-15 21:30:37,618 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:30:37,618 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Augmentation: False
2025-08-15 21:30:37,626 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform CNN initialized:
2025-08-15 21:30:37,626 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Input length: 8000 samples
2025-08-15 21:30:37,626 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Architecture: Conv1D(64->128->128->256->256) -> Global Pool -> FC(512->256->10)
2025-08-15 21:30:37,627 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Total parameters: 640,906
2025-08-15 21:30:37,627 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Receptive field: 128 samples
2025-08-15 21:30:37,633 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw CNN pipeline setup completed:
2025-08-15 21:30:37,633 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Device: cuda
2025-08-15 21:30:37,633 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Train samples: 1890
2025-08-15 21:30:37,633 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Val samples: 270
2025-08-15 21:30:37,633 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Test samples: 540
2025-08-15 21:30:37,633 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Batch size: 16
2025-08-15 21:30:37,633 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:30:37,634 - ml_training_1989882468864 - INFO - ML Training Logger initialized - Log file: train_logs\raw_cnn_classifier_20250815_213037.log
2025-08-15 21:30:37,634 - ml_training_1989882468864 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:30:37,634 - ml_training_1989882468864 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:30:37,634 - ml_training_1989882468864 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:30:37,635 - ml_training_1989882468864 - INFO - NumPy Version: 1.26.4
2025-08-15 21:30:37,635 - ml_training_1989882468864 - INFO - Librosa Version: 0.10.2
2025-08-15 21:30:37,635 - ml_training_1989882468864 - INFO - CUDA Available: Yes
2025-08-15 21:30:37,636 - ml_training_1989882468864 - INFO - CUDA Version: 12.1
2025-08-15 21:30:37,636 - ml_training_1989882468864 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:30:37,636 - ml_training_1989882468864 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:30:37,636 - ml_training_1989882468864 - INFO - === END SYSTEM INFO ===
2025-08-15 21:30:37,637 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\raw_cnn_classifier
2025-08-15 21:30:37,637 - ml_training_1989882468864 - INFO - Trainer initialized for raw_cnn_classifier
2025-08-15 21:30:37,637 - ml_training_1989882468864 - INFO - === RAW_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO - Total Parameters: 640,906
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO - Trainable Parameters: 640,906
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO - Non-trainable Parameters: 0
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO - Model Architecture:
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO -   conv1: Conv1d(1, 64, kernel_size=(80,), stride=(4,), padding=(38,), bias=False)
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO -   conv2: Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO -   conv3: Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO -   conv4: Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO -   conv5: Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:30:37,638 - ml_training_1989882468864 - INFO -   bn1: BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   bn2: BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   bn3: BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   bn4: BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   bn5: BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   pool: MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   dropout1d: Dropout1d(p=0.2, inplace=False)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   dropout: Dropout(p=0.3, inplace=False)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   global_pool: AdaptiveAvgPool1d(output_size=1)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   fc1: Linear(in_features=256, out_features=512, bias=True)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   fc2: Linear(in_features=512, out_features=256, bias=True)
2025-08-15 21:30:37,639 - ml_training_1989882468864 - INFO -   fc3: Linear(in_features=256, out_features=10, bias=True)
2025-08-15 21:30:37,640 - ml_training_1989882468864 - INFO - === END RAW_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:30:37,640 - ml_training_1989882468864 - INFO - === EXPERIMENT CONFIGURATION ===
2025-08-15 21:30:37,640 - ml_training_1989882468864 - INFO - learning_rate: 0.001
2025-08-15 21:30:37,640 - ml_training_1989882468864 - INFO - weight_decay: 0.0001
2025-08-15 21:30:37,641 - ml_training_1989882468864 - INFO - scheduler_type: plateau
2025-08-15 21:30:37,641 - ml_training_1989882468864 - INFO - early_stopping_patience: 10
2025-08-15 21:30:37,641 - ml_training_1989882468864 - INFO - gradient_clipping: 1.0
2025-08-15 21:30:37,641 - ml_training_1989882468864 - INFO - mixed_precision: True
2025-08-15 21:30:37,641 - ml_training_1989882468864 - INFO - optimizer: Adam
2025-08-15 21:30:37,641 - ml_training_1989882468864 - INFO - loss_function: CrossEntropyLoss with label smoothing
2025-08-15 21:30:37,641 - ml_training_1989882468864 - INFO - device: cuda
2025-08-15 21:30:37,642 - ml_training_1989882468864 - INFO - Configuration saved to: train_logs\config_raw_cnn_classifier_20250815_213037.json
2025-08-15 21:30:37,642 - ml_training_1989882468864 - INFO - === END CONFIGURATION ===
2025-08-15 21:30:37,642 - ml_training_1989882468864 - INFO - Starting training for 10 epochs
2025-08-15 21:30:37,642 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_1
2025-08-15 21:30:37,796 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=3.8729, Acc=0.00%
2025-08-15 21:30:38,976 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=2.2453, Acc=12.62%
2025-08-15 21:30:39,978 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=2.2926, Acc=19.00%
2025-08-15 21:30:40,430 - ml_training_1989882468864 - INFO - Timer 'train_epoch_1': 2.7876 seconds
2025-08-15 21:30:40,431 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_1
2025-08-15 21:30:40,558 - ml_training_1989882468864 - INFO - Timer 'val_epoch_1': 0.1270 seconds
2025-08-15 21:30:40,559 - ml_training_1989882468864 - INFO - Epoch   1 | Train Loss: 2.3141 | Train Acc: 20.32% | Val Loss: 1.6611 | Val Acc: 41.11% | LR: 1.00e-03
2025-08-15 21:30:40,601 - ml_training_1989882468864 - INFO - Checkpoint saved at epoch 1
2025-08-15 21:30:40,602 - ml_training_1989882468864 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:30:40,602 - ml_training_1989882468864 - INFO - Checkpoint metrics: {'val_acc': 41.111111111111114, 'val_loss': 1.661128373707042}
2025-08-15 21:30:40,602 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_2
2025-08-15 21:30:40,621 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=2.0720, Acc=31.25%
2025-08-15 21:30:41,639 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=1.6981, Acc=35.91%
2025-08-15 21:30:42,626 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=1.8724, Acc=37.25%
2025-08-15 21:30:42,983 - ml_training_1989882468864 - INFO - Timer 'train_epoch_2': 2.3815 seconds
2025-08-15 21:30:42,984 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_2
2025-08-15 21:30:43,061 - ml_training_1989882468864 - INFO - Timer 'val_epoch_2': 0.0770 seconds
2025-08-15 21:30:43,061 - ml_training_1989882468864 - INFO - Epoch   2 | Train Loss: 1.8000 | Train Acc: 37.41% | Val Loss: 1.4655 | Val Acc: 46.67% | LR: 1.00e-03
2025-08-15 21:30:43,104 - ml_training_1989882468864 - INFO - Checkpoint saved at epoch 2
2025-08-15 21:30:43,104 - ml_training_1989882468864 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:30:43,106 - ml_training_1989882468864 - INFO - Checkpoint metrics: {'val_acc': 46.666666666666664, 'val_loss': 1.4654857761719648}
2025-08-15 21:30:43,106 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_3
2025-08-15 21:30:43,126 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=1.6165, Acc=43.75%
2025-08-15 21:30:44,144 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=1.9521, Acc=46.32%
2025-08-15 21:30:45,098 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=1.5224, Acc=46.35%
2025-08-15 21:30:45,452 - ml_training_1989882468864 - INFO - Timer 'train_epoch_3': 2.3463 seconds
2025-08-15 21:30:45,453 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_3
2025-08-15 21:30:45,528 - ml_training_1989882468864 - INFO - Timer 'val_epoch_3': 0.0745 seconds
2025-08-15 21:30:45,528 - ml_training_1989882468864 - INFO - Epoch   3 | Train Loss: 1.6175 | Train Acc: 47.04% | Val Loss: 1.2698 | Val Acc: 61.48% | LR: 1.00e-03
2025-08-15 21:30:45,567 - ml_training_1989882468864 - INFO - Checkpoint saved at epoch 3
2025-08-15 21:30:45,567 - ml_training_1989882468864 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:30:45,567 - ml_training_1989882468864 - INFO - Checkpoint metrics: {'val_acc': 61.48148148148148, 'val_loss': 1.2698361803503597}
2025-08-15 21:30:45,568 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_4
2025-08-15 21:30:45,588 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=1.5369, Acc=31.25%
2025-08-15 21:30:46,533 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=1.4948, Acc=53.19%
2025-08-15 21:30:47,506 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=1.4223, Acc=55.88%
2025-08-15 21:30:47,833 - ml_training_1989882468864 - INFO - Timer 'train_epoch_4': 2.2653 seconds
2025-08-15 21:30:47,834 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_4
2025-08-15 21:30:47,915 - ml_training_1989882468864 - INFO - Timer 'val_epoch_4': 0.0804 seconds
2025-08-15 21:30:47,916 - ml_training_1989882468864 - INFO - Epoch   4 | Train Loss: 1.4522 | Train Acc: 56.83% | Val Loss: 1.0410 | Val Acc: 77.78% | LR: 1.00e-03
2025-08-15 21:30:47,960 - ml_training_1989882468864 - INFO - Checkpoint saved at epoch 4
2025-08-15 21:30:47,960 - ml_training_1989882468864 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:30:47,960 - ml_training_1989882468864 - INFO - Checkpoint metrics: {'val_acc': 77.77777777777777, 'val_loss': 1.041027167264153}
2025-08-15 21:30:47,960 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_5
2025-08-15 21:30:47,981 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=1.5432, Acc=43.75%
2025-08-15 21:30:48,971 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=1.4469, Acc=62.13%
2025-08-15 21:30:49,927 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=1.4727, Acc=61.45%
2025-08-15 21:30:50,250 - ml_training_1989882468864 - INFO - Timer 'train_epoch_5': 2.2898 seconds
2025-08-15 21:30:50,251 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_5
2025-08-15 21:30:50,316 - ml_training_1989882468864 - INFO - Timer 'val_epoch_5': 0.0647 seconds
2025-08-15 21:30:50,317 - ml_training_1989882468864 - INFO - Epoch   5 | Train Loss: 1.3325 | Train Acc: 62.49% | Val Loss: 0.8919 | Val Acc: 84.81% | LR: 1.00e-03
2025-08-15 21:30:50,366 - ml_training_1989882468864 - INFO - Checkpoint saved at epoch 5
2025-08-15 21:30:50,366 - ml_training_1989882468864 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:30:50,366 - ml_training_1989882468864 - INFO - Checkpoint metrics: {'val_acc': 84.81481481481481, 'val_loss': 0.8918585286420935}
2025-08-15 21:30:50,366 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_6
2025-08-15 21:30:50,388 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=1.2298, Acc=62.50%
2025-08-15 21:30:51,322 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=0.9826, Acc=70.59%
2025-08-15 21:30:52,315 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=1.2768, Acc=70.17%
2025-08-15 21:30:52,664 - ml_training_1989882468864 - INFO - Timer 'train_epoch_6': 2.2983 seconds
2025-08-15 21:30:52,665 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_6
2025-08-15 21:30:52,738 - ml_training_1989882468864 - INFO - Timer 'val_epoch_6': 0.0738 seconds
2025-08-15 21:30:52,739 - ml_training_1989882468864 - INFO - Epoch   6 | Train Loss: 1.1853 | Train Acc: 70.05% | Val Loss: 0.9036 | Val Acc: 81.48% | LR: 1.00e-03
2025-08-15 21:30:52,739 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_7
2025-08-15 21:30:52,756 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=0.8114, Acc=93.75%
2025-08-15 21:30:53,774 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=1.1655, Acc=71.94%
2025-08-15 21:30:54,796 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=1.4443, Acc=71.41%
2025-08-15 21:30:55,139 - ml_training_1989882468864 - INFO - Timer 'train_epoch_7': 2.3995 seconds
2025-08-15 21:30:55,140 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_7
2025-08-15 21:30:55,238 - ml_training_1989882468864 - INFO - Timer 'val_epoch_7': 0.0988 seconds
2025-08-15 21:30:55,239 - ml_training_1989882468864 - INFO - Epoch   7 | Train Loss: 1.1454 | Train Acc: 72.65% | Val Loss: 0.8213 | Val Acc: 87.04% | LR: 1.00e-03
2025-08-15 21:30:55,280 - ml_training_1989882468864 - INFO - Checkpoint saved at epoch 7
2025-08-15 21:30:55,280 - ml_training_1989882468864 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:30:55,280 - ml_training_1989882468864 - INFO - Checkpoint metrics: {'val_acc': 87.03703703703704, 'val_loss': 0.8213256211841807}
2025-08-15 21:30:55,280 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_8
2025-08-15 21:30:55,298 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=1.0457, Acc=81.25%
2025-08-15 21:30:56,263 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=1.1085, Acc=78.43%
2025-08-15 21:30:57,237 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=0.9500, Acc=78.03%
2025-08-15 21:30:57,577 - ml_training_1989882468864 - INFO - Timer 'train_epoch_8': 2.2973 seconds
2025-08-15 21:30:57,577 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_8
2025-08-15 21:30:57,672 - ml_training_1989882468864 - INFO - Timer 'val_epoch_8': 0.0940 seconds
2025-08-15 21:30:57,672 - ml_training_1989882468864 - INFO - Epoch   8 | Train Loss: 1.0651 | Train Acc: 77.94% | Val Loss: 0.8063 | Val Acc: 88.52% | LR: 1.00e-03
2025-08-15 21:30:57,717 - ml_training_1989882468864 - INFO - Checkpoint saved at epoch 8
2025-08-15 21:30:57,717 - ml_training_1989882468864 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:30:57,718 - ml_training_1989882468864 - INFO - Checkpoint metrics: {'val_acc': 88.51851851851852, 'val_loss': 0.8062583909315222}
2025-08-15 21:30:57,718 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_9
2025-08-15 21:30:57,736 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=0.8191, Acc=93.75%
2025-08-15 21:30:58,686 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=1.1023, Acc=78.68%
2025-08-15 21:30:59,680 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=0.8437, Acc=78.65%
2025-08-15 21:31:00,038 - ml_training_1989882468864 - INFO - Timer 'train_epoch_9': 2.3194 seconds
2025-08-15 21:31:00,039 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_9
2025-08-15 21:31:00,119 - ml_training_1989882468864 - INFO - Timer 'val_epoch_9': 0.0808 seconds
2025-08-15 21:31:00,119 - ml_training_1989882468864 - INFO - Epoch   9 | Train Loss: 1.0337 | Train Acc: 78.52% | Val Loss: 0.7867 | Val Acc: 87.04% | LR: 1.00e-03
2025-08-15 21:31:00,120 - ml_training_1989882468864 - DEBUG - Timer started: train_epoch_10
2025-08-15 21:31:00,142 - ml_training_1989882468864 - DEBUG - Batch 0/119: Loss=1.1525, Acc=81.25%
2025-08-15 21:31:01,162 - ml_training_1989882468864 - DEBUG - Batch 50/119: Loss=0.7708, Acc=81.37%
2025-08-15 21:31:02,107 - ml_training_1989882468864 - DEBUG - Batch 100/119: Loss=1.0907, Acc=79.58%
2025-08-15 21:31:02,489 - ml_training_1989882468864 - INFO - Timer 'train_epoch_10': 2.3684 seconds
2025-08-15 21:31:02,490 - ml_training_1989882468864 - DEBUG - Timer started: val_epoch_10
2025-08-15 21:31:02,590 - ml_training_1989882468864 - INFO - Timer 'val_epoch_10': 0.1001 seconds
2025-08-15 21:31:02,590 - ml_training_1989882468864 - INFO - Epoch  10 | Train Loss: 1.0151 | Train Acc: 79.68% | Val Loss: 0.8052 | Val Acc: 88.15% | LR: 1.00e-03
2025-08-15 21:31:02,614 - ml_training_1989882468864 - INFO - Training completed. Evaluating on test set...
2025-08-15 21:31:02,671 - ml_training_1989882468864 - INFO - Loaded checkpoint from epoch 8
2025-08-15 21:31:02,671 - ml_training_1989882468864 - DEBUG - Timer started: test_evaluation
2025-08-15 21:31:02,864 - ml_training_1989882468864 - INFO - Timer 'test_evaluation': 0.1939 seconds
2025-08-15 21:31:02,873 - ml_training_1989882468864 - INFO - === TEST RESULTS ===
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO - Test Accuracy: 0.8759
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO - Test Loss: 0.8168
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO - Classification Report:
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -                 precision    recall  f1-score   support
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -              0     1.0000    0.9444    0.9714        54
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -              1     0.9333    0.7778    0.8485        54
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -              2     0.6438    0.8704    0.7402        54
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -              3     0.6607    0.6852    0.6727        54
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -              4     1.0000    0.9815    0.9907        54
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -              5     0.9153    1.0000    0.9558        54
2025-08-15 21:31:02,874 - ml_training_1989882468864 - INFO -              6     0.9773    0.7963    0.8776        54
2025-08-15 21:31:02,875 - ml_training_1989882468864 - INFO -              7     0.9434    0.9259    0.9346        54
2025-08-15 21:31:02,875 - ml_training_1989882468864 - INFO -              8     0.9362    0.8148    0.8713        54
2025-08-15 21:31:02,875 - ml_training_1989882468864 - INFO -              9     0.8814    0.9630    0.9204        54
2025-08-15 21:31:02,875 - ml_training_1989882468864 - INFO -       accuracy                         0.8759       540
2025-08-15 21:31:02,875 - ml_training_1989882468864 - INFO -      macro avg     0.8891    0.8759    0.8783       540
2025-08-15 21:31:02,875 - ml_training_1989882468864 - INFO -   weighted avg     0.8891    0.8759    0.8783       540
2025-08-15 21:31:02,876 - ml_training_1989882468864 - INFO - === END TEST RESULTS ===
2025-08-15 21:31:04,018 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\raw_cnn_classifier\training_history_raw_cnn_classifier_training_history.png
2025-08-15 21:31:04,494 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:31:04,495 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:31:05,866 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\raw_cnn_classifier\confusion_matrix_raw_cnn_classifier_confusion_matrix.png
2025-08-15 21:31:05,866 - ml_training_1989882468864 - INFO - Visualizations generated successfully
2025-08-15 21:31:05,866 - ml_training_1989882468864 - INFO - Closing ML Training Logger
2025-08-15 21:31:05,866 - ml_training_1989882468864 - INFO - Metrics summary saved to: train_logs\metrics_summary_raw_cnn_classifier_20250815_213037.json
2025-08-15 21:31:05,870 - __main__ - INFO - raw_cnn training completed:
2025-08-15 21:31:05,870 - __main__ - INFO -   Best val accuracy: 88.5185
2025-08-15 21:31:05,870 - __main__ - INFO -   Test accuracy: 0.8759
2025-08-15 21:31:05,870 - __main__ - INFO - Generating comparison visualizations...
2025-08-15 21:31:05,871 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\comparison
2025-08-15 21:31:06,927 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\comparison\model_comparison.png
2025-08-15 21:31:06,934 - __main__ - INFO - Multi-pipeline training completed successfully
2025-08-15 21:31:06,934 - __main__ - INFO - Training script completed successfully
2025-08-15 21:31:58,842 - __main__ - INFO - Training configuration: {'pipelines': ['mfcc', 'mel_cnn', 'raw_cnn'], 'num_epochs': 50, 'batch_size': 32, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'scheduler_type': 'plateau', 'early_stopping_patience': 10, 'gradient_clipping': 1.0, 'save_frequency': 10, 'sample_rate': 8000, 'max_length': 8000}
2025-08-15 21:31:58,843 - __main__ - INFO - Loading dataset...
2025-08-15 21:31:58,843 - ml_training.data.dataset_loader - INFO - Loading and preparing digit dataset...
2025-08-15 21:31:58,878 - ml_training.data.dataset_loader - INFO - ffmpeg detected - will use for high-quality audio resampling
2025-08-15 21:31:58,878 - ml_training.data.dataset_loader - INFO - Initialized DataLoader - SR: 8000Hz, Max Length: 8000 samples
2025-08-15 21:31:58,878 - ml_training.data.dataset_loader - INFO - Loading Free Spoken Digit Dataset from HuggingFace...
2025-08-15 21:32:00,346 - ml_training.data.dataset_loader - INFO - Dataset loaded successfully
2025-08-15 21:32:00,347 - ml_training.data.dataset_loader - INFO - Available splits: ['train', 'test']
2025-08-15 21:32:00,347 - ml_training.data.dataset_loader - INFO - Train split size: 2700
2025-08-15 21:32:01,878 - ml_training.data.dataset_loader - INFO - Dataset sample structure: dict_keys(['audio', 'label'])
2025-08-15 21:32:01,879 - ml_training.data.dataset_loader - INFO - Audio info: sampling_rate=8000, array_shape=(5958,)
2025-08-15 21:32:01,879 - ml_training.data.dataset_loader - INFO - Label type: <class 'int'>, value: 0
2025-08-15 21:32:01,879 - ml_training.data.dataset_loader - INFO - Creating train/test/validation splits...
2025-08-15 21:32:01,879 - ml_training.data.dataset_loader - INFO - Processing 2700 samples from 'train' split
2025-08-15 21:32:01,906 - ml_training.data.dataset_loader - INFO - Processed 100/2700 samples
2025-08-15 21:32:01,937 - ml_training.data.dataset_loader - INFO - Processed 200/2700 samples
2025-08-15 21:32:01,970 - ml_training.data.dataset_loader - INFO - Processed 300/2700 samples
2025-08-15 21:32:02,006 - ml_training.data.dataset_loader - INFO - Processed 400/2700 samples
2025-08-15 21:32:02,038 - ml_training.data.dataset_loader - INFO - Processed 500/2700 samples
2025-08-15 21:32:02,070 - ml_training.data.dataset_loader - INFO - Processed 600/2700 samples
2025-08-15 21:32:02,102 - ml_training.data.dataset_loader - INFO - Processed 700/2700 samples
2025-08-15 21:32:02,136 - ml_training.data.dataset_loader - INFO - Processed 800/2700 samples
2025-08-15 21:32:02,168 - ml_training.data.dataset_loader - INFO - Processed 900/2700 samples
2025-08-15 21:32:02,201 - ml_training.data.dataset_loader - INFO - Processed 1000/2700 samples
2025-08-15 21:32:02,234 - ml_training.data.dataset_loader - INFO - Processed 1100/2700 samples
2025-08-15 21:32:02,268 - ml_training.data.dataset_loader - INFO - Processed 1200/2700 samples
2025-08-15 21:32:02,297 - ml_training.data.dataset_loader - INFO - Processed 1300/2700 samples
2025-08-15 21:32:02,341 - ml_training.data.dataset_loader - INFO - Processed 1400/2700 samples
2025-08-15 21:32:02,378 - ml_training.data.dataset_loader - INFO - Processed 1500/2700 samples
2025-08-15 21:32:02,413 - ml_training.data.dataset_loader - INFO - Processed 1600/2700 samples
2025-08-15 21:32:02,446 - ml_training.data.dataset_loader - INFO - Processed 1700/2700 samples
2025-08-15 21:32:02,480 - ml_training.data.dataset_loader - INFO - Processed 1800/2700 samples
2025-08-15 21:32:02,518 - ml_training.data.dataset_loader - INFO - Processed 1900/2700 samples
2025-08-15 21:32:02,551 - ml_training.data.dataset_loader - INFO - Processed 2000/2700 samples
2025-08-15 21:32:02,581 - ml_training.data.dataset_loader - INFO - Processed 2100/2700 samples
2025-08-15 21:32:02,609 - ml_training.data.dataset_loader - INFO - Processed 2200/2700 samples
2025-08-15 21:32:02,643 - ml_training.data.dataset_loader - INFO - Processed 2300/2700 samples
2025-08-15 21:32:02,679 - ml_training.data.dataset_loader - INFO - Processed 2400/2700 samples
2025-08-15 21:32:02,714 - ml_training.data.dataset_loader - INFO - Processed 2500/2700 samples
2025-08-15 21:32:02,749 - ml_training.data.dataset_loader - INFO - Processed 2600/2700 samples
2025-08-15 21:32:02,783 - ml_training.data.dataset_loader - INFO - Processed 2700/2700 samples
2025-08-15 21:32:02,820 - ml_training.data.dataset_loader - INFO - Audio data shape: (2700, 8000)
2025-08-15 21:32:02,821 - ml_training.data.dataset_loader - INFO - Labels shape: (2700,)
2025-08-15 21:32:02,821 - ml_training.data.dataset_loader - INFO - Unique labels: [0 1 2 3 4 5 6 7 8 9]
2025-08-15 21:32:02,822 - ml_training.data.dataset_loader - INFO - Label encoding: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}
2025-08-15 21:32:02,822 - ml_training.data.dataset_loader - INFO - Creating splits - Test: 20.0%, Val: 10.0%
2025-08-15 21:32:02,863 - ml_training.data.dataset_loader - INFO - Dataset splits created successfully:
2025-08-15 21:32:02,864 - ml_training.data.dataset_loader - INFO -   Train: 1890 samples
2025-08-15 21:32:02,864 - ml_training.data.dataset_loader - INFO -   Val: 270 samples
2025-08-15 21:32:02,864 - ml_training.data.dataset_loader - INFO -   Test: 540 samples
2025-08-15 21:32:02,864 - ml_training.data.dataset_loader - INFO -   Classes: 10 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
2025-08-15 21:32:02,870 - ml_training.data.dataset_loader - INFO - Validating dataset splits...
2025-08-15 21:32:02,871 - ml_training.data.dataset_loader - INFO - Dataset validation passed
2025-08-15 21:32:02,871 - ml_training.data.dataset_loader - INFO - Dataset preparation completed successfully
2025-08-15 21:32:02,874 - ml_training_1984972073312 - INFO - ML Training Logger initialized - Log file: train_logs\comparison_study_20250815_213202.log
2025-08-15 21:32:02,876 - ml_training_1984972073312 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:32:02,876 - ml_training_1984972073312 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:32:02,876 - ml_training_1984972073312 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:32:02,877 - ml_training_1984972073312 - INFO - NumPy Version: 1.26.4
2025-08-15 21:32:02,877 - ml_training_1984972073312 - INFO - Librosa Version: 0.10.2
2025-08-15 21:32:02,896 - ml_training_1984972073312 - INFO - CUDA Available: Yes
2025-08-15 21:32:02,898 - ml_training_1984972073312 - INFO - CUDA Version: 12.1
2025-08-15 21:32:02,900 - ml_training_1984972073312 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:32:02,900 - ml_training_1984972073312 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:32:02,900 - ml_training_1984972073312 - INFO - === END SYSTEM INFO ===
2025-08-15 21:32:02,900 - ml_training_1984972073312 - INFO - === DATASET INFORMATION ===
2025-08-15 21:32:02,900 - ml_training_1984972073312 - INFO - total_samples: 2700
2025-08-15 21:32:02,900 - ml_training_1984972073312 - INFO - train_samples: 1890
2025-08-15 21:32:02,900 - ml_training_1984972073312 - INFO - val_samples: 270
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - test_samples: 540
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - sample_rate: 8000
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - max_length: 8000
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - num_classes: 10
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - class_names: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - audio_shape: (2700, 8000)
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - mean_sample_rate: 8000.0
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - std_sample_rate: 0.0
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - === END DATASET INFO ===
2025-08-15 21:32:02,901 - ml_training_1984972073312 - INFO - Closing ML Training Logger
2025-08-15 21:32:02,903 - ml_training_1984972073312 - INFO - Metrics summary saved to: train_logs\metrics_summary_comparison_study_20250815_213202.json
2025-08-15 21:32:02,903 - __main__ - INFO - Training mfcc pipeline...
2025-08-15 21:32:02,903 - ml_training.pipelines.mfcc_pipeline - INFO - Setting up MFCC pipeline...
2025-08-15 21:32:02,904 - ml_training.pipelines.mfcc_pipeline - INFO - Fitting feature scaler on training data...
2025-08-15 21:32:08,252 - ml_training.pipelines.mfcc_pipeline - INFO - Feature scaling statistics:
2025-08-15 21:32:08,253 - ml_training.pipelines.mfcc_pipeline - INFO -   Mean: [-509.94391019   24.72415496    5.40042514    1.75478205  -10.29276815]... (first 5)
2025-08-15 21:32:08,253 - ml_training.pipelines.mfcc_pipeline - INFO -   Std: [47.04976658 16.63563144  9.60469901  8.82461158  7.35149315]... (first 5)
2025-08-15 21:32:08,253 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 1890 samples...
2025-08-15 21:32:13,388 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (1890, 156)
2025-08-15 21:32:13,388 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 540 samples...
2025-08-15 21:32:14,817 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (540, 156)
2025-08-15 21:32:14,817 - ml_training.pipelines.mfcc_pipeline - INFO - Extracting MFCC features for 270 samples...
2025-08-15 21:32:15,557 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Dataset initialized - Features shape: (270, 156)
2025-08-15 21:32:15,560 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC Classifier initialized:
2025-08-15 21:32:15,560 - ml_training.pipelines.mfcc_pipeline - INFO -   Architecture: 156 -> 256 -> 128 -> 64 -> 10
2025-08-15 21:32:15,560 - ml_training.pipelines.mfcc_pipeline - INFO -   Total parameters: 82,890
2025-08-15 21:32:15,560 - ml_training.pipelines.mfcc_pipeline - INFO -   Dropout: 0.3
2025-08-15 21:32:15,638 - ml_training.pipelines.mfcc_pipeline - INFO - MFCC pipeline setup completed:
2025-08-15 21:32:15,639 - ml_training.pipelines.mfcc_pipeline - INFO -   Device: cuda
2025-08-15 21:32:15,639 - ml_training.pipelines.mfcc_pipeline - INFO -   Train samples: 1890
2025-08-15 21:32:15,639 - ml_training.pipelines.mfcc_pipeline - INFO -   Val samples: 270
2025-08-15 21:32:15,639 - ml_training.pipelines.mfcc_pipeline - INFO -   Test samples: 540
2025-08-15 21:32:15,639 - ml_training.pipelines.mfcc_pipeline - INFO -   Batch size: 32
2025-08-15 21:32:15,640 - ml_training.pipelines.mfcc_pipeline - INFO -   Feature dimension: 156
2025-08-15 21:32:15,640 - ml_training_1985044919168 - INFO - ML Training Logger initialized - Log file: train_logs\mfcc_classifier_20250815_213215.log
2025-08-15 21:32:15,641 - ml_training_1985044919168 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:32:15,641 - ml_training_1985044919168 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:32:15,642 - ml_training_1985044919168 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:32:15,642 - ml_training_1985044919168 - INFO - NumPy Version: 1.26.4
2025-08-15 21:32:15,642 - ml_training_1985044919168 - INFO - Librosa Version: 0.10.2
2025-08-15 21:32:15,642 - ml_training_1985044919168 - INFO - CUDA Available: Yes
2025-08-15 21:32:15,643 - ml_training_1985044919168 - INFO - CUDA Version: 12.1
2025-08-15 21:32:15,643 - ml_training_1985044919168 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:32:15,644 - ml_training_1985044919168 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:32:15,644 - ml_training_1985044919168 - INFO - === END SYSTEM INFO ===
2025-08-15 21:32:15,644 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\mfcc_classifier
2025-08-15 21:32:15,644 - ml_training_1985044919168 - INFO - Trainer initialized for mfcc_classifier
2025-08-15 21:32:15,644 - ml_training_1985044919168 - INFO - === MFCC_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:32:15,646 - ml_training_1985044919168 - INFO - Total Parameters: 82,890
2025-08-15 21:32:15,646 - ml_training_1985044919168 - INFO - Trainable Parameters: 82,890
2025-08-15 21:32:15,646 - ml_training_1985044919168 - INFO - Non-trainable Parameters: 0
2025-08-15 21:32:15,646 - ml_training_1985044919168 - INFO - Model Architecture:
2025-08-15 21:32:15,646 - ml_training_1985044919168 - INFO -   network.0: Linear(in_features=156, out_features=256, bias=True)
2025-08-15 21:32:15,647 - ml_training_1985044919168 - INFO -   network.1: BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:32:15,647 - ml_training_1985044919168 - INFO -   network.2: ReLU(inplace=True)
2025-08-15 21:32:15,647 - ml_training_1985044919168 - INFO -   network.3: Dropout(p=0.3, inplace=False)
2025-08-15 21:32:15,647 - ml_training_1985044919168 - INFO -   network.4: Linear(in_features=256, out_features=128, bias=True)
2025-08-15 21:32:15,647 - ml_training_1985044919168 - INFO -   network.5: BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:32:15,647 - ml_training_1985044919168 - INFO -   network.6: ReLU(inplace=True)
2025-08-15 21:32:15,647 - ml_training_1985044919168 - INFO -   network.7: Dropout(p=0.3, inplace=False)
2025-08-15 21:32:15,648 - ml_training_1985044919168 - INFO -   network.8: Linear(in_features=128, out_features=64, bias=True)
2025-08-15 21:32:15,648 - ml_training_1985044919168 - INFO -   network.9: BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:32:15,648 - ml_training_1985044919168 - INFO -   network.10: ReLU(inplace=True)
2025-08-15 21:32:15,648 - ml_training_1985044919168 - INFO -   network.11: Dropout(p=0.3, inplace=False)
2025-08-15 21:32:15,648 - ml_training_1985044919168 - INFO -   network.12: Linear(in_features=64, out_features=10, bias=True)
2025-08-15 21:32:15,649 - ml_training_1985044919168 - INFO - === END MFCC_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:32:16,805 - ml_training_1985044919168 - INFO - === EXPERIMENT CONFIGURATION ===
2025-08-15 21:32:16,807 - ml_training_1985044919168 - INFO - learning_rate: 0.001
2025-08-15 21:32:16,808 - ml_training_1985044919168 - INFO - weight_decay: 0.0001
2025-08-15 21:32:16,808 - ml_training_1985044919168 - INFO - scheduler_type: plateau
2025-08-15 21:32:16,808 - ml_training_1985044919168 - INFO - early_stopping_patience: 10
2025-08-15 21:32:16,808 - ml_training_1985044919168 - INFO - gradient_clipping: 1.0
2025-08-15 21:32:16,808 - ml_training_1985044919168 - INFO - mixed_precision: True
2025-08-15 21:32:16,809 - ml_training_1985044919168 - INFO - optimizer: Adam
2025-08-15 21:32:16,809 - ml_training_1985044919168 - INFO - loss_function: CrossEntropyLoss with label smoothing
2025-08-15 21:32:16,809 - ml_training_1985044919168 - INFO - device: cuda
2025-08-15 21:32:16,811 - ml_training_1985044919168 - INFO - Configuration saved to: train_logs\config_mfcc_classifier_20250815_213215.json
2025-08-15 21:32:16,811 - ml_training_1985044919168 - INFO - === END CONFIGURATION ===
2025-08-15 21:32:16,811 - ml_training_1985044919168 - INFO - Starting training for 50 epochs
2025-08-15 21:32:16,812 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_1
2025-08-15 21:32:17,125 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=2.8955, Acc=9.38%
2025-08-15 21:32:17,401 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=1.6391, Acc=27.70%
2025-08-15 21:32:17,450 - ml_training_1985044919168 - INFO - Timer 'train_epoch_1': 0.6382 seconds
2025-08-15 21:32:17,451 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_1
2025-08-15 21:32:17,484 - ml_training_1985044919168 - INFO - Timer 'val_epoch_1': 0.0336 seconds
2025-08-15 21:32:17,484 - ml_training_1985044919168 - INFO - Epoch   1 | Train Loss: 2.0860 | Train Acc: 30.95% | Val Loss: 1.2075 | Val Acc: 85.19% | LR: 1.00e-03
2025-08-15 21:32:17,506 - ml_training_1985044919168 - INFO - Checkpoint saved at epoch 1
2025-08-15 21:32:17,506 - ml_training_1985044919168 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:32:17,507 - ml_training_1985044919168 - INFO - Checkpoint metrics: {'val_acc': 85.18518518518519, 'val_loss': 1.207483583026462}
2025-08-15 21:32:17,507 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_2
2025-08-15 21:32:17,517 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=1.4293, Acc=71.88%
2025-08-15 21:32:17,813 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=1.1977, Acc=70.53%
2025-08-15 21:32:17,869 - ml_training_1985044919168 - INFO - Timer 'train_epoch_2': 0.3619 seconds
2025-08-15 21:32:17,869 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_2
2025-08-15 21:32:17,888 - ml_training_1985044919168 - INFO - Timer 'val_epoch_2': 0.0188 seconds
2025-08-15 21:32:17,888 - ml_training_1985044919168 - INFO - Epoch   2 | Train Loss: 1.2437 | Train Acc: 71.48% | Val Loss: 0.8170 | Val Acc: 94.07% | LR: 1.00e-03
2025-08-15 21:32:17,901 - ml_training_1985044919168 - INFO - Checkpoint saved at epoch 2
2025-08-15 21:32:17,902 - ml_training_1985044919168 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:32:17,902 - ml_training_1985044919168 - INFO - Checkpoint metrics: {'val_acc': 94.07407407407408, 'val_loss': 0.8170002632670932}
2025-08-15 21:32:17,902 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_3
2025-08-15 21:32:17,910 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=1.0181, Acc=84.38%
2025-08-15 21:32:18,209 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.7876, Acc=84.07%
2025-08-15 21:32:18,263 - ml_training_1985044919168 - INFO - Timer 'train_epoch_3': 0.3612 seconds
2025-08-15 21:32:18,264 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_3
2025-08-15 21:32:18,283 - ml_training_1985044919168 - INFO - Timer 'val_epoch_3': 0.0186 seconds
2025-08-15 21:32:18,284 - ml_training_1985044919168 - INFO - Epoch   3 | Train Loss: 1.0064 | Train Acc: 83.81% | Val Loss: 0.7034 | Val Acc: 95.56% | LR: 1.00e-03
2025-08-15 21:32:18,297 - ml_training_1985044919168 - INFO - Checkpoint saved at epoch 3
2025-08-15 21:32:18,298 - ml_training_1985044919168 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:32:18,298 - ml_training_1985044919168 - INFO - Checkpoint metrics: {'val_acc': 95.55555555555556, 'val_loss': 0.7033776375982497}
2025-08-15 21:32:18,298 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_4
2025-08-15 21:32:18,306 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.9569, Acc=87.50%
2025-08-15 21:32:18,610 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.9981, Acc=89.64%
2025-08-15 21:32:18,667 - ml_training_1985044919168 - INFO - Timer 'train_epoch_4': 0.3697 seconds
2025-08-15 21:32:18,668 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_4
2025-08-15 21:32:18,699 - ml_training_1985044919168 - INFO - Timer 'val_epoch_4': 0.0316 seconds
2025-08-15 21:32:18,700 - ml_training_1985044919168 - INFO - Epoch   4 | Train Loss: 0.8784 | Train Acc: 89.79% | Val Loss: 0.6662 | Val Acc: 95.56% | LR: 1.00e-03
2025-08-15 21:32:18,700 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_5
2025-08-15 21:32:18,707 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.7791, Acc=90.62%
2025-08-15 21:32:19,022 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.7782, Acc=91.85%
2025-08-15 21:32:19,073 - ml_training_1985044919168 - INFO - Timer 'train_epoch_5': 0.3730 seconds
2025-08-15 21:32:19,073 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_5
2025-08-15 21:32:19,091 - ml_training_1985044919168 - INFO - Timer 'val_epoch_5': 0.0181 seconds
2025-08-15 21:32:19,091 - ml_training_1985044919168 - INFO - Epoch   5 | Train Loss: 0.8296 | Train Acc: 92.28% | Val Loss: 0.6461 | Val Acc: 96.30% | LR: 1.00e-03
2025-08-15 21:32:19,104 - ml_training_1985044919168 - INFO - Checkpoint saved at epoch 5
2025-08-15 21:32:19,105 - ml_training_1985044919168 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:32:19,105 - ml_training_1985044919168 - INFO - Checkpoint metrics: {'val_acc': 96.29629629629629, 'val_loss': 0.6460868981149461}
2025-08-15 21:32:19,105 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_6
2025-08-15 21:32:19,112 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.7384, Acc=93.75%
2025-08-15 21:32:19,424 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.8188, Acc=92.89%
2025-08-15 21:32:19,482 - ml_training_1985044919168 - INFO - Timer 'train_epoch_6': 0.3772 seconds
2025-08-15 21:32:19,483 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_6
2025-08-15 21:32:19,502 - ml_training_1985044919168 - INFO - Timer 'val_epoch_6': 0.0191 seconds
2025-08-15 21:32:19,502 - ml_training_1985044919168 - INFO - Epoch   6 | Train Loss: 0.7865 | Train Acc: 92.80% | Val Loss: 0.6246 | Val Acc: 97.04% | LR: 1.00e-03
2025-08-15 21:32:19,522 - ml_training_1985044919168 - INFO - Checkpoint saved at epoch 6
2025-08-15 21:32:19,522 - ml_training_1985044919168 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:32:19,522 - ml_training_1985044919168 - INFO - Checkpoint metrics: {'val_acc': 97.03703703703704, 'val_loss': 0.6245635483000014}
2025-08-15 21:32:19,523 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_7
2025-08-15 21:32:19,529 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.8732, Acc=90.62%
2025-08-15 21:32:19,828 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.7307, Acc=94.98%
2025-08-15 21:32:19,878 - ml_training_1985044919168 - INFO - Timer 'train_epoch_7': 0.3553 seconds
2025-08-15 21:32:19,878 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_7
2025-08-15 21:32:19,897 - ml_training_1985044919168 - INFO - Timer 'val_epoch_7': 0.0186 seconds
2025-08-15 21:32:19,897 - ml_training_1985044919168 - INFO - Epoch   7 | Train Loss: 0.7522 | Train Acc: 94.66% | Val Loss: 0.6114 | Val Acc: 97.04% | LR: 1.00e-03
2025-08-15 21:32:19,898 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_8
2025-08-15 21:32:19,906 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6856, Acc=100.00%
2025-08-15 21:32:20,197 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6428, Acc=95.28%
2025-08-15 21:32:20,250 - ml_training_1985044919168 - INFO - Timer 'train_epoch_8': 0.3528 seconds
2025-08-15 21:32:20,250 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_8
2025-08-15 21:32:20,269 - ml_training_1985044919168 - INFO - Timer 'val_epoch_8': 0.0186 seconds
2025-08-15 21:32:20,269 - ml_training_1985044919168 - INFO - Epoch   8 | Train Loss: 0.7280 | Train Acc: 95.08% | Val Loss: 0.6067 | Val Acc: 98.15% | LR: 1.00e-03
2025-08-15 21:32:20,283 - ml_training_1985044919168 - INFO - Checkpoint saved at epoch 8
2025-08-15 21:32:20,283 - ml_training_1985044919168 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:32:20,284 - ml_training_1985044919168 - INFO - Checkpoint metrics: {'val_acc': 98.14814814814815, 'val_loss': 0.6066566904385885}
2025-08-15 21:32:20,284 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_9
2025-08-15 21:32:20,294 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.7895, Acc=90.62%
2025-08-15 21:32:20,620 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6941, Acc=95.22%
2025-08-15 21:32:20,673 - ml_training_1985044919168 - INFO - Timer 'train_epoch_9': 0.3886 seconds
2025-08-15 21:32:20,674 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_9
2025-08-15 21:32:20,692 - ml_training_1985044919168 - INFO - Timer 'val_epoch_9': 0.0181 seconds
2025-08-15 21:32:20,692 - ml_training_1985044919168 - INFO - Epoch   9 | Train Loss: 0.7285 | Train Acc: 95.13% | Val Loss: 0.6151 | Val Acc: 97.04% | LR: 1.00e-03
2025-08-15 21:32:20,693 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_10
2025-08-15 21:32:20,700 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6759, Acc=96.88%
2025-08-15 21:32:20,987 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.7383, Acc=96.14%
2025-08-15 21:32:21,038 - ml_training_1985044919168 - INFO - Timer 'train_epoch_10': 0.3452 seconds
2025-08-15 21:32:21,039 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_10
2025-08-15 21:32:21,058 - ml_training_1985044919168 - INFO - Timer 'val_epoch_10': 0.0186 seconds
2025-08-15 21:32:21,059 - ml_training_1985044919168 - INFO - Epoch  10 | Train Loss: 0.7000 | Train Acc: 96.24% | Val Loss: 0.6026 | Val Acc: 97.41% | LR: 1.00e-03
2025-08-15 21:32:21,067 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_11
2025-08-15 21:32:21,074 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.7099, Acc=96.88%
2025-08-15 21:32:21,360 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6889, Acc=97.06%
2025-08-15 21:32:21,410 - ml_training_1985044919168 - INFO - Timer 'train_epoch_11': 0.3435 seconds
2025-08-15 21:32:21,410 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_11
2025-08-15 21:32:21,429 - ml_training_1985044919168 - INFO - Timer 'val_epoch_11': 0.0191 seconds
2025-08-15 21:32:21,429 - ml_training_1985044919168 - INFO - Epoch  11 | Train Loss: 0.6853 | Train Acc: 96.72% | Val Loss: 0.5801 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:32:21,444 - ml_training_1985044919168 - INFO - Checkpoint saved at epoch 11
2025-08-15 21:32:21,445 - ml_training_1985044919168 - INFO - Model path: models\mfcc_classifier\best_model.pt
2025-08-15 21:32:21,445 - ml_training_1985044919168 - INFO - Checkpoint metrics: {'val_acc': 98.51851851851852, 'val_loss': 0.5800960858662924}
2025-08-15 21:32:21,445 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_12
2025-08-15 21:32:21,453 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6423, Acc=100.00%
2025-08-15 21:32:21,759 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6609, Acc=97.61%
2025-08-15 21:32:21,820 - ml_training_1985044919168 - INFO - Timer 'train_epoch_12': 0.3751 seconds
2025-08-15 21:32:21,820 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_12
2025-08-15 21:32:21,837 - ml_training_1985044919168 - INFO - Timer 'val_epoch_12': 0.0171 seconds
2025-08-15 21:32:21,838 - ml_training_1985044919168 - INFO - Epoch  12 | Train Loss: 0.6900 | Train Acc: 97.46% | Val Loss: 0.5825 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:32:21,838 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_13
2025-08-15 21:32:21,844 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6222, Acc=100.00%
2025-08-15 21:32:22,140 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6617, Acc=97.61%
2025-08-15 21:32:22,193 - ml_training_1985044919168 - INFO - Timer 'train_epoch_13': 0.3549 seconds
2025-08-15 21:32:22,194 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_13
2025-08-15 21:32:22,210 - ml_training_1985044919168 - INFO - Timer 'val_epoch_13': 0.0161 seconds
2025-08-15 21:32:22,211 - ml_training_1985044919168 - INFO - Epoch  13 | Train Loss: 0.6803 | Train Acc: 97.57% | Val Loss: 0.5990 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:32:22,211 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_14
2025-08-15 21:32:22,219 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6285, Acc=96.88%
2025-08-15 21:32:22,513 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.5984, Acc=98.16%
2025-08-15 21:32:22,575 - ml_training_1985044919168 - INFO - Timer 'train_epoch_14': 0.3642 seconds
2025-08-15 21:32:22,575 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_14
2025-08-15 21:32:22,600 - ml_training_1985044919168 - INFO - Timer 'val_epoch_14': 0.0241 seconds
2025-08-15 21:32:22,600 - ml_training_1985044919168 - INFO - Epoch  14 | Train Loss: 0.6508 | Train Acc: 98.15% | Val Loss: 0.5867 | Val Acc: 98.15% | LR: 1.00e-03
2025-08-15 21:32:22,601 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_15
2025-08-15 21:32:22,610 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6642, Acc=96.88%
2025-08-15 21:32:22,963 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6431, Acc=98.10%
2025-08-15 21:32:23,022 - ml_training_1985044919168 - INFO - Timer 'train_epoch_15': 0.4218 seconds
2025-08-15 21:32:23,022 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_15
2025-08-15 21:32:23,041 - ml_training_1985044919168 - INFO - Timer 'val_epoch_15': 0.0187 seconds
2025-08-15 21:32:23,042 - ml_training_1985044919168 - INFO - Epoch  15 | Train Loss: 0.6488 | Train Acc: 97.94% | Val Loss: 0.5781 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:32:23,042 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_16
2025-08-15 21:32:23,050 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6961, Acc=96.88%
2025-08-15 21:32:23,352 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.7296, Acc=97.37%
2025-08-15 21:32:23,410 - ml_training_1985044919168 - INFO - Timer 'train_epoch_16': 0.3683 seconds
2025-08-15 21:32:23,410 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_16
2025-08-15 21:32:23,430 - ml_training_1985044919168 - INFO - Timer 'val_epoch_16': 0.0196 seconds
2025-08-15 21:32:23,431 - ml_training_1985044919168 - INFO - Epoch  16 | Train Loss: 0.6751 | Train Acc: 97.46% | Val Loss: 0.5804 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:32:23,431 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_17
2025-08-15 21:32:23,443 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6278, Acc=100.00%
2025-08-15 21:32:23,749 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6757, Acc=98.04%
2025-08-15 21:32:23,800 - ml_training_1985044919168 - INFO - Timer 'train_epoch_17': 0.3691 seconds
2025-08-15 21:32:23,801 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_17
2025-08-15 21:32:23,820 - ml_training_1985044919168 - INFO - Timer 'val_epoch_17': 0.0191 seconds
2025-08-15 21:32:23,821 - ml_training_1985044919168 - INFO - Epoch  17 | Train Loss: 0.6906 | Train Acc: 97.83% | Val Loss: 0.5806 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:32:23,821 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_18
2025-08-15 21:32:23,831 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6355, Acc=100.00%
2025-08-15 21:32:24,118 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6510, Acc=98.65%
2025-08-15 21:32:24,172 - ml_training_1985044919168 - INFO - Timer 'train_epoch_18': 0.3510 seconds
2025-08-15 21:32:24,172 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_18
2025-08-15 21:32:24,190 - ml_training_1985044919168 - INFO - Timer 'val_epoch_18': 0.0181 seconds
2025-08-15 21:32:24,191 - ml_training_1985044919168 - INFO - Epoch  18 | Train Loss: 0.6422 | Train Acc: 98.62% | Val Loss: 0.5728 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:32:24,191 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_19
2025-08-15 21:32:24,198 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6342, Acc=96.88%
2025-08-15 21:32:24,488 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6427, Acc=97.61%
2025-08-15 21:32:24,540 - ml_training_1985044919168 - INFO - Timer 'train_epoch_19': 0.3490 seconds
2025-08-15 21:32:24,541 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_19
2025-08-15 21:32:24,561 - ml_training_1985044919168 - INFO - Timer 'val_epoch_19': 0.0201 seconds
2025-08-15 21:32:24,561 - ml_training_1985044919168 - INFO - Epoch  19 | Train Loss: 0.6446 | Train Acc: 97.72% | Val Loss: 0.5636 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:32:24,562 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_20
2025-08-15 21:32:24,570 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6601, Acc=93.75%
2025-08-15 21:32:24,849 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.7401, Acc=98.41%
2025-08-15 21:32:24,903 - ml_training_1985044919168 - INFO - Timer 'train_epoch_20': 0.3391 seconds
2025-08-15 21:32:24,903 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_20
2025-08-15 21:32:24,922 - ml_training_1985044919168 - INFO - Timer 'val_epoch_20': 0.0199 seconds
2025-08-15 21:32:24,922 - ml_training_1985044919168 - INFO - Epoch  20 | Train Loss: 0.6362 | Train Acc: 98.31% | Val Loss: 0.5715 | Val Acc: 98.15% | LR: 1.00e-03
2025-08-15 21:32:24,932 - ml_training_1985044919168 - DEBUG - Timer started: train_epoch_21
2025-08-15 21:32:24,940 - ml_training_1985044919168 - DEBUG - Batch 0/60: Loss=0.6227, Acc=100.00%
2025-08-15 21:32:25,221 - ml_training_1985044919168 - DEBUG - Batch 50/60: Loss=0.6304, Acc=98.41%
2025-08-15 21:32:25,280 - ml_training_1985044919168 - INFO - Timer 'train_epoch_21': 0.3484 seconds
2025-08-15 21:32:25,281 - ml_training_1985044919168 - DEBUG - Timer started: val_epoch_21
2025-08-15 21:32:25,299 - ml_training_1985044919168 - INFO - Timer 'val_epoch_21': 0.0181 seconds
2025-08-15 21:32:25,299 - ml_training_1985044919168 - INFO - Epoch  21 | Train Loss: 0.6353 | Train Acc: 98.41% | Val Loss: 0.5673 | Val Acc: 98.15% | LR: 1.00e-03
2025-08-15 21:32:25,299 - ml_training_1985044919168 - INFO - Early stopping triggered at epoch 21 (patience: 10)
2025-08-15 21:32:25,299 - ml_training_1985044919168 - INFO - Training completed. Evaluating on test set...
2025-08-15 21:32:25,328 - ml_training_1985044919168 - INFO - Loaded checkpoint from epoch 11
2025-08-15 21:32:25,328 - ml_training_1985044919168 - DEBUG - Timer started: test_evaluation
2025-08-15 21:32:25,371 - ml_training_1985044919168 - INFO - Timer 'test_evaluation': 0.0426 seconds
2025-08-15 21:32:25,380 - ml_training_1985044919168 - INFO - === TEST RESULTS ===
2025-08-15 21:32:25,381 - ml_training_1985044919168 - INFO - Test Accuracy: 0.9852
2025-08-15 21:32:25,381 - ml_training_1985044919168 - INFO - Test Loss: 0.5798
2025-08-15 21:32:25,381 - ml_training_1985044919168 - INFO - Classification Report:
2025-08-15 21:32:25,381 - ml_training_1985044919168 - INFO -                 precision    recall  f1-score   support
2025-08-15 21:32:25,382 - ml_training_1985044919168 - INFO -              0     1.0000    1.0000    1.0000        54
2025-08-15 21:32:25,382 - ml_training_1985044919168 - INFO -              1     1.0000    0.9444    0.9714        54
2025-08-15 21:32:25,382 - ml_training_1985044919168 - INFO -              2     0.9818    1.0000    0.9908        54
2025-08-15 21:32:25,382 - ml_training_1985044919168 - INFO -              3     1.0000    0.9630    0.9811        54
2025-08-15 21:32:25,382 - ml_training_1985044919168 - INFO -              4     0.9818    1.0000    0.9908        54
2025-08-15 21:32:25,383 - ml_training_1985044919168 - INFO -              5     0.9818    1.0000    0.9908        54
2025-08-15 21:32:25,383 - ml_training_1985044919168 - INFO -              6     0.9818    1.0000    0.9908        54
2025-08-15 21:32:25,383 - ml_training_1985044919168 - INFO -              7     1.0000    0.9444    0.9714        54
2025-08-15 21:32:25,383 - ml_training_1985044919168 - INFO -              8     0.9643    1.0000    0.9818        54
2025-08-15 21:32:25,383 - ml_training_1985044919168 - INFO -              9     0.9643    1.0000    0.9818        54
2025-08-15 21:32:25,383 - ml_training_1985044919168 - INFO -       accuracy                         0.9852       540
2025-08-15 21:32:25,384 - ml_training_1985044919168 - INFO -      macro avg     0.9856    0.9852    0.9851       540
2025-08-15 21:32:25,384 - ml_training_1985044919168 - INFO -   weighted avg     0.9856    0.9852    0.9851       540
2025-08-15 21:32:25,384 - ml_training_1985044919168 - INFO - === END TEST RESULTS ===
2025-08-15 21:32:26,479 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mfcc_classifier\training_history_mfcc_classifier_training_history.png
2025-08-15 21:32:27,073 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:32:27,073 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:32:28,257 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mfcc_classifier\confusion_matrix_mfcc_classifier_confusion_matrix.png
2025-08-15 21:32:28,257 - ml_training_1985044919168 - INFO - Visualizations generated successfully
2025-08-15 21:32:28,257 - ml_training_1985044919168 - INFO - Closing ML Training Logger
2025-08-15 21:32:28,260 - ml_training_1985044919168 - INFO - Metrics summary saved to: train_logs\metrics_summary_mfcc_classifier_20250815_213215.json
2025-08-15 21:32:28,260 - __main__ - INFO - mfcc training completed:
2025-08-15 21:32:28,260 - __main__ - INFO -   Best val accuracy: 98.5185
2025-08-15 21:32:28,260 - __main__ - INFO -   Test accuracy: 0.9852
2025-08-15 21:32:28,261 - __main__ - INFO - Training mel_cnn pipeline...
2025-08-15 21:32:28,261 - ml_training.pipelines.mel_cnn_pipeline - INFO - Setting up Mel Spectrogram CNN pipeline...
2025-08-15 21:32:28,268 - ml_training.pipelines.mel_cnn_pipeline - INFO - Mel Spectrogram Extractor initialized:
2025-08-15 21:32:28,269 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Expected output shape: (64, 51)
2025-08-15 21:32:28,269 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Device: cuda
2025-08-15 21:32:28,269 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Frequency range: 0-4000 Hz
2025-08-15 21:32:28,269 - ml_training.pipelines.mel_cnn_pipeline - INFO - Precomputing mel spectrograms for 1890 samples...
2025-08-15 21:32:28,872 - ml_training.pipelines.mel_cnn_pipeline - INFO - Spectrogram precomputation completed
2025-08-15 21:32:28,872 - ml_training.pipelines.mel_cnn_pipeline - INFO - Precomputing mel spectrograms for 540 samples...
2025-08-15 21:32:28,943 - ml_training.pipelines.mel_cnn_pipeline - INFO - Spectrogram precomputation completed
2025-08-15 21:32:28,943 - ml_training.pipelines.mel_cnn_pipeline - INFO - Precomputing mel spectrograms for 270 samples...
2025-08-15 21:32:28,981 - ml_training.pipelines.mel_cnn_pipeline - INFO - Spectrogram precomputation completed
2025-08-15 21:32:28,991 - ml_training.pipelines.mel_cnn_pipeline - INFO - Mel Spectrogram CNN initialized:
2025-08-15 21:32:28,991 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Input shape: (1, 64, 51)
2025-08-15 21:32:28,992 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Architecture: Conv(32->64->128->256) -> Global Pool -> FC(512->256->10)
2025-08-15 21:32:28,992 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Total parameters: 653,802
2025-08-15 21:32:28,996 - ml_training.pipelines.mel_cnn_pipeline - INFO - Mel CNN pipeline setup completed:
2025-08-15 21:32:28,996 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Device: cuda
2025-08-15 21:32:28,996 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Train samples: 1890
2025-08-15 21:32:28,996 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Val samples: 270
2025-08-15 21:32:28,996 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Test samples: 540
2025-08-15 21:32:28,996 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Batch size: 16
2025-08-15 21:32:28,996 - ml_training.pipelines.mel_cnn_pipeline - INFO -   Spectrogram shape: (64, 51)
2025-08-15 21:32:28,998 - ml_training_1987073432496 - INFO - ML Training Logger initialized - Log file: train_logs\mel_cnn_classifier_20250815_213228.log
2025-08-15 21:32:28,998 - ml_training_1987073432496 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:32:28,998 - ml_training_1987073432496 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:32:28,999 - ml_training_1987073432496 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:32:28,999 - ml_training_1987073432496 - INFO - NumPy Version: 1.26.4
2025-08-15 21:32:28,999 - ml_training_1987073432496 - INFO - Librosa Version: 0.10.2
2025-08-15 21:32:28,999 - ml_training_1987073432496 - INFO - CUDA Available: Yes
2025-08-15 21:32:29,003 - ml_training_1987073432496 - INFO - CUDA Version: 12.1
2025-08-15 21:32:29,004 - ml_training_1987073432496 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:32:29,004 - ml_training_1987073432496 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:32:29,004 - ml_training_1987073432496 - INFO - === END SYSTEM INFO ===
2025-08-15 21:32:29,006 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\mel_cnn_classifier
2025-08-15 21:32:29,006 - ml_training_1987073432496 - INFO - Trainer initialized for mel_cnn_classifier
2025-08-15 21:32:29,006 - ml_training_1987073432496 - INFO - === MEL_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:32:29,007 - ml_training_1987073432496 - INFO - Total Parameters: 653,802
2025-08-15 21:32:29,007 - ml_training_1987073432496 - INFO - Trainable Parameters: 653,802
2025-08-15 21:32:29,007 - ml_training_1987073432496 - INFO - Non-trainable Parameters: 0
2025-08-15 21:32:29,007 - ml_training_1987073432496 - INFO - Model Architecture:
2025-08-15 21:32:29,008 - ml_training_1987073432496 - INFO -   conv1: Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:32:29,008 - ml_training_1987073432496 - INFO -   conv2: Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:32:29,008 - ml_training_1987073432496 - INFO -   conv3: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:32:29,008 - ml_training_1987073432496 - INFO -   conv4: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
2025-08-15 21:32:29,009 - ml_training_1987073432496 - INFO -   bn1: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:32:29,009 - ml_training_1987073432496 - INFO -   bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:32:29,009 - ml_training_1987073432496 - INFO -   bn3: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:32:29,010 - ml_training_1987073432496 - INFO -   bn4: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:32:29,010 - ml_training_1987073432496 - INFO -   pool: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
2025-08-15 21:32:29,010 - ml_training_1987073432496 - INFO -   dropout2d: Dropout2d(p=0.2, inplace=False)
2025-08-15 21:32:29,010 - ml_training_1987073432496 - INFO -   dropout: Dropout(p=0.3, inplace=False)
2025-08-15 21:32:29,011 - ml_training_1987073432496 - INFO -   global_pool: AdaptiveAvgPool2d(output_size=(1, 1))
2025-08-15 21:32:29,011 - ml_training_1987073432496 - INFO -   fc1: Linear(in_features=256, out_features=512, bias=True)
2025-08-15 21:32:29,011 - ml_training_1987073432496 - INFO -   fc2: Linear(in_features=512, out_features=256, bias=True)
2025-08-15 21:32:29,011 - ml_training_1987073432496 - INFO -   fc3: Linear(in_features=256, out_features=10, bias=True)
2025-08-15 21:32:29,011 - ml_training_1987073432496 - INFO - === END MEL_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:32:29,012 - ml_training_1987073432496 - INFO - === EXPERIMENT CONFIGURATION ===
2025-08-15 21:32:29,012 - ml_training_1987073432496 - INFO - learning_rate: 0.001
2025-08-15 21:32:29,013 - ml_training_1987073432496 - INFO - weight_decay: 0.0001
2025-08-15 21:32:29,013 - ml_training_1987073432496 - INFO - scheduler_type: plateau
2025-08-15 21:32:29,013 - ml_training_1987073432496 - INFO - early_stopping_patience: 10
2025-08-15 21:32:29,013 - ml_training_1987073432496 - INFO - gradient_clipping: 1.0
2025-08-15 21:32:29,014 - ml_training_1987073432496 - INFO - mixed_precision: True
2025-08-15 21:32:29,014 - ml_training_1987073432496 - INFO - optimizer: Adam
2025-08-15 21:32:29,014 - ml_training_1987073432496 - INFO - loss_function: CrossEntropyLoss with label smoothing
2025-08-15 21:32:29,014 - ml_training_1987073432496 - INFO - device: cuda
2025-08-15 21:32:29,016 - ml_training_1987073432496 - INFO - Configuration saved to: train_logs\config_mel_cnn_classifier_20250815_213228.json
2025-08-15 21:32:29,016 - ml_training_1987073432496 - INFO - === END CONFIGURATION ===
2025-08-15 21:32:29,016 - ml_training_1987073432496 - INFO - Starting training for 50 epochs
2025-08-15 21:32:29,016 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_1
2025-08-15 21:32:29,254 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=2.5753, Acc=18.75%
2025-08-15 21:32:29,858 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=2.4904, Acc=13.48%
2025-08-15 21:32:30,486 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=2.3842, Acc=13.30%
2025-08-15 21:32:30,754 - ml_training_1987073432496 - INFO - Timer 'train_epoch_1': 1.7379 seconds
2025-08-15 21:32:30,755 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_1
2025-08-15 21:32:30,835 - ml_training_1987073432496 - INFO - Timer 'val_epoch_1': 0.0807 seconds
2025-08-15 21:32:30,835 - ml_training_1987073432496 - INFO - Epoch   1 | Train Loss: 2.3504 | Train Acc: 13.44% | Val Loss: 2.1727 | Val Acc: 18.15% | LR: 1.00e-03
2025-08-15 21:32:30,884 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 1
2025-08-15 21:32:30,886 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:30,886 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 18.14814814814815, 'val_loss': 2.17273845392115}
2025-08-15 21:32:30,886 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_2
2025-08-15 21:32:30,901 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=2.3949, Acc=6.25%
2025-08-15 21:32:31,592 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=2.0347, Acc=16.05%
2025-08-15 21:32:32,238 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=2.2001, Acc=17.39%
2025-08-15 21:32:32,486 - ml_training_1987073432496 - INFO - Timer 'train_epoch_2': 1.6001 seconds
2025-08-15 21:32:32,488 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_2
2025-08-15 21:32:32,549 - ml_training_1987073432496 - INFO - Timer 'val_epoch_2': 0.0616 seconds
2025-08-15 21:32:32,550 - ml_training_1987073432496 - INFO - Epoch   2 | Train Loss: 2.2077 | Train Acc: 18.15% | Val Loss: 2.0686 | Val Acc: 22.22% | LR: 1.00e-03
2025-08-15 21:32:32,597 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 2
2025-08-15 21:32:32,597 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:32,597 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 22.22222222222222, 'val_loss': 2.0685665747698616}
2025-08-15 21:32:32,597 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_3
2025-08-15 21:32:32,614 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=2.1475, Acc=18.75%
2025-08-15 21:32:33,308 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=2.0089, Acc=21.08%
2025-08-15 21:32:33,958 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.9946, Acc=22.83%
2025-08-15 21:32:34,213 - ml_training_1987073432496 - INFO - Timer 'train_epoch_3': 1.6152 seconds
2025-08-15 21:32:34,213 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_3
2025-08-15 21:32:34,287 - ml_training_1987073432496 - INFO - Timer 'val_epoch_3': 0.0739 seconds
2025-08-15 21:32:34,288 - ml_training_1987073432496 - INFO - Epoch   3 | Train Loss: 2.0800 | Train Acc: 23.60% | Val Loss: 1.9123 | Val Acc: 28.52% | LR: 1.00e-03
2025-08-15 21:32:34,344 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 3
2025-08-15 21:32:34,344 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:34,346 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 28.51851851851852, 'val_loss': 1.9123169323977303}
2025-08-15 21:32:34,346 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_4
2025-08-15 21:32:34,362 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=2.0327, Acc=12.50%
2025-08-15 21:32:34,985 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=2.2492, Acc=31.74%
2025-08-15 21:32:35,620 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.7313, Acc=31.87%
2025-08-15 21:32:35,833 - ml_training_1987073432496 - INFO - Timer 'train_epoch_4': 1.4875 seconds
2025-08-15 21:32:35,834 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_4
2025-08-15 21:32:35,902 - ml_training_1987073432496 - INFO - Timer 'val_epoch_4': 0.0673 seconds
2025-08-15 21:32:35,903 - ml_training_1987073432496 - INFO - Epoch   4 | Train Loss: 1.9913 | Train Acc: 31.75% | Val Loss: 1.8028 | Val Acc: 42.59% | LR: 1.00e-03
2025-08-15 21:32:35,959 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 4
2025-08-15 21:32:35,959 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:35,960 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 42.592592592592595, 'val_loss': 1.8027780616984648}
2025-08-15 21:32:35,961 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_5
2025-08-15 21:32:35,974 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=2.1921, Acc=31.25%
2025-08-15 21:32:36,579 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=2.3163, Acc=33.09%
2025-08-15 21:32:37,198 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.8300, Acc=34.96%
2025-08-15 21:32:37,406 - ml_training_1987073432496 - INFO - Timer 'train_epoch_5': 1.4451 seconds
2025-08-15 21:32:37,407 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_5
2025-08-15 21:32:37,485 - ml_training_1987073432496 - INFO - Timer 'val_epoch_5': 0.0773 seconds
2025-08-15 21:32:37,486 - ml_training_1987073432496 - INFO - Epoch   5 | Train Loss: 1.8758 | Train Acc: 35.24% | Val Loss: 1.6614 | Val Acc: 43.70% | LR: 1.00e-03
2025-08-15 21:32:37,540 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 5
2025-08-15 21:32:37,540 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:37,541 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 43.7037037037037, 'val_loss': 1.6613729070214664}
2025-08-15 21:32:37,541 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_6
2025-08-15 21:32:37,556 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.8851, Acc=18.75%
2025-08-15 21:32:38,156 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.6454, Acc=41.54%
2025-08-15 21:32:38,814 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.6264, Acc=40.59%
2025-08-15 21:32:39,067 - ml_training_1987073432496 - INFO - Timer 'train_epoch_6': 1.5251 seconds
2025-08-15 21:32:39,067 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_6
2025-08-15 21:32:39,142 - ml_training_1987073432496 - INFO - Timer 'val_epoch_6': 0.0757 seconds
2025-08-15 21:32:39,142 - ml_training_1987073432496 - INFO - Epoch   6 | Train Loss: 1.7312 | Train Acc: 41.53% | Val Loss: 1.4352 | Val Acc: 55.93% | LR: 1.00e-03
2025-08-15 21:32:39,187 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 6
2025-08-15 21:32:39,187 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:39,188 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 55.925925925925924, 'val_loss': 1.4351904251996208}
2025-08-15 21:32:39,188 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_7
2025-08-15 21:32:39,202 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.9763, Acc=25.00%
2025-08-15 21:32:39,876 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.6830, Acc=49.51%
2025-08-15 21:32:40,483 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.6794, Acc=49.75%
2025-08-15 21:32:40,696 - ml_training_1987073432496 - INFO - Timer 'train_epoch_7': 1.5079 seconds
2025-08-15 21:32:40,696 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_7
2025-08-15 21:32:40,783 - ml_training_1987073432496 - INFO - Timer 'val_epoch_7': 0.0867 seconds
2025-08-15 21:32:40,784 - ml_training_1987073432496 - INFO - Epoch   7 | Train Loss: 1.5828 | Train Acc: 50.69% | Val Loss: 1.2123 | Val Acc: 68.89% | LR: 1.00e-03
2025-08-15 21:32:40,829 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 7
2025-08-15 21:32:40,830 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:40,830 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 68.88888888888889, 'val_loss': 1.2123489169513477}
2025-08-15 21:32:40,831 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_8
2025-08-15 21:32:40,845 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.5196, Acc=56.25%
2025-08-15 21:32:41,484 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.6623, Acc=56.25%
2025-08-15 21:32:42,123 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.2644, Acc=55.88%
2025-08-15 21:32:42,357 - ml_training_1987073432496 - INFO - Timer 'train_epoch_8': 1.5255 seconds
2025-08-15 21:32:42,357 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_8
2025-08-15 21:32:42,421 - ml_training_1987073432496 - INFO - Timer 'val_epoch_8': 0.0643 seconds
2025-08-15 21:32:42,421 - ml_training_1987073432496 - INFO - Epoch   8 | Train Loss: 1.4589 | Train Acc: 56.35% | Val Loss: 1.1323 | Val Acc: 68.89% | LR: 1.00e-03
2025-08-15 21:32:42,422 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_9
2025-08-15 21:32:42,439 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.2955, Acc=56.25%
2025-08-15 21:32:43,058 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.3471, Acc=58.33%
2025-08-15 21:32:43,734 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.5900, Acc=60.33%
2025-08-15 21:32:43,967 - ml_training_1987073432496 - INFO - Timer 'train_epoch_9': 1.5454 seconds
2025-08-15 21:32:43,967 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_9
2025-08-15 21:32:44,048 - ml_training_1987073432496 - INFO - Timer 'val_epoch_9': 0.0811 seconds
2025-08-15 21:32:44,049 - ml_training_1987073432496 - INFO - Epoch   9 | Train Loss: 1.3568 | Train Acc: 60.85% | Val Loss: 1.0164 | Val Acc: 79.26% | LR: 1.00e-03
2025-08-15 21:32:44,097 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 9
2025-08-15 21:32:44,098 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:44,098 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 79.25925925925925, 'val_loss': 1.0164191898177652}
2025-08-15 21:32:44,098 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_10
2025-08-15 21:32:44,116 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.2000, Acc=75.00%
2025-08-15 21:32:44,726 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.0972, Acc=62.62%
2025-08-15 21:32:45,309 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.1737, Acc=64.67%
2025-08-15 21:32:45,527 - ml_training_1987073432496 - INFO - Timer 'train_epoch_10': 1.4292 seconds
2025-08-15 21:32:45,528 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_10
2025-08-15 21:32:45,593 - ml_training_1987073432496 - INFO - Timer 'val_epoch_10': 0.0647 seconds
2025-08-15 21:32:45,593 - ml_training_1987073432496 - INFO - Epoch  10 | Train Loss: 1.2695 | Train Acc: 65.71% | Val Loss: 0.9411 | Val Acc: 82.59% | LR: 1.00e-03
2025-08-15 21:32:45,641 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 10
2025-08-15 21:32:45,642 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:45,642 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 82.5925925925926, 'val_loss': 0.9410921159912559}
2025-08-15 21:32:45,643 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_11
2025-08-15 21:32:45,662 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.9083, Acc=68.75%
2025-08-15 21:32:46,310 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.3038, Acc=68.50%
2025-08-15 21:32:46,916 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.2367, Acc=69.93%
2025-08-15 21:32:47,141 - ml_training_1987073432496 - INFO - Timer 'train_epoch_11': 1.4981 seconds
2025-08-15 21:32:47,142 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_11
2025-08-15 21:32:47,204 - ml_training_1987073432496 - INFO - Timer 'val_epoch_11': 0.0616 seconds
2025-08-15 21:32:47,206 - ml_training_1987073432496 - INFO - Epoch  11 | Train Loss: 1.1819 | Train Acc: 69.47% | Val Loss: 0.9121 | Val Acc: 80.74% | LR: 1.00e-03
2025-08-15 21:32:47,206 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_12
2025-08-15 21:32:47,222 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.2443, Acc=75.00%
2025-08-15 21:32:47,830 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.9680, Acc=72.92%
2025-08-15 21:32:48,423 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.9977, Acc=72.77%
2025-08-15 21:32:48,668 - ml_training_1987073432496 - INFO - Timer 'train_epoch_12': 1.4622 seconds
2025-08-15 21:32:48,669 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_12
2025-08-15 21:32:48,746 - ml_training_1987073432496 - INFO - Timer 'val_epoch_12': 0.0777 seconds
2025-08-15 21:32:48,747 - ml_training_1987073432496 - INFO - Epoch  12 | Train Loss: 1.1274 | Train Acc: 73.76% | Val Loss: 0.8850 | Val Acc: 85.93% | LR: 1.00e-03
2025-08-15 21:32:48,794 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 12
2025-08-15 21:32:48,795 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:48,795 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 85.92592592592592, 'val_loss': 0.885048929382773}
2025-08-15 21:32:48,796 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_13
2025-08-15 21:32:48,809 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.0335, Acc=75.00%
2025-08-15 21:32:49,418 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.0957, Acc=75.61%
2025-08-15 21:32:50,041 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.9575, Acc=75.43%
2025-08-15 21:32:50,284 - ml_training_1987073432496 - INFO - Timer 'train_epoch_13': 1.4884 seconds
2025-08-15 21:32:50,285 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_13
2025-08-15 21:32:50,359 - ml_training_1987073432496 - INFO - Timer 'val_epoch_13': 0.0736 seconds
2025-08-15 21:32:50,360 - ml_training_1987073432496 - INFO - Epoch  13 | Train Loss: 1.0867 | Train Acc: 75.50% | Val Loss: 0.7884 | Val Acc: 92.22% | LR: 1.00e-03
2025-08-15 21:32:50,408 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 13
2025-08-15 21:32:50,409 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:50,409 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 92.22222222222223, 'val_loss': 0.7883973016458399}
2025-08-15 21:32:50,410 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_14
2025-08-15 21:32:50,425 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.0877, Acc=75.00%
2025-08-15 21:32:51,006 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.7068, Acc=79.29%
2025-08-15 21:32:51,610 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.1879, Acc=79.33%
2025-08-15 21:32:51,854 - ml_training_1987073432496 - INFO - Timer 'train_epoch_14': 1.4441 seconds
2025-08-15 21:32:51,855 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_14
2025-08-15 21:32:51,937 - ml_training_1987073432496 - INFO - Timer 'val_epoch_14': 0.0811 seconds
2025-08-15 21:32:51,937 - ml_training_1987073432496 - INFO - Epoch  14 | Train Loss: 1.0318 | Train Acc: 78.68% | Val Loss: 0.7345 | Val Acc: 94.44% | LR: 1.00e-03
2025-08-15 21:32:51,974 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 14
2025-08-15 21:32:51,975 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:51,975 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 94.44444444444444, 'val_loss': 0.7344768503132988}
2025-08-15 21:32:51,975 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_15
2025-08-15 21:32:51,991 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.8847, Acc=93.75%
2025-08-15 21:32:52,634 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.1554, Acc=81.99%
2025-08-15 21:32:53,277 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.2084, Acc=80.26%
2025-08-15 21:32:53,495 - ml_training_1987073432496 - INFO - Timer 'train_epoch_15': 1.5192 seconds
2025-08-15 21:32:53,495 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_15
2025-08-15 21:32:53,573 - ml_training_1987073432496 - INFO - Timer 'val_epoch_15': 0.0782 seconds
2025-08-15 21:32:53,574 - ml_training_1987073432496 - INFO - Epoch  15 | Train Loss: 0.9978 | Train Acc: 80.58% | Val Loss: 0.7450 | Val Acc: 94.07% | LR: 1.00e-03
2025-08-15 21:32:53,574 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_16
2025-08-15 21:32:53,588 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.7368, Acc=100.00%
2025-08-15 21:32:54,251 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.0085, Acc=84.07%
2025-08-15 21:32:54,870 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.8318, Acc=83.97%
2025-08-15 21:32:55,106 - ml_training_1987073432496 - INFO - Timer 'train_epoch_16': 1.5320 seconds
2025-08-15 21:32:55,107 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_16
2025-08-15 21:32:55,168 - ml_training_1987073432496 - INFO - Timer 'val_epoch_16': 0.0601 seconds
2025-08-15 21:32:55,168 - ml_training_1987073432496 - INFO - Epoch  16 | Train Loss: 0.9287 | Train Acc: 84.02% | Val Loss: 0.7053 | Val Acc: 93.33% | LR: 1.00e-03
2025-08-15 21:32:55,169 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_17
2025-08-15 21:32:55,181 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.9371, Acc=81.25%
2025-08-15 21:32:55,825 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.0272, Acc=86.52%
2025-08-15 21:32:56,506 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.7651, Acc=85.95%
2025-08-15 21:32:56,737 - ml_training_1987073432496 - INFO - Timer 'train_epoch_17': 1.5679 seconds
2025-08-15 21:32:56,738 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_17
2025-08-15 21:32:56,798 - ml_training_1987073432496 - INFO - Timer 'val_epoch_17': 0.0599 seconds
2025-08-15 21:32:56,800 - ml_training_1987073432496 - INFO - Epoch  17 | Train Loss: 0.8941 | Train Acc: 85.56% | Val Loss: 0.7184 | Val Acc: 93.70% | LR: 1.00e-03
2025-08-15 21:32:56,800 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_18
2025-08-15 21:32:56,814 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.7822, Acc=93.75%
2025-08-15 21:32:57,451 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=1.0640, Acc=85.66%
2025-08-15 21:32:58,113 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.6610, Acc=86.94%
2025-08-15 21:32:58,343 - ml_training_1987073432496 - INFO - Timer 'train_epoch_18': 1.5431 seconds
2025-08-15 21:32:58,344 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_18
2025-08-15 21:32:58,410 - ml_training_1987073432496 - INFO - Timer 'val_epoch_18': 0.0662 seconds
2025-08-15 21:32:58,411 - ml_training_1987073432496 - INFO - Epoch  18 | Train Loss: 0.8640 | Train Acc: 87.14% | Val Loss: 0.6481 | Val Acc: 95.56% | LR: 1.00e-03
2025-08-15 21:32:58,457 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 18
2025-08-15 21:32:58,458 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:32:58,458 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 95.55555555555556, 'val_loss': 0.6480942158138051}
2025-08-15 21:32:58,459 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_19
2025-08-15 21:32:58,472 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.9931, Acc=75.00%
2025-08-15 21:32:59,042 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.7591, Acc=89.22%
2025-08-15 21:32:59,704 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.7836, Acc=88.18%
2025-08-15 21:32:59,944 - ml_training_1987073432496 - INFO - Timer 'train_epoch_19': 1.4832 seconds
2025-08-15 21:32:59,944 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_19
2025-08-15 21:33:00,012 - ml_training_1987073432496 - INFO - Timer 'val_epoch_19': 0.0689 seconds
2025-08-15 21:33:00,012 - ml_training_1987073432496 - INFO - Epoch  19 | Train Loss: 0.8307 | Train Acc: 88.52% | Val Loss: 0.6351 | Val Acc: 97.41% | LR: 1.00e-03
2025-08-15 21:33:00,060 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 19
2025-08-15 21:33:00,061 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:33:00,061 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 97.4074074074074, 'val_loss': 0.6351059464847341}
2025-08-15 21:33:00,062 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_20
2025-08-15 21:33:00,077 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.7860, Acc=87.50%
2025-08-15 21:33:00,719 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.8882, Acc=90.20%
2025-08-15 21:33:01,329 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.9911, Acc=90.04%
2025-08-15 21:33:01,549 - ml_training_1987073432496 - INFO - Timer 'train_epoch_20': 1.4866 seconds
2025-08-15 21:33:01,550 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_20
2025-08-15 21:33:01,620 - ml_training_1987073432496 - INFO - Timer 'val_epoch_20': 0.0702 seconds
2025-08-15 21:33:01,621 - ml_training_1987073432496 - INFO - Epoch  20 | Train Loss: 0.8233 | Train Acc: 89.89% | Val Loss: 0.6426 | Val Acc: 95.19% | LR: 1.00e-03
2025-08-15 21:33:01,643 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_21
2025-08-15 21:33:01,660 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.8059, Acc=87.50%
2025-08-15 21:33:02,284 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.7708, Acc=89.95%
2025-08-15 21:33:02,971 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.7863, Acc=90.66%
2025-08-15 21:33:03,195 - ml_training_1987073432496 - INFO - Timer 'train_epoch_21': 1.5520 seconds
2025-08-15 21:33:03,196 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_21
2025-08-15 21:33:03,268 - ml_training_1987073432496 - INFO - Timer 'val_epoch_21': 0.0717 seconds
2025-08-15 21:33:03,269 - ml_training_1987073432496 - INFO - Epoch  21 | Train Loss: 0.7968 | Train Acc: 90.95% | Val Loss: 0.6171 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:33:03,310 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 21
2025-08-15 21:33:03,310 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:33:03,310 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 97.77777777777777, 'val_loss': 0.617107142420376}
2025-08-15 21:33:03,311 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_22
2025-08-15 21:33:03,327 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.9575, Acc=87.50%
2025-08-15 21:33:04,068 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.6719, Acc=93.50%
2025-08-15 21:33:04,805 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.5915, Acc=92.88%
2025-08-15 21:33:05,106 - ml_training_1987073432496 - INFO - Timer 'train_epoch_22': 1.7943 seconds
2025-08-15 21:33:05,106 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_22
2025-08-15 21:33:05,198 - ml_training_1987073432496 - INFO - Timer 'val_epoch_22': 0.0924 seconds
2025-08-15 21:33:05,199 - ml_training_1987073432496 - INFO - Epoch  22 | Train Loss: 0.7619 | Train Acc: 92.59% | Val Loss: 0.6389 | Val Acc: 96.67% | LR: 1.00e-03
2025-08-15 21:33:05,199 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_23
2025-08-15 21:33:05,213 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.7172, Acc=93.75%
2025-08-15 21:33:05,914 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.7499, Acc=93.01%
2025-08-15 21:33:06,586 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.6485, Acc=93.44%
2025-08-15 21:33:06,832 - ml_training_1987073432496 - INFO - Timer 'train_epoch_23': 1.6325 seconds
2025-08-15 21:33:06,833 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_23
2025-08-15 21:33:06,907 - ml_training_1987073432496 - INFO - Timer 'val_epoch_23': 0.0749 seconds
2025-08-15 21:33:06,908 - ml_training_1987073432496 - INFO - Epoch  23 | Train Loss: 0.7419 | Train Acc: 93.28% | Val Loss: 0.5947 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:33:06,955 - ml_training_1987073432496 - INFO - Checkpoint saved at epoch 23
2025-08-15 21:33:06,956 - ml_training_1987073432496 - INFO - Model path: models\mel_cnn_classifier\best_model.pt
2025-08-15 21:33:06,956 - ml_training_1987073432496 - INFO - Checkpoint metrics: {'val_acc': 98.51851851851852, 'val_loss': 0.5946993126588709}
2025-08-15 21:33:06,957 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_24
2025-08-15 21:33:06,974 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.6096, Acc=100.00%
2025-08-15 21:33:07,660 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.6086, Acc=93.50%
2025-08-15 21:33:08,269 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=1.2083, Acc=92.88%
2025-08-15 21:33:08,501 - ml_training_1987073432496 - INFO - Timer 'train_epoch_24': 1.5440 seconds
2025-08-15 21:33:08,502 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_24
2025-08-15 21:33:08,568 - ml_training_1987073432496 - INFO - Timer 'val_epoch_24': 0.0652 seconds
2025-08-15 21:33:08,569 - ml_training_1987073432496 - INFO - Epoch  24 | Train Loss: 0.7560 | Train Acc: 92.96% | Val Loss: 0.5906 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:33:08,569 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_25
2025-08-15 21:33:08,588 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.8567, Acc=93.75%
2025-08-15 21:33:09,203 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.6097, Acc=93.63%
2025-08-15 21:33:09,850 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.6232, Acc=94.43%
2025-08-15 21:33:10,110 - ml_training_1987073432496 - INFO - Timer 'train_epoch_25': 1.5412 seconds
2025-08-15 21:33:10,111 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_25
2025-08-15 21:33:10,199 - ml_training_1987073432496 - INFO - Timer 'val_epoch_25': 0.0879 seconds
2025-08-15 21:33:10,200 - ml_training_1987073432496 - INFO - Epoch  25 | Train Loss: 0.7335 | Train Acc: 94.02% | Val Loss: 0.6071 | Val Acc: 97.04% | LR: 1.00e-03
2025-08-15 21:33:10,200 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_26
2025-08-15 21:33:10,212 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.7994, Acc=87.50%
2025-08-15 21:33:10,837 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.6601, Acc=94.12%
2025-08-15 21:33:11,454 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.7543, Acc=94.18%
2025-08-15 21:33:11,661 - ml_training_1987073432496 - INFO - Timer 'train_epoch_26': 1.4608 seconds
2025-08-15 21:33:11,662 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_26
2025-08-15 21:33:11,733 - ml_training_1987073432496 - INFO - Timer 'val_epoch_26': 0.0717 seconds
2025-08-15 21:33:11,734 - ml_training_1987073432496 - INFO - Epoch  26 | Train Loss: 0.7097 | Train Acc: 94.34% | Val Loss: 0.5891 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:33:11,734 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_27
2025-08-15 21:33:11,746 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.8400, Acc=87.50%
2025-08-15 21:33:12,357 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.6473, Acc=95.47%
2025-08-15 21:33:12,977 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.6112, Acc=95.05%
2025-08-15 21:33:13,192 - ml_training_1987073432496 - INFO - Timer 'train_epoch_27': 1.4580 seconds
2025-08-15 21:33:13,193 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_27
2025-08-15 21:33:13,276 - ml_training_1987073432496 - INFO - Timer 'val_epoch_27': 0.0824 seconds
2025-08-15 21:33:13,276 - ml_training_1987073432496 - INFO - Epoch  27 | Train Loss: 0.7073 | Train Acc: 94.92% | Val Loss: 0.6093 | Val Acc: 97.04% | LR: 1.00e-03
2025-08-15 21:33:13,277 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_28
2025-08-15 21:33:13,290 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=1.0534, Acc=75.00%
2025-08-15 21:33:13,965 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.8890, Acc=94.24%
2025-08-15 21:33:14,597 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.5953, Acc=94.68%
2025-08-15 21:33:14,832 - ml_training_1987073432496 - INFO - Timer 'train_epoch_28': 1.5547 seconds
2025-08-15 21:33:14,833 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_28
2025-08-15 21:33:14,911 - ml_training_1987073432496 - INFO - Timer 'val_epoch_28': 0.0786 seconds
2025-08-15 21:33:14,912 - ml_training_1987073432496 - INFO - Epoch  28 | Train Loss: 0.7001 | Train Acc: 95.03% | Val Loss: 0.5703 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:33:14,912 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_29
2025-08-15 21:33:14,923 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.6838, Acc=93.75%
2025-08-15 21:33:15,537 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.7117, Acc=95.47%
2025-08-15 21:33:16,174 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.5966, Acc=95.54%
2025-08-15 21:33:16,426 - ml_training_1987073432496 - INFO - Timer 'train_epoch_29': 1.5134 seconds
2025-08-15 21:33:16,427 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_29
2025-08-15 21:33:16,492 - ml_training_1987073432496 - INFO - Timer 'val_epoch_29': 0.0643 seconds
2025-08-15 21:33:16,493 - ml_training_1987073432496 - INFO - Epoch  29 | Train Loss: 0.6818 | Train Acc: 95.56% | Val Loss: 0.5835 | Val Acc: 97.78% | LR: 1.00e-03
2025-08-15 21:33:16,494 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_30
2025-08-15 21:33:16,509 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.7486, Acc=87.50%
2025-08-15 21:33:17,144 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.6740, Acc=95.96%
2025-08-15 21:33:17,747 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.7762, Acc=95.17%
2025-08-15 21:33:18,001 - ml_training_1987073432496 - INFO - Timer 'train_epoch_30': 1.5073 seconds
2025-08-15 21:33:18,002 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_30
2025-08-15 21:33:18,077 - ml_training_1987073432496 - INFO - Timer 'val_epoch_30': 0.0755 seconds
2025-08-15 21:33:18,078 - ml_training_1987073432496 - INFO - Epoch  30 | Train Loss: 0.6705 | Train Acc: 95.45% | Val Loss: 0.5730 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:33:18,101 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_31
2025-08-15 21:33:18,117 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.6028, Acc=100.00%
2025-08-15 21:33:18,766 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.5791, Acc=97.06%
2025-08-15 21:33:19,426 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.6835, Acc=96.60%
2025-08-15 21:33:19,632 - ml_training_1987073432496 - INFO - Timer 'train_epoch_31': 1.5315 seconds
2025-08-15 21:33:19,632 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_31
2025-08-15 21:33:19,706 - ml_training_1987073432496 - INFO - Timer 'val_epoch_31': 0.0733 seconds
2025-08-15 21:33:19,706 - ml_training_1987073432496 - INFO - Epoch  31 | Train Loss: 0.6573 | Train Acc: 96.67% | Val Loss: 0.5532 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:33:19,706 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_32
2025-08-15 21:33:19,718 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.6092, Acc=100.00%
2025-08-15 21:33:20,351 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.5979, Acc=97.30%
2025-08-15 21:33:20,972 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.6167, Acc=97.15%
2025-08-15 21:33:21,203 - ml_training_1987073432496 - INFO - Timer 'train_epoch_32': 1.4976 seconds
2025-08-15 21:33:21,203 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_32
2025-08-15 21:33:21,269 - ml_training_1987073432496 - INFO - Timer 'val_epoch_32': 0.0657 seconds
2025-08-15 21:33:21,270 - ml_training_1987073432496 - INFO - Epoch  32 | Train Loss: 0.6411 | Train Acc: 97.25% | Val Loss: 0.5831 | Val Acc: 97.04% | LR: 1.00e-03
2025-08-15 21:33:21,270 - ml_training_1987073432496 - DEBUG - Timer started: train_epoch_33
2025-08-15 21:33:21,284 - ml_training_1987073432496 - DEBUG - Batch 0/119: Loss=0.5746, Acc=100.00%
2025-08-15 21:33:21,907 - ml_training_1987073432496 - DEBUG - Batch 50/119: Loss=0.5599, Acc=96.81%
2025-08-15 21:33:22,574 - ml_training_1987073432496 - DEBUG - Batch 100/119: Loss=0.7800, Acc=97.15%
2025-08-15 21:33:22,814 - ml_training_1987073432496 - INFO - Timer 'train_epoch_33': 1.5438 seconds
2025-08-15 21:33:22,815 - ml_training_1987073432496 - DEBUG - Timer started: val_epoch_33
2025-08-15 21:33:22,897 - ml_training_1987073432496 - INFO - Timer 'val_epoch_33': 0.0827 seconds
2025-08-15 21:33:22,897 - ml_training_1987073432496 - INFO - Epoch  33 | Train Loss: 0.6436 | Train Acc: 96.88% | Val Loss: 0.5729 | Val Acc: 98.52% | LR: 1.00e-03
2025-08-15 21:33:22,898 - ml_training_1987073432496 - INFO - Early stopping triggered at epoch 33 (patience: 10)
2025-08-15 21:33:22,898 - ml_training_1987073432496 - INFO - Training completed. Evaluating on test set...
2025-08-15 21:33:22,954 - ml_training_1987073432496 - INFO - Loaded checkpoint from epoch 23
2025-08-15 21:33:22,956 - ml_training_1987073432496 - DEBUG - Timer started: test_evaluation
2025-08-15 21:33:23,115 - ml_training_1987073432496 - INFO - Timer 'test_evaluation': 0.1589 seconds
2025-08-15 21:33:23,126 - ml_training_1987073432496 - INFO - === TEST RESULTS ===
2025-08-15 21:33:23,126 - ml_training_1987073432496 - INFO - Test Accuracy: 0.9722
2025-08-15 21:33:23,127 - ml_training_1987073432496 - INFO - Test Loss: 0.6125
2025-08-15 21:33:23,127 - ml_training_1987073432496 - INFO - Classification Report:
2025-08-15 21:33:23,128 - ml_training_1987073432496 - INFO -                 precision    recall  f1-score   support
2025-08-15 21:33:23,128 - ml_training_1987073432496 - INFO -              0     1.0000    0.9815    0.9907        54
2025-08-15 21:33:23,128 - ml_training_1987073432496 - INFO -              1     0.9811    0.9630    0.9720        54
2025-08-15 21:33:23,129 - ml_training_1987073432496 - INFO -              2     0.9153    1.0000    0.9558        54
2025-08-15 21:33:23,129 - ml_training_1987073432496 - INFO -              3     1.0000    0.9630    0.9811        54
2025-08-15 21:33:23,129 - ml_training_1987073432496 - INFO -              4     1.0000    1.0000    1.0000        54
2025-08-15 21:33:23,130 - ml_training_1987073432496 - INFO -              5     0.9643    1.0000    0.9818        54
2025-08-15 21:33:23,130 - ml_training_1987073432496 - INFO -              6     0.9138    0.9815    0.9464        54
2025-08-15 21:33:23,131 - ml_training_1987073432496 - INFO -              7     1.0000    0.9259    0.9615        54
2025-08-15 21:33:23,131 - ml_training_1987073432496 - INFO -              8     0.9808    0.9444    0.9623        54
2025-08-15 21:33:23,132 - ml_training_1987073432496 - INFO -              9     0.9811    0.9630    0.9720        54
2025-08-15 21:33:23,132 - ml_training_1987073432496 - INFO -       accuracy                         0.9722       540
2025-08-15 21:33:23,132 - ml_training_1987073432496 - INFO -      macro avg     0.9736    0.9722    0.9724       540
2025-08-15 21:33:23,133 - ml_training_1987073432496 - INFO -   weighted avg     0.9736    0.9722    0.9724       540
2025-08-15 21:33:23,134 - ml_training_1987073432496 - INFO - === END TEST RESULTS ===
2025-08-15 21:33:24,213 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mel_cnn_classifier\training_history_mel_cnn_classifier_training_history.png
2025-08-15 21:33:24,637 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:33:24,638 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:33:25,750 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\mel_cnn_classifier\confusion_matrix_mel_cnn_classifier_confusion_matrix.png
2025-08-15 21:33:25,751 - ml_training_1987073432496 - INFO - Visualizations generated successfully
2025-08-15 21:33:25,751 - ml_training_1987073432496 - INFO - Closing ML Training Logger
2025-08-15 21:33:25,753 - ml_training_1987073432496 - INFO - Metrics summary saved to: train_logs\metrics_summary_mel_cnn_classifier_20250815_213228.json
2025-08-15 21:33:25,754 - __main__ - INFO - mel_cnn training completed:
2025-08-15 21:33:25,754 - __main__ - INFO -   Best val accuracy: 98.5185
2025-08-15 21:33:25,754 - __main__ - INFO -   Test accuracy: 0.9722
2025-08-15 21:33:25,754 - __main__ - INFO - Training raw_cnn pipeline...
2025-08-15 21:33:25,754 - ml_training.pipelines.raw_cnn_pipeline - INFO - Setting up Raw Waveform CNN pipeline...
2025-08-15 21:33:25,769 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform Dataset initialized:
2025-08-15 21:33:25,769 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Samples: 1890
2025-08-15 21:33:25,770 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:33:25,770 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Augmentation: True
2025-08-15 21:33:25,770 - ml_training.pipelines.raw_cnn_pipeline - INFO -     Noise factor: 0.005
2025-08-15 21:33:25,770 - ml_training.pipelines.raw_cnn_pipeline - INFO -     Max shift: 400 samples
2025-08-15 21:33:25,770 - ml_training.pipelines.raw_cnn_pipeline - INFO -     Amplitude range: (0.8, 1.2)
2025-08-15 21:33:25,776 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform Dataset initialized:
2025-08-15 21:33:25,776 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Samples: 540
2025-08-15 21:33:25,776 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:33:25,776 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Augmentation: False
2025-08-15 21:33:25,779 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform Dataset initialized:
2025-08-15 21:33:25,780 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Samples: 270
2025-08-15 21:33:25,780 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:33:25,780 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Augmentation: False
2025-08-15 21:33:25,788 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw Waveform CNN initialized:
2025-08-15 21:33:25,788 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Input length: 8000 samples
2025-08-15 21:33:25,789 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Architecture: Conv1D(64->128->128->256->256) -> Global Pool -> FC(512->256->10)
2025-08-15 21:33:25,789 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Total parameters: 640,906
2025-08-15 21:33:25,789 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Receptive field: 128 samples
2025-08-15 21:33:25,794 - ml_training.pipelines.raw_cnn_pipeline - INFO - Raw CNN pipeline setup completed:
2025-08-15 21:33:25,794 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Device: cuda
2025-08-15 21:33:25,795 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Train samples: 1890
2025-08-15 21:33:25,795 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Val samples: 270
2025-08-15 21:33:25,795 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Test samples: 540
2025-08-15 21:33:25,795 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Batch size: 16
2025-08-15 21:33:25,795 - ml_training.pipelines.raw_cnn_pipeline - INFO -   Audio length: 8000 samples
2025-08-15 21:33:25,796 - ml_training_1987073486976 - INFO - ML Training Logger initialized - Log file: train_logs\raw_cnn_classifier_20250815_213325.log
2025-08-15 21:33:25,797 - ml_training_1987073486976 - INFO - === SYSTEM INFORMATION ===
2025-08-15 21:33:25,797 - ml_training_1987073486976 - INFO - Python Version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
2025-08-15 21:33:25,797 - ml_training_1987073486976 - INFO - PyTorch Version: 2.3.1+cu121
2025-08-15 21:33:25,798 - ml_training_1987073486976 - INFO - NumPy Version: 1.26.4
2025-08-15 21:33:25,798 - ml_training_1987073486976 - INFO - Librosa Version: 0.10.2
2025-08-15 21:33:25,798 - ml_training_1987073486976 - INFO - CUDA Available: Yes
2025-08-15 21:33:25,799 - ml_training_1987073486976 - INFO - CUDA Version: 12.1
2025-08-15 21:33:25,799 - ml_training_1987073486976 - INFO - GPU: NVIDIA GeForce RTX 3060 Laptop GPU
2025-08-15 21:33:25,799 - ml_training_1987073486976 - INFO - GPU Memory: 6.0 GB
2025-08-15 21:33:25,799 - ml_training_1987073486976 - INFO - === END SYSTEM INFO ===
2025-08-15 21:33:25,800 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\raw_cnn_classifier
2025-08-15 21:33:25,800 - ml_training_1987073486976 - INFO - Trainer initialized for raw_cnn_classifier
2025-08-15 21:33:25,801 - ml_training_1987073486976 - INFO - === RAW_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:33:25,801 - ml_training_1987073486976 - INFO - Total Parameters: 640,906
2025-08-15 21:33:25,801 - ml_training_1987073486976 - INFO - Trainable Parameters: 640,906
2025-08-15 21:33:25,801 - ml_training_1987073486976 - INFO - Non-trainable Parameters: 0
2025-08-15 21:33:25,802 - ml_training_1987073486976 - INFO - Model Architecture:
2025-08-15 21:33:25,802 - ml_training_1987073486976 - INFO -   conv1: Conv1d(1, 64, kernel_size=(80,), stride=(4,), padding=(38,), bias=False)
2025-08-15 21:33:25,802 - ml_training_1987073486976 - INFO -   conv2: Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:33:25,802 - ml_training_1987073486976 - INFO -   conv3: Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:33:25,802 - ml_training_1987073486976 - INFO -   conv4: Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:33:25,802 - ml_training_1987073486976 - INFO -   conv5: Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
2025-08-15 21:33:25,803 - ml_training_1987073486976 - INFO -   bn1: BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:33:25,803 - ml_training_1987073486976 - INFO -   bn2: BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:33:25,803 - ml_training_1987073486976 - INFO -   bn3: BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:33:25,803 - ml_training_1987073486976 - INFO -   bn4: BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:33:25,803 - ml_training_1987073486976 - INFO -   bn5: BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2025-08-15 21:33:25,803 - ml_training_1987073486976 - INFO -   pool: MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
2025-08-15 21:33:25,804 - ml_training_1987073486976 - INFO -   dropout1d: Dropout1d(p=0.2, inplace=False)
2025-08-15 21:33:25,804 - ml_training_1987073486976 - INFO -   dropout: Dropout(p=0.3, inplace=False)
2025-08-15 21:33:25,805 - ml_training_1987073486976 - INFO -   global_pool: AdaptiveAvgPool1d(output_size=1)
2025-08-15 21:33:25,805 - ml_training_1987073486976 - INFO -   fc1: Linear(in_features=256, out_features=512, bias=True)
2025-08-15 21:33:25,805 - ml_training_1987073486976 - INFO -   fc2: Linear(in_features=512, out_features=256, bias=True)
2025-08-15 21:33:25,805 - ml_training_1987073486976 - INFO -   fc3: Linear(in_features=256, out_features=10, bias=True)
2025-08-15 21:33:25,806 - ml_training_1987073486976 - INFO - === END RAW_CNN_CLASSIFIER ARCHITECTURE ===
2025-08-15 21:33:25,807 - ml_training_1987073486976 - INFO - === EXPERIMENT CONFIGURATION ===
2025-08-15 21:33:25,807 - ml_training_1987073486976 - INFO - learning_rate: 0.001
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - weight_decay: 0.0001
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - scheduler_type: plateau
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - early_stopping_patience: 10
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - gradient_clipping: 1.0
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - mixed_precision: True
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - optimizer: Adam
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - loss_function: CrossEntropyLoss with label smoothing
2025-08-15 21:33:25,808 - ml_training_1987073486976 - INFO - device: cuda
2025-08-15 21:33:25,809 - ml_training_1987073486976 - INFO - Configuration saved to: train_logs\config_raw_cnn_classifier_20250815_213325.json
2025-08-15 21:33:25,810 - ml_training_1987073486976 - INFO - === END CONFIGURATION ===
2025-08-15 21:33:25,810 - ml_training_1987073486976 - INFO - Starting training for 50 epochs
2025-08-15 21:33:25,810 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_1
2025-08-15 21:33:25,900 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=2.6564, Acc=0.00%
2025-08-15 21:33:26,969 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=2.2450, Acc=11.64%
2025-08-15 21:33:27,876 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=2.2547, Acc=17.14%
2025-08-15 21:33:28,276 - ml_training_1987073486976 - INFO - Timer 'train_epoch_1': 2.4656 seconds
2025-08-15 21:33:28,277 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_1
2025-08-15 21:33:28,374 - ml_training_1987073486976 - INFO - Timer 'val_epoch_1': 0.0968 seconds
2025-08-15 21:33:28,375 - ml_training_1987073486976 - INFO - Epoch   1 | Train Loss: 2.3229 | Train Acc: 19.21% | Val Loss: 1.8552 | Val Acc: 32.96% | LR: 1.00e-03
2025-08-15 21:33:28,426 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 1
2025-08-15 21:33:28,426 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:28,428 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 32.96296296296296, 'val_loss': 1.855174415251788}
2025-08-15 21:33:28,428 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_2
2025-08-15 21:33:28,448 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=2.3806, Acc=12.50%
2025-08-15 21:33:29,383 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=2.0006, Acc=29.90%
2025-08-15 21:33:30,259 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.7425, Acc=33.29%
2025-08-15 21:33:30,667 - ml_training_1987073486976 - INFO - Timer 'train_epoch_2': 2.2393 seconds
2025-08-15 21:33:30,668 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_2
2025-08-15 21:33:30,747 - ml_training_1987073486976 - INFO - Timer 'val_epoch_2': 0.0794 seconds
2025-08-15 21:33:30,748 - ml_training_1987073486976 - INFO - Epoch   2 | Train Loss: 1.8290 | Train Acc: 34.44% | Val Loss: 1.4958 | Val Acc: 52.22% | LR: 1.00e-03
2025-08-15 21:33:30,804 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 2
2025-08-15 21:33:30,806 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:30,806 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 52.22222222222222, 'val_loss': 1.4958129139507519}
2025-08-15 21:33:30,807 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_3
2025-08-15 21:33:30,829 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=2.2285, Acc=37.50%
2025-08-15 21:33:31,749 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.6773, Acc=44.73%
2025-08-15 21:33:32,690 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.8074, Acc=47.22%
2025-08-15 21:33:33,036 - ml_training_1987073486976 - INFO - Timer 'train_epoch_3': 2.2284 seconds
2025-08-15 21:33:33,036 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_3
2025-08-15 21:33:33,126 - ml_training_1987073486976 - INFO - Timer 'val_epoch_3': 0.0898 seconds
2025-08-15 21:33:33,126 - ml_training_1987073486976 - INFO - Epoch   3 | Train Loss: 1.6401 | Train Acc: 47.30% | Val Loss: 1.3124 | Val Acc: 61.48% | LR: 1.00e-03
2025-08-15 21:33:33,176 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 3
2025-08-15 21:33:33,176 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:33,176 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 61.48148148148148, 'val_loss': 1.3123561634736902}
2025-08-15 21:33:33,177 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_4
2025-08-15 21:33:33,203 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.5468, Acc=50.00%
2025-08-15 21:33:34,129 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.5165, Acc=52.45%
2025-08-15 21:33:35,067 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.4670, Acc=53.59%
2025-08-15 21:33:35,387 - ml_training_1987073486976 - INFO - Timer 'train_epoch_4': 2.2103 seconds
2025-08-15 21:33:35,388 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_4
2025-08-15 21:33:35,462 - ml_training_1987073486976 - INFO - Timer 'val_epoch_4': 0.0731 seconds
2025-08-15 21:33:35,463 - ml_training_1987073486976 - INFO - Epoch   4 | Train Loss: 1.4857 | Train Acc: 54.13% | Val Loss: 1.1624 | Val Acc: 68.15% | LR: 1.00e-03
2025-08-15 21:33:35,524 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 4
2025-08-15 21:33:35,524 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:35,524 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 68.14814814814815, 'val_loss': 1.1624383926391602}
2025-08-15 21:33:35,525 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_5
2025-08-15 21:33:35,546 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.3746, Acc=68.75%
2025-08-15 21:33:36,496 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.2590, Acc=59.93%
2025-08-15 21:33:37,405 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.0616, Acc=61.01%
2025-08-15 21:33:37,713 - ml_training_1987073486976 - INFO - Timer 'train_epoch_5': 2.1876 seconds
2025-08-15 21:33:37,714 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_5
2025-08-15 21:33:37,801 - ml_training_1987073486976 - INFO - Timer 'val_epoch_5': 0.0865 seconds
2025-08-15 21:33:37,802 - ml_training_1987073486976 - INFO - Epoch   5 | Train Loss: 1.3384 | Train Acc: 61.80% | Val Loss: 1.0196 | Val Acc: 76.67% | LR: 1.00e-03
2025-08-15 21:33:37,850 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 5
2025-08-15 21:33:37,850 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:37,850 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 76.66666666666667, 'val_loss': 1.0195540505297043}
2025-08-15 21:33:37,852 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_6
2025-08-15 21:33:37,873 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.2123, Acc=68.75%
2025-08-15 21:33:38,868 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.0197, Acc=66.30%
2025-08-15 21:33:39,816 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8928, Acc=65.59%
2025-08-15 21:33:40,150 - ml_training_1987073486976 - INFO - Timer 'train_epoch_6': 2.2978 seconds
2025-08-15 21:33:40,150 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_6
2025-08-15 21:33:40,235 - ml_training_1987073486976 - INFO - Timer 'val_epoch_6': 0.0859 seconds
2025-08-15 21:33:40,236 - ml_training_1987073486976 - INFO - Epoch   6 | Train Loss: 1.2791 | Train Acc: 65.77% | Val Loss: 0.9421 | Val Acc: 79.26% | LR: 1.00e-03
2025-08-15 21:33:40,285 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 6
2025-08-15 21:33:40,285 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:40,286 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 79.25925925925925, 'val_loss': 0.9420559160849628}
2025-08-15 21:33:40,286 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_7
2025-08-15 21:33:40,312 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.1362, Acc=87.50%
2025-08-15 21:33:41,267 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.6849, Acc=69.36%
2025-08-15 21:33:42,166 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.0045, Acc=70.67%
2025-08-15 21:33:42,501 - ml_training_1987073486976 - INFO - Timer 'train_epoch_7': 2.2154 seconds
2025-08-15 21:33:42,501 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_7
2025-08-15 21:33:42,624 - ml_training_1987073486976 - INFO - Timer 'val_epoch_7': 0.1230 seconds
2025-08-15 21:33:42,626 - ml_training_1987073486976 - INFO - Epoch   7 | Train Loss: 1.1733 | Train Acc: 71.32% | Val Loss: 0.8411 | Val Acc: 86.67% | LR: 1.00e-03
2025-08-15 21:33:42,674 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 7
2025-08-15 21:33:42,675 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:42,675 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 86.66666666666667, 'val_loss': 0.8410833863651052}
2025-08-15 21:33:42,676 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_8
2025-08-15 21:33:42,706 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.3462, Acc=62.50%
2025-08-15 21:33:43,649 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.1214, Acc=75.12%
2025-08-15 21:33:44,605 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.5056, Acc=74.20%
2025-08-15 21:33:44,969 - ml_training_1987073486976 - INFO - Timer 'train_epoch_8': 2.2922 seconds
2025-08-15 21:33:44,970 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_8
2025-08-15 21:33:45,051 - ml_training_1987073486976 - INFO - Timer 'val_epoch_8': 0.0816 seconds
2025-08-15 21:33:45,051 - ml_training_1987073486976 - INFO - Epoch   8 | Train Loss: 1.1352 | Train Acc: 74.34% | Val Loss: 0.8870 | Val Acc: 79.26% | LR: 1.00e-03
2025-08-15 21:33:45,052 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_9
2025-08-15 21:33:45,073 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.9493, Acc=75.00%
2025-08-15 21:33:45,998 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.2203, Acc=77.08%
2025-08-15 21:33:46,968 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8836, Acc=76.61%
2025-08-15 21:33:47,267 - ml_training_1987073486976 - INFO - Timer 'train_epoch_9': 2.2144 seconds
2025-08-15 21:33:47,268 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_9
2025-08-15 21:33:47,354 - ml_training_1987073486976 - INFO - Timer 'val_epoch_9': 0.0863 seconds
2025-08-15 21:33:47,355 - ml_training_1987073486976 - INFO - Epoch   9 | Train Loss: 1.0786 | Train Acc: 77.14% | Val Loss: 0.8186 | Val Acc: 86.30% | LR: 1.00e-03
2025-08-15 21:33:47,355 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_10
2025-08-15 21:33:47,378 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.9965, Acc=68.75%
2025-08-15 21:33:48,299 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.7229, Acc=78.06%
2025-08-15 21:33:49,191 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8855, Acc=77.41%
2025-08-15 21:33:49,519 - ml_training_1987073486976 - INFO - Timer 'train_epoch_10': 2.1639 seconds
2025-08-15 21:33:49,520 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_10
2025-08-15 21:33:49,616 - ml_training_1987073486976 - INFO - Timer 'val_epoch_10': 0.0953 seconds
2025-08-15 21:33:49,616 - ml_training_1987073486976 - INFO - Epoch  10 | Train Loss: 1.0442 | Train Acc: 77.35% | Val Loss: 0.7951 | Val Acc: 88.89% | LR: 1.00e-03
2025-08-15 21:33:49,668 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 10
2025-08-15 21:33:49,668 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:49,669 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 88.88888888888889, 'val_loss': 0.7951189454864053}
2025-08-15 21:33:49,671 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_11
2025-08-15 21:33:49,692 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.0369, Acc=87.50%
2025-08-15 21:33:50,620 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.8748, Acc=80.51%
2025-08-15 21:33:51,583 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8499, Acc=81.75%
2025-08-15 21:33:51,955 - ml_training_1987073486976 - INFO - Timer 'train_epoch_11': 2.2839 seconds
2025-08-15 21:33:51,956 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_11
2025-08-15 21:33:52,041 - ml_training_1987073486976 - INFO - Timer 'val_epoch_11': 0.0847 seconds
2025-08-15 21:33:52,041 - ml_training_1987073486976 - INFO - Epoch  11 | Train Loss: 1.0117 | Train Acc: 81.01% | Val Loss: 0.7876 | Val Acc: 90.00% | LR: 1.00e-03
2025-08-15 21:33:52,090 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 11
2025-08-15 21:33:52,090 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:52,091 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 90.0, 'val_loss': 0.7876224026960486}
2025-08-15 21:33:52,091 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_12
2025-08-15 21:33:52,111 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.9225, Acc=87.50%
2025-08-15 21:33:53,036 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.9312, Acc=81.50%
2025-08-15 21:33:53,956 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8965, Acc=82.43%
2025-08-15 21:33:54,290 - ml_training_1987073486976 - INFO - Timer 'train_epoch_12': 2.1989 seconds
2025-08-15 21:33:54,291 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_12
2025-08-15 21:33:54,375 - ml_training_1987073486976 - INFO - Timer 'val_epoch_12': 0.0834 seconds
2025-08-15 21:33:54,376 - ml_training_1987073486976 - INFO - Epoch  12 | Train Loss: 0.9827 | Train Acc: 82.17% | Val Loss: 0.7358 | Val Acc: 90.37% | LR: 1.00e-03
2025-08-15 21:33:54,423 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 12
2025-08-15 21:33:54,424 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:33:54,424 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 90.37037037037037, 'val_loss': 0.7358376769458547}
2025-08-15 21:33:54,426 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_13
2025-08-15 21:33:54,445 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.6734, Acc=93.75%
2025-08-15 21:33:55,394 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.8355, Acc=84.07%
2025-08-15 21:33:56,320 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.9067, Acc=83.85%
2025-08-15 21:33:56,679 - ml_training_1987073486976 - INFO - Timer 'train_epoch_13': 2.2526 seconds
2025-08-15 21:33:56,679 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_13
2025-08-15 21:33:56,764 - ml_training_1987073486976 - INFO - Timer 'val_epoch_13': 0.0848 seconds
2025-08-15 21:33:56,766 - ml_training_1987073486976 - INFO - Epoch  13 | Train Loss: 0.9200 | Train Acc: 83.76% | Val Loss: 0.8063 | Val Acc: 87.41% | LR: 1.00e-03
2025-08-15 21:33:56,766 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_14
2025-08-15 21:33:56,786 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.8937, Acc=87.50%
2025-08-15 21:33:57,691 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.7143, Acc=84.31%
2025-08-15 21:33:58,624 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8512, Acc=84.28%
2025-08-15 21:33:58,942 - ml_training_1987073486976 - INFO - Timer 'train_epoch_14': 2.1765 seconds
2025-08-15 21:33:58,943 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_14
2025-08-15 21:33:59,041 - ml_training_1987073486976 - INFO - Timer 'val_epoch_14': 0.0976 seconds
2025-08-15 21:33:59,042 - ml_training_1987073486976 - INFO - Epoch  14 | Train Loss: 0.9353 | Train Acc: 83.49% | Val Loss: 0.7457 | Val Acc: 89.63% | LR: 1.00e-03
2025-08-15 21:33:59,042 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_15
2025-08-15 21:33:59,063 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.1581, Acc=81.25%
2025-08-15 21:34:00,038 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.0198, Acc=82.60%
2025-08-15 21:34:00,963 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8557, Acc=84.03%
2025-08-15 21:34:01,296 - ml_training_1987073486976 - INFO - Timer 'train_epoch_15': 2.2541 seconds
2025-08-15 21:34:01,297 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_15
2025-08-15 21:34:01,387 - ml_training_1987073486976 - INFO - Timer 'val_epoch_15': 0.0896 seconds
2025-08-15 21:34:01,388 - ml_training_1987073486976 - INFO - Epoch  15 | Train Loss: 0.9131 | Train Acc: 83.76% | Val Loss: 0.7087 | Val Acc: 92.59% | LR: 1.00e-03
2025-08-15 21:34:01,434 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 15
2025-08-15 21:34:01,434 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:34:01,436 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 92.5925925925926, 'val_loss': 0.7086655392366297}
2025-08-15 21:34:01,436 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_16
2025-08-15 21:34:01,460 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.6563, Acc=100.00%
2025-08-15 21:34:02,414 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.1601, Acc=85.42%
2025-08-15 21:34:03,391 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.7583, Acc=85.09%
2025-08-15 21:34:03,716 - ml_training_1987073486976 - INFO - Timer 'train_epoch_16': 2.2807 seconds
2025-08-15 21:34:03,717 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_16
2025-08-15 21:34:03,799 - ml_training_1987073486976 - INFO - Timer 'val_epoch_16': 0.0817 seconds
2025-08-15 21:34:03,800 - ml_training_1987073486976 - INFO - Epoch  16 | Train Loss: 0.8936 | Train Acc: 84.50% | Val Loss: 0.7787 | Val Acc: 89.26% | LR: 1.00e-03
2025-08-15 21:34:03,801 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_17
2025-08-15 21:34:03,822 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.8999, Acc=87.50%
2025-08-15 21:34:04,789 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.6822, Acc=86.89%
2025-08-15 21:34:05,709 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8720, Acc=86.26%
2025-08-15 21:34:06,037 - ml_training_1987073486976 - INFO - Timer 'train_epoch_17': 2.2358 seconds
2025-08-15 21:34:06,037 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_17
2025-08-15 21:34:06,128 - ml_training_1987073486976 - INFO - Timer 'val_epoch_17': 0.0901 seconds
2025-08-15 21:34:06,128 - ml_training_1987073486976 - INFO - Epoch  17 | Train Loss: 0.8808 | Train Acc: 85.93% | Val Loss: 0.7626 | Val Acc: 89.26% | LR: 1.00e-03
2025-08-15 21:34:06,129 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_18
2025-08-15 21:34:06,151 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.9794, Acc=68.75%
2025-08-15 21:34:07,075 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.7113, Acc=86.76%
2025-08-15 21:34:07,988 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.6993, Acc=86.82%
2025-08-15 21:34:08,329 - ml_training_1987073486976 - INFO - Timer 'train_epoch_18': 2.2002 seconds
2025-08-15 21:34:08,330 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_18
2025-08-15 21:34:08,415 - ml_training_1987073486976 - INFO - Timer 'val_epoch_18': 0.0853 seconds
2025-08-15 21:34:08,417 - ml_training_1987073486976 - INFO - Epoch  18 | Train Loss: 0.8757 | Train Acc: 86.83% | Val Loss: 0.6928 | Val Acc: 91.85% | LR: 1.00e-03
2025-08-15 21:34:08,418 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_19
2025-08-15 21:34:08,436 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.6728, Acc=93.75%
2025-08-15 21:34:09,389 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.8724, Acc=87.01%
2025-08-15 21:34:10,289 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8258, Acc=86.76%
2025-08-15 21:34:10,641 - ml_training_1987073486976 - INFO - Timer 'train_epoch_19': 2.2235 seconds
2025-08-15 21:34:10,642 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_19
2025-08-15 21:34:10,722 - ml_training_1987073486976 - INFO - Timer 'val_epoch_19': 0.0798 seconds
2025-08-15 21:34:10,723 - ml_training_1987073486976 - INFO - Epoch  19 | Train Loss: 0.8667 | Train Acc: 86.67% | Val Loss: 0.6806 | Val Acc: 95.19% | LR: 1.00e-03
2025-08-15 21:34:10,774 - ml_training_1987073486976 - INFO - Checkpoint saved at epoch 19
2025-08-15 21:34:10,774 - ml_training_1987073486976 - INFO - Model path: models\raw_cnn_classifier\best_model.pt
2025-08-15 21:34:10,775 - ml_training_1987073486976 - INFO - Checkpoint metrics: {'val_acc': 95.18518518518519, 'val_loss': 0.6806180301834556}
2025-08-15 21:34:10,775 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_20
2025-08-15 21:34:10,802 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.6356, Acc=100.00%
2025-08-15 21:34:11,738 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.7704, Acc=86.89%
2025-08-15 21:34:12,686 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.7454, Acc=86.82%
2025-08-15 21:34:13,002 - ml_training_1987073486976 - INFO - Timer 'train_epoch_20': 2.2278 seconds
2025-08-15 21:34:13,003 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_20
2025-08-15 21:34:13,088 - ml_training_1987073486976 - INFO - Timer 'val_epoch_20': 0.0847 seconds
2025-08-15 21:34:13,089 - ml_training_1987073486976 - INFO - Epoch  20 | Train Loss: 0.8572 | Train Acc: 87.14% | Val Loss: 0.6633 | Val Acc: 95.19% | LR: 1.00e-03
2025-08-15 21:34:13,109 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_21
2025-08-15 21:34:13,130 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.8910, Acc=81.25%
2025-08-15 21:34:14,079 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.7046, Acc=87.62%
2025-08-15 21:34:15,011 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8153, Acc=87.87%
2025-08-15 21:34:15,360 - ml_training_1987073486976 - INFO - Timer 'train_epoch_21': 2.2508 seconds
2025-08-15 21:34:15,361 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_21
2025-08-15 21:34:15,446 - ml_training_1987073486976 - INFO - Timer 'val_epoch_21': 0.0858 seconds
2025-08-15 21:34:15,447 - ml_training_1987073486976 - INFO - Epoch  21 | Train Loss: 0.8234 | Train Acc: 87.99% | Val Loss: 0.6967 | Val Acc: 92.96% | LR: 1.00e-03
2025-08-15 21:34:15,447 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_22
2025-08-15 21:34:15,467 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.8650, Acc=81.25%
2025-08-15 21:34:16,386 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.8595, Acc=89.71%
2025-08-15 21:34:17,378 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.6861, Acc=89.48%
2025-08-15 21:34:17,729 - ml_training_1987073486976 - INFO - Timer 'train_epoch_22': 2.2820 seconds
2025-08-15 21:34:17,730 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_22
2025-08-15 21:34:17,813 - ml_training_1987073486976 - INFO - Timer 'val_epoch_22': 0.0832 seconds
2025-08-15 21:34:17,813 - ml_training_1987073486976 - INFO - Epoch  22 | Train Loss: 0.8327 | Train Acc: 89.37% | Val Loss: 0.6670 | Val Acc: 95.19% | LR: 1.00e-03
2025-08-15 21:34:17,814 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_23
2025-08-15 21:34:17,831 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.6729, Acc=100.00%
2025-08-15 21:34:18,748 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.9854, Acc=90.07%
2025-08-15 21:34:19,679 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.7465, Acc=90.22%
2025-08-15 21:34:20,016 - ml_training_1987073486976 - INFO - Timer 'train_epoch_23': 2.2015 seconds
2025-08-15 21:34:20,017 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_23
2025-08-15 21:34:20,124 - ml_training_1987073486976 - INFO - Timer 'val_epoch_23': 0.1063 seconds
2025-08-15 21:34:20,125 - ml_training_1987073486976 - INFO - Epoch  23 | Train Loss: 0.7957 | Train Acc: 89.84% | Val Loss: 0.7176 | Val Acc: 92.22% | LR: 1.00e-03
2025-08-15 21:34:20,125 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_24
2025-08-15 21:34:20,154 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=1.1511, Acc=68.75%
2025-08-15 21:34:21,037 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.8653, Acc=91.30%
2025-08-15 21:34:21,988 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.9703, Acc=90.28%
2025-08-15 21:34:22,342 - ml_training_1987073486976 - INFO - Timer 'train_epoch_24': 2.2175 seconds
2025-08-15 21:34:22,343 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_24
2025-08-15 21:34:22,422 - ml_training_1987073486976 - INFO - Timer 'val_epoch_24': 0.0784 seconds
2025-08-15 21:34:22,423 - ml_training_1987073486976 - INFO - Epoch  24 | Train Loss: 0.7768 | Train Acc: 90.74% | Val Loss: 0.6587 | Val Acc: 94.07% | LR: 1.00e-03
2025-08-15 21:34:22,423 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_25
2025-08-15 21:34:22,444 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.8644, Acc=93.75%
2025-08-15 21:34:23,436 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=1.1850, Acc=87.99%
2025-08-15 21:34:24,343 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.6882, Acc=88.86%
2025-08-15 21:34:24,702 - ml_training_1987073486976 - INFO - Timer 'train_epoch_25': 2.2783 seconds
2025-08-15 21:34:24,702 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_25
2025-08-15 21:34:24,800 - ml_training_1987073486976 - INFO - Timer 'val_epoch_25': 0.0984 seconds
2025-08-15 21:34:24,801 - ml_training_1987073486976 - INFO - Epoch  25 | Train Loss: 0.8082 | Train Acc: 89.21% | Val Loss: 0.6561 | Val Acc: 92.59% | LR: 1.00e-03
2025-08-15 21:34:24,801 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_26
2025-08-15 21:34:24,821 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.7303, Acc=93.75%
2025-08-15 21:34:25,752 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.6032, Acc=89.46%
2025-08-15 21:34:26,634 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.0295, Acc=90.47%
2025-08-15 21:34:26,979 - ml_training_1987073486976 - INFO - Timer 'train_epoch_26': 2.1780 seconds
2025-08-15 21:34:26,980 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_26
2025-08-15 21:34:27,058 - ml_training_1987073486976 - INFO - Timer 'val_epoch_26': 0.0780 seconds
2025-08-15 21:34:27,058 - ml_training_1987073486976 - INFO - Epoch  26 | Train Loss: 0.7695 | Train Acc: 90.58% | Val Loss: 0.6647 | Val Acc: 93.33% | LR: 1.00e-03
2025-08-15 21:34:27,059 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_27
2025-08-15 21:34:27,076 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.5715, Acc=100.00%
2025-08-15 21:34:28,032 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.6679, Acc=91.67%
2025-08-15 21:34:28,957 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.0502, Acc=90.97%
2025-08-15 21:34:29,309 - ml_training_1987073486976 - INFO - Timer 'train_epoch_27': 2.2493 seconds
2025-08-15 21:34:29,310 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_27
2025-08-15 21:34:29,397 - ml_training_1987073486976 - INFO - Timer 'val_epoch_27': 0.0878 seconds
2025-08-15 21:34:29,397 - ml_training_1987073486976 - INFO - Epoch  27 | Train Loss: 0.7895 | Train Acc: 90.74% | Val Loss: 0.6461 | Val Acc: 94.07% | LR: 1.00e-03
2025-08-15 21:34:29,398 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_28
2025-08-15 21:34:29,420 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.6782, Acc=93.75%
2025-08-15 21:34:30,386 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.7010, Acc=90.44%
2025-08-15 21:34:31,294 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=0.8313, Acc=90.16%
2025-08-15 21:34:31,642 - ml_training_1987073486976 - INFO - Timer 'train_epoch_28': 2.2438 seconds
2025-08-15 21:34:31,645 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_28
2025-08-15 21:34:31,731 - ml_training_1987073486976 - INFO - Timer 'val_epoch_28': 0.0857 seconds
2025-08-15 21:34:31,731 - ml_training_1987073486976 - INFO - Epoch  28 | Train Loss: 0.7629 | Train Acc: 90.58% | Val Loss: 0.6590 | Val Acc: 94.81% | LR: 1.00e-03
2025-08-15 21:34:31,732 - ml_training_1987073486976 - DEBUG - Timer started: train_epoch_29
2025-08-15 21:34:31,750 - ml_training_1987073486976 - DEBUG - Batch 0/119: Loss=0.6763, Acc=93.75%
2025-08-15 21:34:32,698 - ml_training_1987073486976 - DEBUG - Batch 50/119: Loss=0.6802, Acc=91.54%
2025-08-15 21:34:33,619 - ml_training_1987073486976 - DEBUG - Batch 100/119: Loss=1.1723, Acc=91.77%
2025-08-15 21:34:33,982 - ml_training_1987073486976 - INFO - Timer 'train_epoch_29': 2.2508 seconds
2025-08-15 21:34:33,983 - ml_training_1987073486976 - DEBUG - Timer started: val_epoch_29
2025-08-15 21:34:34,068 - ml_training_1987073486976 - INFO - Timer 'val_epoch_29': 0.0843 seconds
2025-08-15 21:34:34,069 - ml_training_1987073486976 - INFO - Epoch  29 | Train Loss: 0.7544 | Train Acc: 91.69% | Val Loss: 0.6654 | Val Acc: 93.70% | LR: 1.00e-03
2025-08-15 21:34:34,069 - ml_training_1987073486976 - INFO - Early stopping triggered at epoch 29 (patience: 10)
2025-08-15 21:34:34,069 - ml_training_1987073486976 - INFO - Training completed. Evaluating on test set...
2025-08-15 21:34:34,127 - ml_training_1987073486976 - INFO - Loaded checkpoint from epoch 19
2025-08-15 21:34:34,128 - ml_training_1987073486976 - DEBUG - Timer started: test_evaluation
2025-08-15 21:34:34,325 - ml_training_1987073486976 - INFO - Timer 'test_evaluation': 0.1966 seconds
2025-08-15 21:34:34,336 - ml_training_1987073486976 - INFO - === TEST RESULTS ===
2025-08-15 21:34:34,336 - ml_training_1987073486976 - INFO - Test Accuracy: 0.9130
2025-08-15 21:34:34,336 - ml_training_1987073486976 - INFO - Test Loss: 0.7201
2025-08-15 21:34:34,337 - ml_training_1987073486976 - INFO - Classification Report:
2025-08-15 21:34:34,337 - ml_training_1987073486976 - INFO -                 precision    recall  f1-score   support
2025-08-15 21:34:34,338 - ml_training_1987073486976 - INFO -              0     0.9630    0.9630    0.9630        54
2025-08-15 21:34:34,338 - ml_training_1987073486976 - INFO -              1     0.9811    0.9630    0.9720        54
2025-08-15 21:34:34,339 - ml_training_1987073486976 - INFO -              2     0.7581    0.8704    0.8103        54
2025-08-15 21:34:34,339 - ml_training_1987073486976 - INFO -              3     0.9167    0.6111    0.7333        54
2025-08-15 21:34:34,340 - ml_training_1987073486976 - INFO -              4     0.8308    1.0000    0.9076        54
2025-08-15 21:34:34,340 - ml_training_1987073486976 - INFO -              5     0.9455    0.9630    0.9541        54
2025-08-15 21:34:34,341 - ml_training_1987073486976 - INFO -              6     0.9286    0.9630    0.9455        54
2025-08-15 21:34:34,341 - ml_training_1987073486976 - INFO -              7     0.9123    0.9630    0.9369        54
2025-08-15 21:34:34,342 - ml_training_1987073486976 - INFO -              8     0.9792    0.8704    0.9216        54
2025-08-15 21:34:34,342 - ml_training_1987073486976 - INFO -              9     0.9630    0.9630    0.9630        54
2025-08-15 21:34:34,342 - ml_training_1987073486976 - INFO -       accuracy                         0.9130       540
2025-08-15 21:34:34,342 - ml_training_1987073486976 - INFO -      macro avg     0.9178    0.9130    0.9107       540
2025-08-15 21:34:34,343 - ml_training_1987073486976 - INFO -   weighted avg     0.9178    0.9130    0.9107       540
2025-08-15 21:34:34,343 - ml_training_1987073486976 - INFO - === END TEST RESULTS ===
2025-08-15 21:34:35,437 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\raw_cnn_classifier\training_history_raw_cnn_classifier_training_history.png
2025-08-15 21:34:35,868 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:34:35,869 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-15 21:34:36,956 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\raw_cnn_classifier\confusion_matrix_raw_cnn_classifier_confusion_matrix.png
2025-08-15 21:34:36,957 - ml_training_1987073486976 - INFO - Visualizations generated successfully
2025-08-15 21:34:36,957 - ml_training_1987073486976 - INFO - Closing ML Training Logger
2025-08-15 21:34:36,959 - ml_training_1987073486976 - INFO - Metrics summary saved to: train_logs\metrics_summary_raw_cnn_classifier_20250815_213325.json
2025-08-15 21:34:36,963 - __main__ - INFO - raw_cnn training completed:
2025-08-15 21:34:36,963 - __main__ - INFO -   Best val accuracy: 95.1852
2025-08-15 21:34:36,963 - __main__ - INFO -   Test accuracy: 0.9130
2025-08-15 21:34:36,964 - __main__ - INFO - Generating comparison visualizations...
2025-08-15 21:34:36,964 - ml_training.utils.visualization - INFO - Visualizer initialized - Output directory: train_logs\plots\comparison
2025-08-15 21:34:37,866 - ml_training.utils.visualization - INFO - Plot saved to: train_logs\plots\comparison\model_comparison.png
2025-08-15 21:34:37,870 - __main__ - INFO - Multi-pipeline training completed successfully
2025-08-15 21:34:37,870 - __main__ - INFO - Training script completed successfully
